{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Week 10: Text-as-Data\"\n",
        "subtitle: \"*DSAN 5650: Causal Inference for Computational Social Science*<br><span class='subsubtitle'>Summer 2025, Georgetown University</span>\"\n",
        "author: \"Jeff Jacobs\"\n",
        "institute: \"[`jj1088@georgetown.edu`](mailto:jj1088@georgetown.edu)\"\n",
        "bibliography: \"../_DSAN5650.bib\"\n",
        "date: 2025-07-23\n",
        "date-format: full\n",
        "lecnum: 10\n",
        "categories:\n",
        "  - \"Class Sessions\"\n",
        "format:\n",
        "  revealjs:\n",
        "    df-print: kable\n",
        "    footer: \"DSAN 5650 Week 10: {{< var w10.footer >}}\"\n",
        "    output-file: \"slides.html\"\n",
        "    html-math-method: mathjax\n",
        "    scrollable: true\n",
        "    link-external-icon: true\n",
        "    link-external-newwindow: true\n",
        "    echo: true\n",
        "    code-fold: true\n",
        "    theme: [default, \"../dsan-globals/jjquarto.scss\"]\n",
        "    include-in-header:\n",
        "      text: \"<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css'><link rel='stylesheet' type='text/css' href='https://cdn.jsdelivr.net/gh/dreampulse/computer-modern-web-font@master/fonts.css'>\"\n",
        "    slide-number: true\n",
        "    simplemenu:\n",
        "      flat: true\n",
        "      barhtml:\n",
        "        header: \"<div class='menubar'><span style='position: absolute; left: 8; padding-left: 8px;'><a href='./index.html'>&larr; Return to Notes</a></span><ul class='menu'></ul></div>\"\n",
        "      scale: 0.5\n",
        "    revealjs-plugins:\n",
        "      - simplemenu\n",
        "  html:\n",
        "    df-print: kable\n",
        "    output-file: \"index.html\"\n",
        "    html-math-method: mathjax\n",
        "    link-external-icon: true\n",
        "    link-external-newwindow: true\n",
        "    echo: true\n",
        "    code-fold: true\n",
        "    include-in-header:\n",
        "      text: \"<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css'><link rel='stylesheet' type='text/css' href='https://cdn.jsdelivr.net/gh/dreampulse/computer-modern-web-font@master/fonts.css'>\"\n",
        "---\n",
        "\n",
        "\n",
        "::: {.content-visible unless-format=\"revealjs\"}\n",
        "\n",
        "<center>\n",
        "<a class=\"h2\" href=\"./slides.html\" target=\"_blank\">Open slides in new window &rarr;</a>\n",
        "</center>\n",
        "\n",
        ":::\n",
        "\n",
        "# Schedule {.smaller .crunch-title .crunch-callout .code-90 data-stack-name=\"Schedule\"}\n",
        "\n",
        "Today's Planned Schedule:\n",
        "\n",
        "| | Start | End | Topic |\n",
        "|:- |:- |:- |:- |\n",
        "| **Lecture** | 6:30pm | 6:45pm | [Final Projects: Dependent vs. Independent Variables &rarr;](#final-project-tings) |\n",
        "| | 6:45pm | 7:20pm | [Double Robustness &rarr;](#double-robustness)\n",
        "| | 7:20pm | 8:00pm | [When Conditioning Won't Cut It: IVs &rarr;](#hard-mode-when-conditioning-cant-fix-things) |\n",
        "| **Break!** | 8:00pm | 8:10pm | |\n",
        "| | 8:10pm | 9:00pm | [Drawing Causal Inferences from Text Data &rarr;](#lab-causal-inference-with-text) |\n",
        "\n",
        ": {tbl-colwidths=\"[12,12,12,64]\"}\n",
        "\n",
        "\n",
        "::: {.hidden}\n",
        "\n",
        "$$\n",
        "\\DeclareMathOperator*{\\argmax}{argmax}\n",
        "\\DeclareMathOperator*{\\argmin}{argmin}\n",
        "\\newcommand{\\bigexp}[1]{\\exp\\mkern-4mu\\left[ #1 \\right]}\n",
        "\\newcommand{\\bigexpect}[1]{\\mathbb{E}\\mkern-4mu \\left[ #1 \\right]}\n",
        "\\newcommand{\\definedas}{\\overset{\\small\\text{def}}{=}}\n",
        "\\newcommand{\\definedalign}{\\overset{\\phantom{\\text{defn}}}{=}}\n",
        "\\newcommand{\\eqeventual}{\\overset{\\text{eventually}}{=}}\n",
        "\\newcommand{\\Err}{\\text{Err}}\n",
        "\\newcommand{\\expect}[1]{\\mathbb{E}[#1]}\n",
        "\\newcommand{\\expectsq}[1]{\\mathbb{E}^2[#1]}\n",
        "\\newcommand{\\fw}[1]{\\texttt{#1}}\n",
        "\\newcommand{\\given}{\\mid}\n",
        "\\newcommand{\\green}[1]{\\color{green}{#1}}\n",
        "\\newcommand{\\heads}{\\outcome{heads}}\n",
        "\\newcommand{\\iid}{\\overset{\\text{\\small{iid}}}{\\sim}}\n",
        "\\newcommand{\\lik}{\\mathcal{L}}\n",
        "\\newcommand{\\loglik}{\\ell}\n",
        "\\DeclareMathOperator*{\\maximize}{maximize}\n",
        "\\DeclareMathOperator*{\\minimize}{minimize}\n",
        "\\newcommand{\\mle}{\\textsf{ML}}\n",
        "\\newcommand{\\nimplies}{\\;\\not\\!\\!\\!\\!\\implies}\n",
        "\\newcommand{\\orange}[1]{\\color{orange}{#1}}\n",
        "\\newcommand{\\outcome}[1]{\\textsf{#1}}\n",
        "\\newcommand{\\param}[1]{{\\color{purple} #1}}\n",
        "\\newcommand{\\pgsamplespace}{\\{\\green{1},\\green{2},\\green{3},\\purp{4},\\purp{5},\\purp{6}\\}}\n",
        "\\newcommand{\\pedge}[2]{\\require{enclose}\\enclose{circle}{~{#1}~} \\rightarrow \\; \\enclose{circle}{\\kern.01em {#2}~\\kern.01em}}\n",
        "\\newcommand{\\pnode}[1]{\\require{enclose}\\enclose{circle}{\\kern.1em {#1} \\kern.1em}}\n",
        "\\newcommand{\\ponode}[1]{\\require{enclose}\\enclose{box}[background=lightgray]{{#1}}}\n",
        "\\newcommand{\\pnodesp}[1]{\\require{enclose}\\enclose{circle}{~{#1}~}}\n",
        "\\newcommand{\\purp}[1]{\\color{purple}{#1}}\n",
        "\\newcommand{\\sign}{\\text{Sign}}\n",
        "\\newcommand{\\spacecap}{\\; \\cap \\;}\n",
        "\\newcommand{\\spacewedge}{\\; \\wedge \\;}\n",
        "\\newcommand{\\tails}{\\outcome{tails}}\n",
        "\\newcommand{\\Var}[1]{\\text{Var}[#1]}\n",
        "\\newcommand{\\bigVar}[1]{\\text{Var}\\mkern-4mu \\left[ #1 \\right]}\n",
        "$$\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "# Final Projects: Independent vs. Dependent Variables {.smaller data-name=\"Final Projects\"}\n",
        "\n",
        "![](images/pgm_general.svg){fig-align=\"center\"}\n",
        "\n",
        "## From Idea to Execution\n",
        "\n",
        "* Starting point: a puzzle about the social world!\n",
        "  * Why are fertility rates dropping in these countries? Why \n",
        "* Dependent Variable\n",
        "  * What Explains This?\n",
        "* Independent Variable / Treatment!\n",
        "  * What Happens When...\n",
        "\n",
        "# Double Robustness {data-stack-name=\"Double Robustness\" .smaller}\n",
        "\n",
        "* Propensity Score Weighting seems so much easier than all the hard work of modeling... why can't we just propensity score all the things and be done with it!?\n",
        "* By using **doubly-robust** estimation methods, you can:\n",
        "  * <i class='bi bi-1-circle'></i> Carefully develop a **covariate adjustment strategy** (then use e.g. regression),\n",
        "  * <i class='bi bi-2-circle'></i> Carefully develop a **propensity score strategy**, and then\n",
        "  * <i class='bi bi-3-circle'></i> Be only as wrong as the least-wrong of <i class='bi bi-1-circle'></i> and <i class='bi bi-2-circle'></i>!!\n",
        "\n",
        "![*With doubly-robust estimation, as long as the answer is either True or False you're good!*](images/false-true.png){fig-align=\"center\"}\n",
        "\n",
        "## Doubly-Robust Estimation {.smaller .crunch-title .crunch-quarto-layout-panel .crunch-quarto-figure}\n",
        "\n",
        ":::: {layout=\"[1,1]\" layout-valign=\"center\"}\n",
        "::: {#blog-dgp}\n",
        "\n",
        "![Super cool example courtesy of [Matteo Courthoud](https://matteocourthoud.github.io/post/aipw/)!](images/darkmode.svg){fig-align=\"center\" width=\"300\"}\n",
        "\n",
        ":::\n",
        "::: {#blog-table}\n",
        "\n",
        "![](images/modes.png){fig-align=\"center\"}\n"
      ],
      "id": "d70591f2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import patchworklib as pw;\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "from causalml.match import create_table_one\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def generate_data(N=300, seed=1):\n",
        "  np.random.seed(seed)\n",
        "  \n",
        "  # Control variables\n",
        "  male = np.random.binomial(1, 0.45, N)\n",
        "  age = np.rint(18 + np.random.beta(2, 2, N)*50)\n",
        "  hours = np.minimum(np.round(np.random.lognormal(5, 1.3, N), 1), 2000)\n",
        "  \n",
        "  # Treatment\n",
        "  pr = np.maximum(0, np.minimum(1, 0.8 + 0.3*male - np.sqrt(age-18)/10))\n",
        "  dark_mode = np.random.binomial(1, pr, N)==1\n",
        "  \n",
        "  # Outcome\n",
        "  read_time = np.round(np.random.normal(10 - 4*male + 2*np.log(hours) + 2*dark_mode, 4, N), 1)\n",
        "\n",
        "  # Generate the dataframe\n",
        "  df = pd.DataFrame({'read_time': read_time, 'dark_mode': dark_mode, 'male': male, 'age': age, 'hours': hours})\n",
        "\n",
        "  return df\n",
        "\n",
        "user_df = generate_data(N=300)\n",
        "ols_model = smf.ols(\"read_time ~ dark_mode\", data=user_df).fit()\n",
        "ols_summary = ols_model.summary()\n",
        "results_as_html = ols_summary.tables[1].as_html()\n",
        "ols_summary_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
        "ols_summary_df[['coef','std err']]\n",
        "#type(ols_summary.tables[1])[['coef','std err']]\n",
        "# .tables[1]\n",
        "# ols_df[['coef','std err']]"
      ],
      "id": "0a3562e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "* ...So, is this a causal effect? Does dark theme **cause** users to spend less time reading?\n",
        "\n",
        "## Unit of Observation: (Article, Reader) {.title-10 .smaller .crunch-title}\n",
        "\n",
        "*(...since I couldn't figure out how to fit it on the last slide)*\n"
      ],
      "id": "96a24282"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: page-read-data\n",
        "user_df.head()"
      ],
      "id": "page-read-data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What Does the Data Look Like?\n"
      ],
      "id": "26aa4b93"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "#ax = pw.Brick(figsize=(8,5))\n",
        "sns.pairplot(\n",
        "  data=user_df, aspect=0.8\n",
        ")"
      ],
      "id": "4820c64a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Balance {.smaller .crunch-title .table-90}\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "Enter **Uber**'s causal inference library: [`causalml`](https://causalml.readthedocs.io/en/latest/about.html)\n"
      ],
      "id": "c91fe028"
    },
    {
      "cell_type": "code",
      "metadata": {
        "df-print": "kable"
      },
      "source": [
        "from IPython.display import display, HTML\n",
        "X = ['male', 'age', 'hours']\n",
        "table1 = create_table_one(user_df, 'dark_mode', X)\n",
        "user_df.to_csv(\"assets/user_df.csv\")\n",
        "table1.to_csv(\"assets/table1.csv\")\n",
        "HTML(table1.to_html())"
      ],
      "id": "969eb563",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "And then `WeightIt` to generate a \"love plot\":\n",
        "\n",
        "![](images/loveplot.png){fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "## *Augmented* Inverse Propensity Weighting (AIPW) {.smaller .crunch-title .title-09 .math-90}\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\hat \\tau_{AIPW} &= \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\text{RegEst}(X_i) + \\text{PropensityAdj}(X_i, Y_i) \\right) \\\\\n",
        "\\text{RegEst}(X_i) &= \\hat \\mu^{(1)}(X_i) - \\hat \\mu^{(0)}(X_i) \\\\\n",
        "\\text{PropensityAdj}(X_i, Y_i) &= \\frac{D_i}{\\hat{\\mathtt{e}}(X_i)} \\left( Y_i - \\hat \\mu^{(1)}(X_i) \\right) - \\frac{(1-D_i) }{1-\\hat{\\mathtt{e}}(X_i)} \\left( Y_i - \\hat \\mu^{(0)}(X_i) \\right)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "where $\\mu^{(d)}(x)$ is the **response function**, i.e. the expected value of the outcome, conditional on observable characteristics $x$ and treatment status $d$, and $e(X)$ is the **propensity score**.\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\mu^{(d)}(x) &= \\mathbb E \\left[ Y_i \\ \\big | \\ X_i = x, D_i = d \\right] \\\\\n",
        "\\mathtt{e}(x) &= \\mathbb E \\left[ D_i = 1 \\ \\big | \\ X_i = x \\right]\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "## Model 1: Propensity Score {.smaller .crunch-title .crunch-img .crunch-quarto-figure}\n"
      ],
      "id": "8978bc41"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "def estimate_e(df, X, D, model_e):\n",
        "    e = model_e.fit(df[X], df[D]).predict_proba(df[X])[:,1]\n",
        "    return e\n",
        "user_df['e'] = estimate_e(user_df, X, \"dark_mode\", LogisticRegression())\n",
        "ax = pw.Brick(figsize=(7, 2.75));\n",
        "sns.kdeplot(\n",
        "  x='e', hue='dark_mode', data=user_df,\n",
        "  # bins=30,\n",
        "  #stat='density',\n",
        "  common_norm=False,\n",
        "  fill=True,\n",
        "  ax=ax\n",
        ");\n",
        "ax.set_xlabel(\"$e(X)$\");\n",
        "ax.savefig()"
      ],
      "id": "8668eb67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "w = 1 / (user_df['e'] * user_df[\"dark_mode\"] + (1-user_df['e']) * (1-user_df[\"dark_mode\"]))\n",
        "smf.wls(\"read_time ~ dark_mode\", weights=w, data=user_df).fit().summary().tables[1]"
      ],
      "id": "98ab5f22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2: Regression with Controls {.smaller}\n",
        "\n",
        "* First, with `scikit-learn`:\n"
      ],
      "id": "5845770f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def estimate_mu(df, X, D, y, model_mu):\n",
        "    mu = model_mu.fit(df[X + [D]], df[y])\n",
        "    mu0 = mu.predict(df[X + [D]].assign(dark_mode=0))\n",
        "    mu1 = mu.predict(df[X + [D]].assign(dark_mode=1))\n",
        "    return mu0, mu1\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "mu0, mu1 = estimate_mu(user_df, X, \"dark_mode\", \"read_time\", LinearRegression())\n",
        "print(np.mean(mu0), np.mean(mu1))\n",
        "print(np.mean(mu1-mu0))"
      ],
      "id": "9bebeb53",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Enter [`EconML`](https://econml.azurewebsites.net/index.html), Microsoft's \"Official\" ML-based econometrics library ðŸ˜Ž\n"
      ],
      "id": "40763909"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from econml.dr import LinearDRLearner\n",
        "\n",
        "model = LinearDRLearner(\n",
        "  model_propensity=LogisticRegression(),\n",
        "  model_regression=LinearRegression(),\n",
        "  random_state=5650\n",
        ")\n",
        "model.fit(Y=user_df[\"read_time\"], T=user_df[\"dark_mode\"], X=user_df[X]);\n",
        "model.ate_inference(X=user_df[X].values, T0=0, T1=1).summary().tables[0]"
      ],
      "id": "96c71204",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Double-Robustness to the Rescue! {.smaller}\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "Wrong **regression** model:\n"
      ],
      "id": "a4701fee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "def compare_estimators(X_e, X_mu, D, y, seed):\n",
        "    df = generate_data(seed=seed)\n",
        "    e = estimate_e(df, X_e, D, LogisticRegression())\n",
        "    mu0, mu1 = estimate_mu(df, X_mu, D, y, LinearRegression())\n",
        "    slearn = mu1 - mu0\n",
        "    ipw = (df[D] / e - (1-df[D]) / (1-e)) * df[y]\n",
        "    aipw = slearn + df[D] / e * (df[y] - mu1) - (1-df[D]) / (1-e) * (df[y] - mu0)\n",
        "    return np.mean((slearn, ipw, aipw), axis=1)\n",
        "\n",
        "def simulate_estimators(X_e, X_mu, D, y):\n",
        "    r = Parallel(n_jobs=8)(delayed(compare_estimators)(X_e, X_mu, D, y, i) for i in range(100))\n",
        "    df_tau = pd.DataFrame(r, columns=['S-learn', 'IPW', 'AIPW'])\n",
        "    return df_tau\n",
        "# The actual plots\n",
        "ax = pw.Brick(figsize=(4, 3.5))\n",
        "wrong_reg_df = simulate_estimators(\n",
        "  X_e=['male', 'age'], X_mu=['hours'], D=\"dark_mode\", y=\"read_time\"\n",
        ")\n",
        "wrong_reg_plot = sns.boxplot(\n",
        "  data=pd.melt(wrong_reg_df), x='variable', y='value', hue='variable',\n",
        "  ax=ax,\n",
        "  linewidth=2\n",
        ");\n",
        "wrong_reg_plot.set(\n",
        "  title=\"Distribution of $\\hat Ï„$\", xlabel='', ylabel=''\n",
        ");\n",
        "ax.axhline(2, c='r', ls=':');\n",
        "ax.savefig()"
      ],
      "id": "0fcdfc9d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "Wrong **propensity score** model:\n"
      ],
      "id": "4c74e451"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: center\n",
        "ax = pw.Brick(figsize=(4, 3.5))\n",
        "wrong_ps_df = simulate_estimators(\n",
        "  ['age'], ['male', 'hours'], D=\"dark_mode\", y=\"read_time\"\n",
        ")\n",
        "wrong_ps_plot = sns.boxplot(\n",
        "  data=pd.melt(wrong_ps_df), x='variable', y='value', hue='variable',\n",
        "  ax=ax,\n",
        "  linewidth=2\n",
        ");\n",
        "ax.set_title(\"Distribution of $\\hat Ï„$\");\n",
        "ax.axhline(2, c='r', ls=':');\n",
        "ax.savefig()"
      ],
      "id": "75d1a898",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "# Hard Mode: When Conditioning Isn't an Option / Can't Fix Things {.title-09 .crunch-title .text-90 data-stack-name=\"Instrumental Variables\"}\n",
        "\n",
        "* Approaches we've discussed thus far depend on the ability to **adjust for** (e.g., by conditioning-on and/or purposefully-not-conditioning-on) **confounders themselves** (e.g., in regression), or on **propensity scores**\n",
        "* Enter **Instrumental Variables!** (this week), **Specification of Mechanisms / Front-Door Pathways** (next week)\n",
        "* $\\leadsto$ Find **\"natural experiments\"**, randomizations or pseudo-randomizations in society that allow us to replicate the \"holy grail\" of random assignment\n",
        "\n",
        "::: {.notes}\n",
        "\n",
        "I... always ask economists why it isn't explained like this, and they always say \"it's more complicated than that\", and then they explain the complications and I think I understand them but still think that this is a good way to describe the gist!\n",
        "\n",
        ":::\n",
        "\n",
        "## Instrumental Variable Estimation\n",
        "\n",
        "# Lab: Causal Inference with Text {data-stack-name=\"Text-as-Data\"}\n",
        "\n",
        "* Lab Time!\n",
        "\n",
        "## References\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ],
      "id": "a68273a3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/jpj/.pyenv/versions/3.11.5/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}