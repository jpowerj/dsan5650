---
title: "Week 2: Probabilistic Graphical Models (PGMs)"
subtitle: "*DSAN 5650: Causal Inference for Computational Social Science*<br><span class='subsubtitle'>Summer 2025, Georgetown University</span>"
author: "Jeff Jacobs"
institute: "[`jj1088@georgetown.edu`](mailto:jj1088@georgetown.edu)"
bibliography: "../_DSAN5650.bib"
date: 2025-05-28
date-format: full
lecnum: 2
categories:
  - "Class Sessions"
format:
  revealjs:
    df-print: kable
    footer: "DSAN 5650 Week 2: {{< var w02.footer >}}"
    output-file: "slides.html"
    html-math-method: mathjax
    scrollable: true
    link-external-icon: true
    link-external-newwindow: true
    theme: [default, "../dsan-globals/jjquarto.scss"]
    include-in-header:
      text: "<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css'><link rel='stylesheet' type='text/css' href='https://cdn.jsdelivr.net/gh/dreampulse/computer-modern-web-font@master/fonts.css'><link rel='preconnect' href='https://fonts.googleapis.com'><link rel='preconnect' href='https://fonts.gstatic.com' crossorigin><link href='https://fonts.googleapis.com/css2?family=Barrio&display=swap' rel='stylesheet'>"
    slide-number: true
    simplemenu:
      flat: true
      barhtml:
        header: "<div class='menubar'><span style='position: absolute; left: 8; padding-left: 8px;'><a href='./index.html'>&larr; Return to Notes</a></span><ul class='menu'></ul></div>"
      scale: 0.5
    revealjs-plugins:
      - simplemenu
  html:
    df-print: kable
    output-file: "index.html"
    html-math-method: mathjax
    link-external-icon: true
    link-external-newwindow: true
---

::: {.content-visible unless-format="revealjs"}

<center>
<a class="h2" href="./slides.html" target="_blank">Open slides in new window &rarr;</a>
</center>

:::

# Schedule {.smaller .crunch-title .crunch-callout .code-90 data-name="Schedule"}

Today's Planned Schedule:

| | Start | End | Topic |
|:- |:- |:- |:- |
| **Lecture** | 6:30pm | 6:45pm | [TA Intros &rarr;](#ta-intros) |
| | 6:45pm | 7:00pm | [HW1 Questions and Concerns &rarr;](#hw1-questions-andor-concerns)
| | 7:00pm | 7:30pm | [Motivating Examples: Causal Inference &rarr;](#motivation-ii-causal-inference) |
| | 7:30pm | 7:45pm | [Your First Probabilistic Graphical Model! &rarr;](#your-first-probabilistic-graphical-model)
| **Break!** | 7:45pm | 8:00pm | |
| | 8:00pm | 8:30pm | [PGM Nuts and Bolts &rarr;](#pgm-nuts-and-bolts)
| | 8:30pm | 9:00pm | [Course Logistics &rarr;](#course-logistics) |

: {tbl-colwidths="[12,12,12,64]"}

{{< include ../dsan-globals/_globals-py.qmd >}}

{{< include ../dsan-globals/_globals-tex.qmd >}}


::: {.hidden}

```{=html}
<style>
.barrio-jj {
  font-family: "Barrio", system-ui;
  /* font-weight: 400; */
  font-style: normal;
}
</style>
```

:::

# TA Intros {data-stack-name="TA Intros"}

## Courtney Green {.crunch-title .text-90}

**Background:** BA in Public Policy & Leadership, now interested in using data to examine structural disparities.

**Interests & what I can help with:** How sociodemographic factors (e.g., race, gender, income, immigration status, education level) shape policy outcomes and institutional practices in areas like criminal justice, housing, healthcare, education, and environment.

* **Ask me about:** Counterfactual balancing, handling messy or privacy-limited datasets, and framing causal questions around inequality.

* Reach out if you're thinking about a final project that touches social systems, systemic inequity, or fairness! 

## What Got Me Interested in Causal Inference {.crunch-title .text-75}
**5000 Project: Over-Policing and Wrongful Convictions in Illinois** 

* **Motivation:** Explore what demographic factors predict wrongful convictions using real exoneration data.
* **Challenge:** No data on ‚Äúnon-exonerated innocents,‚Äù so I (with prof's help) created a counterfactual dataset by sampling from the incarcerated population
* **Method:** Trained models (logistic regression, random forest, KNN) on a balanced dataset of 548 exonerated and 548 non-exonerated individuals
* **Finding:** Race and geography (esp. Cook Count/Chicago) were the strongest predictors of exoneration
* **Takeaway:** Questions about systemic bias can‚Äôt be answered with just descriptive stats, you need counterfactual reasoning and causal inference

<span style="font-size: 80%;">[(Optional) View the counterfactual setup](https://crg123.georgetown.domains/projects/dsan-5000/_site/technical-details/data-balancing/main.html)</span>


## Wendy Hu {.crunch-title .text-82 .crunch-ul}

* **Background:** BS in Social Work, passionate about advancing social equity through computational tools
* **Interest:** I bring a background in social welfare, public health, and NGO data, with experience analyzing behavioral and institutional outcomes. My work spans Indigenous health, gender equity, and trauma-informed service design‚Äîalways with a focus on equity, system change, and policy relevance.
* **Ask me about:** Framing social justice questions in data terms, working with community or clinical datasets and interpreting model results in context.
* If you‚Äôre designing a project around health, inequality, nonprofit impact, or any socially embedded issue‚ÄîI‚Äôd love to help bridge rigor and relevance.

# HW1 Questions and/or Concerns {data-stack-name="HW1"}

## Technical Issues (JupyterHub)

## Content Issues

# Motivating Examples: Causal Inference {data-stack-name="Causal Inference"}

* The *methodology* we'll use to *draw inferences* about social phenomena from data

## Disclaimer: Unfortunate Side Effects of Engaging Seriously with Causality {.smaller .crunch-title .title-10 .crunch-p .crunch-img}

:::: {.columns}
::: {.column width="50%"}

<i class='bi bi-1-circle'></i> You'll no longer be able to read "scientific" writing without striking this expression (involuntarily):

:::
::: {.column width="50%"}

<i class='bi bi-2-circle'></i> "Scientific" talks will begin to sound like the following:

:::
::::

:::: {layout="[5,5]" layout-valign="default"}
::: {#expression}

![](images/hrngg.png){fig-align="center" width="300"}

:::
::: {#looked-at-the-data}

{{< video https://jpj.georgetown.domains/dsan5650-scratch/looked_at_the_data.mp4 >}}

:::
::::

## Blasting Off Into Causality! {.title-10 .crunch-title .not-title-slide}

![](images/posadism_causal.jpg){fig-align="center"}

## Data-Generating Processes (DGPs) {.title-09 .text-85 .crunch-title .crunch-ul .crunch-quarto-figure .crunch-quarto-layout-panel .crunch-li-5}

:::: {layout="[55,45]" layout-align="center" layout-valign="center"}
::: {#dgps-5100}

* You saw this in DSAN 5100!
* ¬´$X_1, \ldots, X_n$ drawn i.i.d. Normal, mean $\mu$ variance $\sigma^2$¬ª characterizes **DGP of $(X_1, \ldots, X_n)$**

:::

![](images/hmm_clusters_single_dist.svg){fig-align="center" width="280"}

::::

* 5650: **Dive into DGPs**, rather than treating as black box/footnote to Law of Large Numbers, so we can move [*asymptotically!*]...
* **From *associational* statements**:
  * ¬´$\underbrace{\text{An increase}}_{\small\text{noun}}$ in $X$ by 1 is associated with increase in $Y$ by $\beta$¬ª
* **To *causal* ones**: ¬´$\underbrace{\text{Increasing}}_{\small\text{verb}}$ $X$ by 1 *causes* $Y$ to increase by $\beta$¬ª

## DGPs and the Emergence of Order {.crunch-title .crunch-quarto-layout-panel .title-09 .crunch-quarto-figure}

::: {layout="[1,1]"}

* Who can guess the state of this process after 10 steps, with 1 person?
* 10 people? 50? 100? (If they find themselves on the same spot, they stand on each other's heads)
* 100 steps? 1000?

![](images/random_walk.svg){fig-align="center" width="430"}

:::

## The Result: 16 Steps

![](images/random-walk-16-1.png){fig-align="center"}

## The Result: 64 Steps

![](images/random-walk-64-1.png){fig-align="center"}

## "Mathematical/Scientific Modeling" {.smaller .crunch-title .crunch-ul}

* Thing we observe (poking out of water): **data**
* Hidden but possibly discoverable via deeper dive (ecosystem under surface): **DGP**

<!-- My sincere belief and definitely not an image forwarded to me unironically by a family member when I was a tween -->

![](images/fwds_from_grandma.jpg){fig-align="center"}

## So What's the Problem? {.crunch-title .crunch-ul .crunch-li-8 .inline-90}

* Non-probabilistic models: High potential for being garbage
  * *tldr: even if SUPER certain, using $\Pr(\mathcal{H}) = 1-\varepsilon$ with tiny $\varepsilon$ has literal life-saving advantages* [@finetti_probability_1972]
* Probabilistic models: Getting there, still looking at "surface"
  * Of the $N = 100$ times we observed event $X$ occurring, event $Y$ also occurred $90$ of those times
  * $\implies \Pr(Y \mid X) = \frac{\#[X, Y]}{\#[X]} = \frac{90}{100} = 0.9$
* Causal models: Does $Y$ happen **because of** $X$ happening? For that, need to start modeling **what's happening under the surface** making $X$ and $Y$ **"pop up" together** so often

## The *Shallow* Problem of Causal Inference {.title-08}

:::: {.columns}
::: {.column width="65%"}

![](images/ski-revenue-lawyers-1.png){fig-align="center"}

:::
::: {.column width="35%"}

``` {.r style="font-size: 72%;"}
cor(ski_df$value, law_df$value)
```

```
[1] 0.9921178
```

::: {style="font-size: 50% !important;"}
(Data from Vigen, <a href='http://web.archive.org/web/20191006000802/http://tylervigen.com/view_correlation?id=29272' target='_blank'>Spurious Correlations</a>)
:::

This, however, is only a *mini-boss*. Beyond it lies the truly invincible **FINAL BOSS**... üôÄ

:::
::::

## The *Fundamental* Problem of Causal Inference {.crunch-title .crunch-ul .crunch-callout .title-07}

The only workable definition of ¬´$X$ causes $Y$¬ª:

::: {.callout-note icon="false" title="<i class='bi bi-info-circle pe-1'></i> Defining Causality [@hume_treatise_1739, ruining everything as usual üò§]"}

$X$ causes $Y$ if and only if:

1. $X$ *temporally precedes* $Y$ and
2. 
    * In **two worlds** $W_0$ and $W_1$ where
    * everything is exactly the same **except that** $X = 0$ in $W_0$ and $X = 1$ in $W_1$,
    * $Y = 0$ in $W_0$ and $Y = 1$ in $W_1$

:::

* The problem? We live in **one** world, not two identical worlds simultaneously üò≠

## What Is To Be Done?

![](images/face_everything_and_rise.jpg){fig-align="center"}

## Probability++ {.crunch-title}
  
* Tools from prob/stats (RVs, CDFs, Conditional Probability) **necessary but not sufficient** for causal inference!
* Example: Say we use DSAN 5100 tools to discover:
  * Probability that event $E_1$ occurs is $\Pr(E_1) = 0.5$
  * Probability that $E_1$ occurs **conditional on** another event $E_0$ occurring is $\Pr(E_1 \mid E_0) = 0.75$
* Unfortunately, we still **cannot** infer that the occurrence of $E_0$ **causes** an increase in the likelihood of $E_1$ occurring.

## Beyond Conditional Probability {.crunch-title .text-90}

* This issue (that **conditional probabilities** could not be interpreted causally) at first represented a kind of dead end for scientists interested in employing probability theory to study causal relationships...
* Recent decades: researchers have built up an additional "layer" of modeling tools, augmenting existing machinery of probability to address causality head-on!
* @pearl_causality_2000: Formal proofs that ($\Pr$ axioms) $\cup$ ($\textsf{do}$ axioms) $\Rightarrow$ causal inference procedures successfully recover causal effects

## Preview: do-Calculus {.crunch-title .crunch-math .text-85 .table-85 .crunch-ul .inline-90 .math-90 .crunch-li-6}

* *Extends* core of probability to incorporate causality, via $\textsf{do}$ operator
* $\textsf{do}(X = 5)$ is a "special" **event**, representing **intervention in DGP** to **force** $X \leftarrow 5$... $\textsf{do}(X = 5)$ **not the same event** as $X = 5$!

| $X = 5$ | $\neq$ | $\textsf{do}(X = 5)$ |
|:-:|:-:|:-:|
| *Observing* that $X$ took on value 5 (for some possibly-unknown reason) | $\neq$ | *Intervening* to force $X \leftarrow 5$, all else in DGP remaining the same (intervention then "flows" through rest of DGP) |

: {tbl-colwidths="[46,2,52]"}

* Probably the most difficult thing in 5650 to wrap head around
* "Special": $\Pr(\textsf{do}(X = 5))$ *not* well-defined, only $\Pr(Y = 6 \mid \textsf{do}(X = 5))$
* To emphasize special-ness, we may use notation like:

  $$
  \Pr(Y = 6 \mid \textsf{do}(X = 5)) \equiv \textstyle \Pr_{\textsf{do}(X = 5)}(Y = 6)
  $$

  to avoid confusion with "normal" events

## Causal World Unlocked üòé (With Great Power Comes Great Responsibility...) {.title-08 .crunch-title .crunch-ul}

* With $\textsf{do}(\cdot)$ in hand... (Alongside DGP satisfying axioms slightly more strict than core probability axioms)
* We *can* make causal inferences from similar pair of facts! If:
  * Probability that event $E_1$ occurs is $\Pr(E_1) = 0.5$,
  * The probability that $E_1$ occurs **conditional on** the event $\textsf{do}(E_0)$ occurring is $\Pr(E_1 \mid \textsf{do}(E_0)) = 0.75$,
* **Now** we can actually infer that the occurrence of $E_0$ **caused** an increase in the likelihood of $E_1$ occurring!

## Ulysses and the [Computational] Sirens {.smaller .crunch-title}

![](images/sirens.jpg){fig-align="center"}

# Your First PGM! {.smaller .crunch-title .title-10 .crunch-ul .crunch-li-8 .crunch-quarto-figure .crunch-img .crunch-p data-stack-name="PGMs"}

![[Image source](http://probmods.org/chapters/dependence.html)](images/medical.jpg){fig-align="center"}

* <i class='bi bi-1-circle'></i> Which of the variables (ovals) are **observed**? Which are **latent**?
* <i class='bi bi-2-circle'></i> What do you think the arrows represent?
* <i class='bi bi-3-circle'></i> Can we use this to find the **"root cause"** of (e.g.) observed **chest pain**? Or conversely, to **predict** possible &uarr; in likelihood of chest pain if we start smoking?

## Bayesian Inference but with Pictures {.title-09 .crunch-title .crunch-ul .crunch-li-8 .crunch-callout .text-90}

A **Probabilistic Graphical Model (PGM)** provides us with:

* A **formal**-mathematical...
* But also easily **visualizable** (by construction)...
* Representation of a **data-generating process (DGP)!**

Example: Let's model how **weather** $W$ affects **evening plans** $Y$: the choice between **going to a party** or **staying in to watch movies**

::: {.callout-tip title="<i class='bi bi-info-circle'></i> The Partier's Dilemma" icon="false"}

1.  A person $i$ wakes up with some initial affinity for partying: $\Pr(Y_i = \textsf{Go Out})$
2.  $i$ then goes to their window and observes the weather $W_i$ outside:
    i. If the weather is **sunny**, $i$'s affinity increases: $\Pr(Y_i = \textsf{Go} \mid W_i = \textsf{Sun}) > \Pr(Y = \textsf{Go})$
    ii. Otherwise, if it is **rainy**, $i$'s affinity decreases: $\Pr(Y_i = \textsf{Go} \mid W_i = \textsf{Sun}) < \Pr(Y = \textsf{Go})$

:::

## Two Main "Building Blocks" {.crunch-title .title-09 .inline-95 .math-80 .crunch-ul .crunch-math .crunch-li-8 .text-90}

* **Nodes** like $\require{enclose}\enclose{circle}{\kern .01em ~X~\kern .01em}$ denote **Random Variables**

$$
\boxed{\require{enclose}\enclose{circle}{\kern .01em ~X~\kern .01em}} \simeq \boxed{ \begin{array}{c|cc}x & \textsf{Tails} & \textsf{Heads} \\\hline \Pr(X = x) & 0.5 & 0.5\end{array}}
$$

* **Edges** like $\require{enclose}\enclose{circle}{\kern .01em ~X~\kern .01em} \rightarrow \; \enclose{circle}{\kern.01em Y~\kern .01em}$ denote **relationships** between RVs
  * What an edge "means" can get [ontologically] tricky!
  * Retain sanity by just remembering: an edge $\require{enclose}\enclose{circle}{\kern .01em ~X~\kern .01em} \rightarrow \; \enclose{circle}{\kern.01em Y~\kern .01em}$ is included in our PGM if we "care about" modeling the **conditional probability table (CPT)** of $Y$ w.r.t. $X$

$$
\require{enclose}\boxed{ \enclose{circle}{\kern .01em ~X~\kern .01em} \rightarrow \; \enclose{circle}{\kern.01em Y~\kern .01em} } \simeq \boxed{
  \begin{array}{c|cc}
  x & \Pr(Y = \textsf{Lose} \mid X = x) & \Pr(Y = \textsf{Win} \mid X = x) \\\hline
  \textsf{Tails} & 0.8 & 0.2 \\
  \textsf{Heads} & 0.5 & 0.5
  \end{array}
}
$$

## PGM for the Partier's Dilemma {.smaller .crunch-title .crunch-ul .table-90}

* A node $\pnode{W}$ denoting RV $W$, which can take on values in $\mathcal{R}_W = \{\textsf{Sun}, \textsf{Rain}\}$,
* A node $\pnode{Y}$ denoting RV $Y$, which can take on values in $\mathcal{R}_Y = \{\textsf{Go}, \textsf{Stay}\}$, and 
* An edge $\pedge{W}{Y}$ representing the following relationship between $W$ and $Y$:
  * $\Pr(Y = \textsf{Go} \mid W = \textsf{Sun}) = 0.8$
  * $\Pr(Y = \textsf{Stay} \mid W = \textsf{Sun}) = 0.2$
  * $\Pr(Y = \textsf{Go} \mid W = \textsf{Rain}) = 0.1$
  * $\Pr(Y = \textsf{Stay} \mid W = \textsf{Rain}) = 0.9$

:::: {layout="[1,1]"}
::: {#fig-partier-dgp}

![](images/pgm.svg){fig-align="center" width="400"}

Our PGM of the Partier's Dilemma
:::
::: {#fig-partier-cpt}

| | $\Pr(Y = \textsf{Stay} \mid W)$ | $\Pr(Y = \textsf{Go} \mid W)$ |
|-:|:-:|:-:|
| $W = \textsf{Sun}$ | 0.2 | 0.8 |
| $W = \textsf{Rain}$ | 0.9 | 0.1 |

The Conditional Probability Table (CPT) for the edge $\pedge{W}{Y}$ in @fig-partier-dgp
:::
::::

## Observed vs. Latent Nodes

* PGMs help us make **valid (Bayesian) inferences** about the world in the face of **incomplete information**!
* Key remaining tool: separation of nodes into two categories:
  * **Observed nodes** (shaded)
  * **Latent nodes** (unshaded)
* $\Rightarrow$ Can use our PGM as a **weather-inference machine!**
* If we **observe** $i$ at a party, what can we infer about the **weather** outside?

## Observed Partier, Latent Weather {.title-09}

* We can draw this situation as a PGM with **shaded** and **unshaded nodes**, distinguishing what we **know** from what we'd like to **infer**:

![](images/pgm_yobs.svg){fig-align="center" width="400"}

| | | |
|:-:|:-:|:-:|
| ‚ùì | &nbsp; | ‚úÖ |

: {tbl-colwidths="[18,64,18]"}

* And we can now use Bayes' Rule to compute how observed information ($i$ at party $\Rightarrow [Y = \textsf{Go}]$) "flows" back into $W$

## Computation via Bayes' Rule {.smaller .crunch-title .crunch-ul .crunch-math .math-80}

* Bayes' Rule, $\Pr(A \mid B) = \frac{\Pr(B \mid A)\Pr(A)}{\Pr(B)}$, tells us how to use info about $\Pr(B \mid A)$ to obtain info about $\Pr(A \mid B)$!
* We use it to obtain a distribution for $W$ **updated to incorporate** new info $[Y = \textsf{Go}]$:

$$
\begin{align*}
&\Pr(W = \textsf{Sun} \mid Y = \textsf{Go}) 
= \frac{\Pr(Y = \textsf{Go} \mid W = \textsf{Sun}) \Pr(W = \textsf{Sun})}{\Pr(Y = \textsf{Go})} \\
=\, &\frac{\Pr(Y = \textsf{Go} \mid W = \textsf{Sun}) \Pr(W = \textsf{Sun})}{\Pr(Y = \textsf{Go} \mid W = \textsf{Sun}) \Pr(W = \textsf{Sun}) + \Pr(Y = \textsf{Go} \mid W = \textsf{Rain}) \Pr(W = \textsf{Rain})}
\end{align*}
$$

* Plug in info from CPT to obtain our new (conditional) probability of interest:

$$
\begin{align*}
\Pr(W = \textsf{Sun} \mid Y = \textsf{Go}) &= \frac{(0.8)(0.5)}{(0.8)(0.5) + (0.1)(0.5)} = \frac{0.4}{0.4 + 0.05} \approx 0.89
\end{align*}
$$

* We've learned something interesting! Observing $i$ at the party $\leadsto$ probability of sun jumps from $0.5$ (**"prior"** estimate of $W$, best guess without any other relevant info) to $0.89$ (**"posterior"** estimate of $W$, best guess after incorporating relevant info).

## Importance of Observed vs. Latent Distinction! {.smaller .crunch-title .title-10}

* Across many different fields, hidden stumbling-block in your project may be **failure to model this distinction** and pursue its implications!

::: {#fig-fence-dog}

<center>

{{< video https://jpj.georgetown.domains/dsan5650-scratch/fence_dog.mp4 height="400" align="center" >}}

</center>

Your model failing to achieve its goal bc you haven't yet distinguished observed vs. latent variables
:::

## Example from Cognitive Neuroscience: Visual Perception {.smaller .crunch-title .title-08 .crunch-ul .crunch-quarto-figure .crunch-quarto-layout-panel}

:::: {layout="[55,45]" layout-valign="center"}
::: {#cog-neuro-text}

* We "see" **3D objects** like a basketballs, but our eyes are (curved) **2D surfaces!**
* $\Rightarrow$ Our brains **construct** 3D environment by combining 2D info (**observed** photons-hitting-light-cones) with **latent** heuristic info:
  * Instantaneous **Binocular Disparity**, fusing info from **two** slightly-offset eyes,
  * Short-term **Motion** [**Parallax**](https://en.wikipedia.org/wiki/Parallax): How does object shift over short temporal "windows" of movement?
  * Long-term mental models (orange-ish circle with this line pattern is usually a basketball, which is usually this big, etc.)

:::
::: {#cog-neuro-img}

![[Image source](https://royalsocietypublishing.org/doi/10.1098/rstb.2015.0256) (a very cool article!)](images/parallax.jpg){fig-align="center"}

:::
::::

* Similar examples in many other fields $\leadsto$ science is a strange waltz of general models vs. field-specific details, but there's one model that is **infinitely helpful** imo...

## Hidden Markov Models (HMMs) Are Our Ur-PGMs! {.smaller .crunch-title .title-09 .crunch-quarto-figure .crunch-quarto-layout-cell .callout-fw}

* Using ["Ur"](https://blogs.transparent.com/german/the-german-prefix-ur/) in the same sense as ["America's Ur-Choropleths"](https://kieranhealy.org/blog/archives/2015/06/12/americas-ur-choropleths/)...
* HMMs are our "Ur-Models" for Computational [**Social** Science]{.barrio-jj} specifically

:::: {layout="[3,1]" layout-valign="center"}

![](images/hmm.svg){fig-align="right" width="700"}

![](images/mood_crop.jpg){fig-align="left" width="100"}

::::

* Let's consider an extremely currently-popular strand of CSS research, and step through why (a) it may be harder than it initially seems, but (b) we can use HMMs to "organize"/manage/visualize the complexity!

::: {.notes}

As in, how America's Ur-Choropleths are two visualizations you can keep at hand before launching into a specific nation-wide choropleth about a specific issue!

:::

## Studying "Fake News" {.smaller .callout-fw .callout-valign .crunch-img .crunch-p .crunch-quarto-figure .crunch-title .crunch-callout .text-70 .crunch-ul .crunch-li-5 .crunch-quarto-layout-panel}


::::: {.callout}
:::: {#callout-container}
::: {style="float: left; margin-right: 12px; margin-bottom: -2px"}

![](images/real-tired.png){width="50"}

:::

Studying "fake news" with ML and/or Deep Learning and/or Big Data is very popular in Computational Social Science: let's use HMMs to see why it might be more... difficult/complicated than it seems at first üôà

::::
:::::

* The (implicit) model in studies like @iyengar_news_2010 is something like:

:::: {layout="[65,35]" layout-valign="center" layout-align="center"}
::: {#iyengar-text}

![](images/hmm_media.svg){fig-align="center" width="520"}

* Thus allowing results to be summarized in a table like:

![](images/iyengar_results.jpg){fig-align="center" width="400"}

:::
::: {#iyengar-img}

![@iyengar_news_2010](images/iyengar_kinder.jpg){fig-align="center" width="60%"}

:::
::::

## The Devil in the Details I {.smaller .crunch-title .lh-adjust}

> Residents of the [New Haven, Connecticut area]{.jjbox} participated in one of two experiments, each of which spanned [six consecutive days]{.jjbox} [...] took place in [November 1980]{.jjbox}, shortly after the [presidential election]{.jjbox}

> We measured **problem importance** with four questions that appeared in both the pretreatment and posttreatment questionnaires:
> 
> * Please [indicate how important]{.jjbox} you consider these
problems to be.
> * Should the federal government [do more]{.jjbox} to develop solutions to these problems, even if it means [raising taxes]{.jjbox}?
> * How much do you yourself [care]{.jjbox} about these problems?
> * [These days]{.jjbox} how much do you [talk]{.jjbox} about these
problems?

## The Devil in the Details II

![](images/iyengar_experiment.jpg){fig-align="center"}

## Randomization and Fine-Tuned Treatment {.smaller .crunch-quarto-figure .crunch-quarto-layout-panel}

:::: {layout="[50,50]" layout-valign="center"}

![](images/iyengar_treatment.jpg){fig-align="center"}

![](images/iyengar_control.jpg){fig-align="center"}

::::

* ...These are the types of things we usually **don't** have control over as data scientists (we're just handed a `.csv`!)

## The Final Piece: Plate Notation

* For describing general distributions, there is often a "single node generating a bunch of nodes" structure:

![](images/hmm_clusters_single_dist.svg){fig-align="center"}

* PGM notation has a built-in tool for this: **plates!**

![](images/pgm_plates.svg){fig-align="center"}

## References

::: {#refs}
:::
