{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Week 2: Probabilistic Graphical Models (PGMs)\"\n",
        "subtitle: \"*DSAN 5650: Causal Inference for Computational Social Science*<br><span class='subsubtitle'>Summer 2025, Georgetown University</span>\"\n",
        "author: \"Jeff Jacobs\"\n",
        "institute: \"[`jj1088@georgetown.edu`](mailto:jj1088@georgetown.edu)\"\n",
        "bibliography: \"../_DSAN5650.bib\"\n",
        "date: 2025-05-28\n",
        "date-format: full\n",
        "lecnum: 2\n",
        "categories:\n",
        "  - \"Class Sessions\"\n",
        "format:\n",
        "  revealjs:\n",
        "    df-print: kable\n",
        "    footer: \"DSAN 5650 Week 2: {{< var w02.footer >}}\"\n",
        "    output-file: \"slides.html\"\n",
        "    html-math-method: mathjax\n",
        "    scrollable: true\n",
        "    link-external-icon: true\n",
        "    link-external-newwindow: true\n",
        "    theme: [default, \"../dsan-globals/jjquarto.scss\"]\n",
        "    include-in-header:\n",
        "      text: \"<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css'><link rel='stylesheet' type='text/css' href='https://cdn.jsdelivr.net/gh/dreampulse/computer-modern-web-font@master/fonts.css'><link rel='preconnect' href='https://fonts.googleapis.com'><link rel='preconnect' href='https://fonts.gstatic.com' crossorigin><link href='https://fonts.googleapis.com/css2?family=Barrio&display=swap' rel='stylesheet'>\"\n",
        "    slide-number: true\n",
        "    simplemenu:\n",
        "      flat: true\n",
        "      barhtml:\n",
        "        header: \"<div class='menubar'><span style='position: absolute; left: 8; padding-left: 8px;'><a href='./index.html'>&larr; Return to Notes</a></span><ul class='menu'></ul></div>\"\n",
        "      scale: 0.5\n",
        "    revealjs-plugins:\n",
        "      - simplemenu\n",
        "  html:\n",
        "    df-print: kable\n",
        "    output-file: \"index.html\"\n",
        "    html-math-method: mathjax\n",
        "    link-external-icon: true\n",
        "    link-external-newwindow: true\n",
        "---\n",
        "\n",
        "\n",
        "::: {.content-visible unless-format=\"revealjs\"}\n",
        "\n",
        "<center>\n",
        "<a class=\"h2\" href=\"./slides.html\" target=\"_blank\">Open slides in new window &rarr;</a>\n",
        "</center>\n",
        "\n",
        ":::\n",
        "\n",
        "# Schedule {.smaller .crunch-title .crunch-callout .code-90 data-name=\"Schedule\"}\n",
        "\n",
        "Today's Planned Schedule:\n",
        "\n",
        "| | Start | End | Topic |\n",
        "|:- |:- |:- |:- |\n",
        "| **Lecture** | 6:30pm | 6:45pm | [TA Intros &rarr;](#ta-intros) |\n",
        "| | 6:45pm | 7:00pm | [HW1 Questions and Concerns &rarr;](#hw1-questions-andor-concerns)\n",
        "| | 7:00pm | 7:30pm | [Motivating Examples: Causal Inference &rarr;](#motivation-ii-causal-inference) |\n",
        "| | 7:30pm | 7:45pm | [Your First Probabilistic Graphical Model! &rarr;](#your-first-probabilistic-graphical-model)\n",
        "| **Break!** | 7:45pm | 8:00pm | |\n",
        "| | 8:00pm | 9:00pm | [PGM \"Lab\" &rarr;](#hidden-markov-models-(hmms-are-our-ur-pgms))\n",
        "\n",
        ": {tbl-colwidths=\"[12,12,12,64]\"}\n",
        "\n",
        "\n",
        "::: {.hidden}"
      ],
      "id": "6e4367e4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cb_palette = [\n",
        "    \"#E69F00\", \"#56B4E9\", \"#009E73\",\n",
        "    \"#F0E442\", \"#0072B2\", \"#D55E00\",\n",
        "    \"#CC79A7\"\n",
        "]"
      ],
      "id": "47701739",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "::: {.hidden}\n",
        "\n",
        "$$\n",
        "\\DeclareMathOperator*{\\argmax}{argmax}\n",
        "\\DeclareMathOperator*{\\argmin}{argmin}\n",
        "\\newcommand{\\bigexp}[1]{\\exp\\mkern-4mu\\left[ #1 \\right]}\n",
        "\\newcommand{\\bigexpect}[1]{\\mathbb{E}\\mkern-4mu \\left[ #1 \\right]}\n",
        "\\newcommand{\\definedas}{\\overset{\\small\\text{def}}{=}}\n",
        "\\newcommand{\\definedalign}{\\overset{\\phantom{\\text{defn}}}{=}}\n",
        "\\newcommand{\\eqeventual}{\\overset{\\text{eventually}}{=}}\n",
        "\\newcommand{\\Err}{\\text{Err}}\n",
        "\\newcommand{\\expect}[1]{\\mathbb{E}[#1]}\n",
        "\\newcommand{\\expectsq}[1]{\\mathbb{E}^2[#1]}\n",
        "\\newcommand{\\fw}[1]{\\texttt{#1}}\n",
        "\\newcommand{\\given}{\\mid}\n",
        "\\newcommand{\\green}[1]{\\color{green}{#1}}\n",
        "\\newcommand{\\heads}{\\outcome{heads}}\n",
        "\\newcommand{\\iid}{\\overset{\\text{\\small{iid}}}{\\sim}}\n",
        "\\newcommand{\\lik}{\\mathcal{L}}\n",
        "\\newcommand{\\loglik}{\\ell}\n",
        "\\DeclareMathOperator*{\\maximize}{maximize}\n",
        "\\DeclareMathOperator*{\\minimize}{minimize}\n",
        "\\newcommand{\\mle}{\\textsf{ML}}\n",
        "\\newcommand{\\nimplies}{\\;\\not\\!\\!\\!\\!\\implies}\n",
        "\\newcommand{\\orange}[1]{\\color{orange}{#1}}\n",
        "\\newcommand{\\outcome}[1]{\\textsf{#1}}\n",
        "\\newcommand{\\param}[1]{{\\color{purple} #1}}\n",
        "\\newcommand{\\pgsamplespace}{\\{\\green{1},\\green{2},\\green{3},\\purp{4},\\purp{5},\\purp{6}\\}}\n",
        "\\newcommand{\\pedge}[2]{\\require{enclose}\\enclose{circle}{~{#1}~} \\rightarrow \\; \\enclose{circle}{\\kern.01em {#2}~\\kern.01em}}\n",
        "\\newcommand{\\pnode}[1]{\\require{enclose}\\enclose{circle}{\\kern.1em {#1} \\kern.1em}}\n",
        "\\newcommand{\\ponode}[1]{\\require{enclose}\\enclose{box}[background=lightgray]{{#1}}}\n",
        "\\newcommand{\\pnodesp}[1]{\\require{enclose}\\enclose{circle}{~{#1}~}}\n",
        "\\newcommand{\\purp}[1]{\\color{purple}{#1}}\n",
        "\\newcommand{\\sign}{\\text{Sign}}\n",
        "\\newcommand{\\spacecap}{\\; \\cap \\;}\n",
        "\\newcommand{\\spacewedge}{\\; \\wedge \\;}\n",
        "\\newcommand{\\tails}{\\outcome{tails}}\n",
        "\\newcommand{\\Var}[1]{\\text{Var}[#1]}\n",
        "\\newcommand{\\bigVar}[1]{\\text{Var}\\mkern-4mu \\left[ #1 \\right]}\n",
        "$$\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.hidden}\n",
        "\n",
        "\n",
        "```{=html}\n",
        "<style>\n",
        ".barrio-jj {\n",
        "  font-family: \"Barrio\", system-ui;\n",
        "  /* font-weight: 400; */\n",
        "  font-style: normal;\n",
        "}\n",
        "</style>\n",
        "```\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "# TA Intros {data-stack-name=\"TA Intros\"}\n",
        "\n",
        "## Courtney Green {.crunch-title .text-90}\n",
        "\n",
        "**Background:** BA in Public Policy & Leadership, now interested in using data to examine structural disparities.\n",
        "\n",
        "**Interests & what I can help with:** How sociodemographic factors (e.g., race, gender, income, immigration status, education level) shape policy outcomes and institutional practices in areas like criminal justice, housing, healthcare, education, and environment.\n",
        "\n",
        "* **Ask me about:** Counterfactual balancing, handling messy or privacy-limited datasets, and framing causal questions around inequality.\n",
        "\n",
        "* Reach out if you're thinking about a final project that touches social systems, systemic inequity, or fairness! \n",
        "\n",
        "## What Got Me Interested in Causal Inference {.crunch-title .text-75}\n",
        "**5000 Project: Over-Policing and Wrongful Convictions in Illinois** \n",
        "\n",
        "* **Motivation:** Explore what demographic factors predict wrongful convictions using real exoneration data.\n",
        "* **Challenge:** No data on ‚Äúnon-exonerated innocents,‚Äù so I (with prof's help) created a counterfactual dataset by sampling from the incarcerated population\n",
        "* **Method:** Trained models (logistic regression, random forest, KNN) on a balanced dataset of 548 exonerated and 548 non-exonerated individuals\n",
        "* **Finding:** Race and geography (esp. Cook Count/Chicago) were the strongest predictors of exoneration\n",
        "* **Takeaway:** Questions about systemic bias can‚Äôt be answered with just descriptive stats, you need counterfactual reasoning and causal inference\n",
        "\n",
        "<span style=\"font-size: 80%;\">[(Optional) View the counterfactual setup](https://crg123.georgetown.domains/projects/dsan-5000/_site/technical-details/data-balancing/main.html)</span>\n",
        "\n",
        "\n",
        "## Wendy Hu {.crunch-title .text-82 .crunch-ul}\n",
        "\n",
        "* **Background:** BS in Social Work, passionate about advancing social equity through computational tools\n",
        "* **Interest:** I bring a background in social welfare, public health, and NGO data, with experience analyzing behavioral and institutional outcomes. My work spans Indigenous health, gender equity, and trauma-informed service design‚Äîalways with a focus on equity, system change, and policy relevance.\n",
        "* **Ask me about:** Framing social justice questions in data terms, working with community or clinical datasets and interpreting model results in context.\n",
        "* If you‚Äôre designing a project around health, inequality, nonprofit impact, or any socially embedded issue‚ÄîI‚Äôd love to help bridge rigor and relevance.\n",
        "\n",
        "## Jeff's HW1 Update/Apology\n",
        "\n",
        "* Basically... I goofed by trying to shove a homework into the first two weeks of class üò≠\n",
        "* Last week was \"setting the table\", so there are a few (multiple-choice) questions on that\n",
        "* But, really only makes sense to have HW starting from **end of today**, once we've introduced **PGMs**, the **language** we need to actually do Causal Computational Social Science!\n",
        "\n",
        "<center>\n",
        "\n",
        "<i class='bi bi-exclamation-triangle'></i> **Due date pushed** to **Friday, June 6, 5:59pm** <i class='bi bi-exclamation-triangle'></i>\n",
        "\n",
        "</center>\n",
        "\n",
        "## HW1 Detail (Plz Don't Hate Me üôà) {.crunch-title .smaller .title-09}\n",
        "\n",
        "*(The main reason this is taking me so long)*\n",
        "\n",
        "* Two key libraries for \"main\" course content (HW2 onwards):\n",
        "  * In R: [`rethinking`](https://github.com/rmcelreath/rethinking), \"lite\" version of [Stan](https://mc-stan.org/)\n",
        "  * In Python: [`PyMC`](https://www.pymc.io/welcome.html)\n",
        "* Both are overkill for current unit: lots of work required to \"turn off\" fancy features and [implement basic PGMs](https://discourse.pymc.io/t/bayes-nets-belief-networks-and-pymc/5150/2)\n",
        "* $\\leadsto$ Only way I know to achieve two goals:\n",
        "  * <i class='bi bi-1-circle'></i> Learning **simple PGMs first**, as tools for **thinking**, before adding in additional full-on **coding** baggage of Stan/PyMC\n",
        "  * <i class='bi bi-2-circle'></i> Having an entire **textbook** on these base PGMs that you can use as reference\n",
        "* Is to use [small, restricted] subset of JavaScript, called [WebPPL](http://webppl.org/), because...\n",
        "\n",
        "\n",
        "<center>\n",
        "\n",
        "[http://probmods.org/](http://probmods.org/){.boxed-cb}\n",
        "\n",
        "</center>\n",
        "\n",
        "# Motivating Examples: Causal Inference {data-stack-name=\"Causal Inference\"}\n",
        "\n",
        "* The *methodology* we'll use to *draw inferences* about social phenomena from data\n",
        "\n",
        "## Disclaimer: Unfortunate Side Effects of Engaging Seriously with Causality {.smaller .crunch-title .title-10 .crunch-p .crunch-img}\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "<i class='bi bi-1-circle'></i> You'll no longer be able to read \"scientific\" writing without striking this expression (involuntarily):\n",
        "\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "<i class='bi bi-2-circle'></i> \"Scientific\" talks will begin to sound like the following:\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        ":::: {layout=\"[5,5]\" layout-valign=\"default\"}\n",
        "::: {#expression}\n",
        "\n",
        "![](images/hrngg.png){fig-align=\"center\" width=\"300\"}\n",
        "\n",
        ":::\n",
        "::: {#looked-at-the-data}\n",
        "\n",
        "\n",
        "{{< video https://jpj.georgetown.domains/dsan5650-scratch/looked_at_the_data.mp4 >}}\n",
        "\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "## Blasting Off Into Causality! {.title-10 .crunch-title .not-title-slide}\n",
        "\n",
        "![](images/posadism_causal.jpg){fig-align=\"center\"}\n",
        "\n",
        "## Data-Generating Processes (DGPs) {.title-09 .text-85 .crunch-title .crunch-ul .crunch-quarto-figure .crunch-quarto-layout-panel .crunch-li-5}\n",
        "\n",
        ":::: {layout=\"[55,45]\" layout-align=\"center\" layout-valign=\"center\"}\n",
        "::: {#dgps-5100}\n",
        "\n",
        "* You saw this in DSAN 5100!\n",
        "* ¬´$X_1, \\ldots, X_n$ drawn i.i.d. Normal, mean $\\mu$ variance $\\sigma^2$¬ª characterizes **DGP of $(X_1, \\ldots, X_n)$**\n",
        "\n",
        ":::\n",
        "\n",
        "![](images/hmm_clusters_single_dist.svg){fig-align=\"center\" width=\"280\"}\n",
        "\n",
        "::::\n",
        "\n",
        "* 5650: **Dive into DGPs**, rather than treating as black box/footnote to Law of Large Numbers, so we can move [*asymptotically!*]...\n",
        "* **From *associational* statements**:\n",
        "  * ¬´$\\underbrace{\\text{An increase}}_{\\small\\text{noun}}$ in $X$ by 1 is associated with increase in $Y$ by $\\beta$¬ª\n",
        "* **To *causal* ones**: ¬´$\\underbrace{\\text{Increasing}}_{\\small\\text{verb}}$ $X$ by 1 *causes* $Y$ to increase by $\\beta$¬ª\n",
        "\n",
        "## DGPs and the Emergence of Order {.crunch-title .crunch-quarto-layout-panel .title-09 .crunch-quarto-figure}\n",
        "\n",
        "::: {layout=\"[1,1]\"}\n",
        "\n",
        "* Who can guess the state of this process after 10 steps, with 1 person?\n",
        "* 10 people? 50? 100? (If they find themselves on the same spot, they stand on each other's heads)\n",
        "* 100 steps? 1000?\n",
        "\n",
        "![](images/random_walk.svg){fig-align=\"center\" width=\"430\"}\n",
        "\n",
        ":::\n",
        "\n",
        "## The Result: 16 Steps\n",
        "\n",
        "![](images/random-walk-16-1.png){fig-align=\"center\"}\n",
        "\n",
        "## The Result: 64 Steps\n",
        "\n",
        "![](images/random-walk-64-1.png){fig-align=\"center\"}\n",
        "\n",
        "## \"Mathematical/Scientific Modeling\" {.smaller .crunch-title .crunch-ul}\n",
        "\n",
        "* Thing we observe (poking out of water): **data**\n",
        "* Hidden but possibly discoverable via deeper dive (ecosystem under surface): **DGP**\n",
        "\n",
        "<!-- My sincere belief and definitely not an image forwarded to me unironically by a family member when I was a tween -->\n",
        "\n",
        "![](images/fwds_from_grandma.jpg){fig-align=\"center\"}\n",
        "\n",
        "## So What's the Problem? {.crunch-title .crunch-ul .crunch-li-8 .inline-90 .text-90}\n",
        "\n",
        "* Non-probabilistic models: High potential for being garbage\n",
        "  * *tldr: even if SUPER certain, using $\\Pr(\\mathcal{H}) = 1-\\varepsilon$ with tiny $\\varepsilon$ has literal life-saving advantages*^[See [Appendix Slide](#appendix-zero-probabilities)] [@finetti_probability_1972]\n",
        "* Probabilistic models: Getting there, still looking at \"surface\"\n",
        "  * Of the $N = 100$ times we observed event $X$ occurring, event $Y$ also occurred $90$ of those times\n",
        "  * $\\implies \\Pr(Y \\mid X) = \\frac{\\#[X, Y]}{\\#[X]} = \\frac{90}{100} = 0.9$\n",
        "* Causal models: Does $Y$ happen **because of** $X$ happening? For that, need to start modeling **what's happening under the surface** making $X$ and $Y$ **\"pop up\" together** so often\n",
        "\n",
        "## The *Shallow* Problem of Causal Inference {.title-08}\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"65%\"}\n",
        "\n",
        "![](images/ski-revenue-lawyers-1.png){fig-align=\"center\"}\n",
        "\n",
        ":::\n",
        "::: {.column width=\"35%\"}\n",
        "\n",
        "``` {.r style=\"font-size: 72%;\"}\n",
        "cor(ski_df$value, law_df$value)\n",
        "```\n",
        "\n",
        "```\n",
        "[1] 0.9921178\n",
        "```\n",
        "\n",
        "::: {style=\"font-size: 50% !important;\"}\n",
        "(Data from Vigen, <a href='http://web.archive.org/web/20191006000802/http://tylervigen.com/view_correlation?id=29272' target='_blank'>Spurious Correlations</a>)\n",
        ":::\n",
        "\n",
        "This, however, is only a *mini-boss*. Beyond it lies the truly invincible **FINAL BOSS**... üôÄ\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "## The *Fundamental* Problem of Causal Inference {.crunch-title .crunch-ul .crunch-callout .title-07}\n",
        "\n",
        "The only workable definition of ¬´$X$ causes $Y$¬ª:\n",
        "\n",
        "::: {.callout-note icon=\"false\" title=\"<i class='bi bi-info-circle pe-1'></i> Defining Causality [@hume_treatise_1739, ruining everything as usual üò§]\"}\n",
        "\n",
        "$X$ causes $Y$ if and only if:\n",
        "\n",
        "1. $X$ *temporally precedes* $Y$ and\n",
        "2. \n",
        "    * In **two worlds** $W_0$ and $W_1$ where\n",
        "    * everything is exactly the same **except that** $X = 0$ in $W_0$ and $X = 1$ in $W_1$,\n",
        "    * $Y = 0$ in $W_0$ and $Y = 1$ in $W_1$\n",
        "\n",
        ":::\n",
        "\n",
        "* The problem? We live in **one** world, not two identical worlds simultaneously üò≠\n",
        "\n",
        "## What Is To Be Done?\n",
        "\n",
        "![](images/face_everything_and_rise.jpg){fig-align=\"center\"}\n",
        "\n",
        "## Probability++ {.crunch-title}\n",
        "  \n",
        "* Tools from prob/stats (RVs, CDFs, Conditional Probability) **necessary but not sufficient** for causal inference!\n",
        "* Example: Say we use DSAN 5100 tools to discover:\n",
        "  * Probability that event $E_1$ occurs is $\\Pr(E_1) = 0.5$\n",
        "  * Probability that $E_1$ occurs **conditional on** another event $E_0$ occurring is $\\Pr(E_1 \\mid E_0) = 0.75$\n",
        "* Unfortunately, we still **cannot** infer that the occurrence of $E_0$ **causes** an increase in the likelihood of $E_1$ occurring.\n",
        "\n",
        "## Beyond Conditional Probability {.crunch-title .text-90}\n",
        "\n",
        "* This issue (that **conditional probabilities** could not be interpreted causally) at first represented a kind of dead end for scientists interested in employing probability theory to study causal relationships...\n",
        "* Recent decades: researchers have built up an additional \"layer\" of modeling tools, augmenting existing machinery of probability to address causality head-on!\n",
        "* @pearl_causality_2000: Formal proofs that ($\\Pr$ axioms) $\\cup$ ($\\textsf{do}$ axioms) $\\Rightarrow$ causal inference procedures successfully recover causal effects\n",
        "\n",
        "## Preview: do-Calculus {.crunch-title .crunch-math .text-85 .table-85 .crunch-ul .inline-90 .math-90 .crunch-li-6}\n",
        "\n",
        "* *Extends* core of probability to incorporate causality, via $\\textsf{do}$ operator\n",
        "* $\\textsf{do}(X = 5)$ is a \"special\" **event**, representing **intervention in DGP** to **force** $X \\leftarrow 5$... $\\textsf{do}(X = 5)$ **not the same event** as $X = 5$!\n",
        "\n",
        "| $X = 5$ | $\\neq$ | $\\textsf{do}(X = 5)$ |\n",
        "|:-:|:-:|:-:|\n",
        "| *Observing* that $X$ took on value 5 (for some possibly-unknown reason) | $\\neq$ | *Intervening* to force $X \\leftarrow 5$, all else in DGP remaining the same (intervention then \"flows\" through rest of DGP) |\n",
        "\n",
        ": {tbl-colwidths=\"[46,2,52]\"}\n",
        "\n",
        "* Probably the most difficult thing in 5650 to wrap head around\n",
        "* \"Special\": $\\Pr(\\textsf{do}(X = 5))$ *not* well-defined, only $\\Pr(Y = 6 \\mid \\textsf{do}(X = 5))$\n",
        "* To emphasize special-ness, we may use notation like:\n",
        "\n",
        "  $$\n",
        "  \\Pr(Y = 6 \\mid \\textsf{do}(X = 5)) \\equiv \\textstyle \\Pr_{\\textsf{do}(X = 5)}(Y = 6)\n",
        "  $$\n",
        "\n",
        "  to avoid confusion with \"normal\" events\n",
        "\n",
        "## Causal World Unlocked üòé (With Great Power Comes Great Responsibility...) {.title-08 .crunch-title .crunch-ul}\n",
        "\n",
        "* With $\\textsf{do}(\\cdot)$ in hand... (Alongside DGP satisfying axioms slightly more strict than core probability axioms)\n",
        "* We *can* make causal inferences from similar pair of facts! If:\n",
        "  * Probability that event $E_1$ occurs is $\\Pr(E_1) = 0.5$,\n",
        "  * The probability that $E_1$ occurs **conditional on** the event $\\textsf{do}(E_0)$ occurring is $\\Pr(E_1 \\mid \\textsf{do}(E_0)) = 0.75$,\n",
        "* **Now** we can actually infer that the occurrence of $E_0$ **caused** an increase in the likelihood of $E_1$ occurring!\n",
        "\n",
        "## Ulysses and the [Computational] Sirens {.smaller .crunch-title}\n",
        "\n",
        "![](images/sirens.jpg){fig-align=\"center\"}\n",
        "\n",
        "# Your First PGM! {.smaller .crunch-title .title-10 .crunch-ul .crunch-li-8 .crunch-quarto-figure .crunch-img .crunch-p data-stack-name=\"PGMs\"}\n",
        "\n",
        "![[Image source](http://probmods.org/chapters/dependence.html)](images/medical.jpg){fig-align=\"center\"}\n",
        "\n",
        "* <i class='bi bi-1-circle'></i> Which of the variables (ovals) are **observed**? Which are **latent**?\n",
        "* <i class='bi bi-2-circle'></i> What do you think the arrows represent?\n",
        "* <i class='bi bi-3-circle'></i> Can we use this to find the **\"root cause\"** of (e.g.) observed **chest pain**? Or conversely, to **predict** possible &uarr; in likelihood of chest pain if we start smoking?\n",
        "\n",
        "## Bayesian Inference but with Pictures {.title-09 .crunch-title .crunch-ul .crunch-li-8 .crunch-callout .text-90 .inline-90}\n",
        "\n",
        "A **Probabilistic Graphical Model (PGM)** provides us with:\n",
        "\n",
        "* A **formal**-mathematical...\n",
        "* But also easily **visualizable** (by construction)...\n",
        "* Representation of a **data-generating process (DGP)!**\n",
        "\n",
        "Example: Let's model how **weather** $W$ affects **evening plans** $Y$: the choice between **going to a party** or **staying in to watch movies**\n",
        "\n",
        "::: {.callout-tip title=\"<i class='bi bi-info-circle'></i> The Partier's Dilemma\" icon=\"false\"}\n",
        "\n",
        "1.  A person $i$ wakes up with some initial affinity for partying: $\\Pr(Y_i = \\textsf{Go})$\n",
        "2.  $i$ then goes to their window and observes the weather $W_i$ outside:\n",
        "    i. If the weather is **sunny**, $i$'s affinity increases: $\\Pr(Y_i = \\textsf{Go} \\mid W_i = \\textsf{Sun}) > \\Pr(Y = \\textsf{Go})$\n",
        "    ii. Otherwise, if it is **rainy**, $i$'s affinity decreases: $\\Pr(Y_i = \\textsf{Go} \\mid W_i = \\textsf{Rain}) < \\Pr(Y = \\textsf{Go})$\n",
        "\n",
        ":::\n",
        "\n",
        "## Two Main \"Building Blocks\" {.crunch-title .title-09 .inline-95 .math-80 .crunch-ul .crunch-math .crunch-li-8 .text-90}\n",
        "\n",
        "* **Nodes** like $\\require{enclose}\\enclose{circle}{\\kern .01em ~X~\\kern .01em}$ denote **Random Variables**\n",
        "\n",
        "$$\n",
        "\\boxed{\\require{enclose}\\enclose{circle}{\\kern .01em ~X~\\kern .01em}} \\simeq \\boxed{ \\begin{array}{c|cc}x & \\textsf{Tails} & \\textsf{Heads} \\\\\\hline \\Pr(X = x) & 0.5 & 0.5\\end{array}}\n",
        "$$\n",
        "\n",
        "* **Edges** like $\\require{enclose}\\enclose{circle}{\\kern .01em ~X~\\kern .01em} \\rightarrow \\; \\enclose{circle}{\\kern.01em Y~\\kern .01em}$ denote **relationships** between RVs\n",
        "  * What an edge \"means\" can get [ontologically] tricky!\n",
        "  * Retain sanity by just remembering: an edge $\\require{enclose}\\enclose{circle}{\\kern .01em ~X~\\kern .01em} \\rightarrow \\; \\enclose{circle}{\\kern.01em Y~\\kern .01em}$ is included in our PGM if we \"care about\" modeling the **conditional probability table (CPT)** of $Y$ w.r.t. $X$\n",
        "\n",
        "$$\n",
        "\\require{enclose}\\boxed{ \\enclose{circle}{\\kern .01em ~X~\\kern .01em} \\rightarrow \\; \\enclose{circle}{\\kern.01em Y~\\kern .01em} } \\simeq \\boxed{\n",
        "  \\begin{array}{c|cc}\n",
        "  x & \\Pr(Y = \\textsf{Lose} \\mid X = x) & \\Pr(Y = \\textsf{Win} \\mid X = x) \\\\\\hline\n",
        "  \\textsf{Tails} & 0.8 & 0.2 \\\\\n",
        "  \\textsf{Heads} & 0.5 & 0.5\n",
        "  \\end{array}\n",
        "}\n",
        "$$\n",
        "\n",
        "## PGM for the Partier's Dilemma {.smaller .crunch-title .crunch-ul .table-90}\n",
        "\n",
        "* A node $\\pnode{W}$ denoting RV $W$, which can take on values in $\\mathcal{R}_W = \\{\\textsf{Sun}, \\textsf{Rain}\\}$,\n",
        "* A node $\\pnode{Y}$ denoting RV $Y$, which can take on values in $\\mathcal{R}_Y = \\{\\textsf{Go}, \\textsf{Stay}\\}$, and \n",
        "* An edge $\\pedge{W}{Y}$ representing the following relationship between $W$ and $Y$:\n",
        "  * $\\Pr(Y = \\textsf{Go} \\mid W = \\textsf{Sun}) = 0.8$\n",
        "  * $\\Pr(Y = \\textsf{Stay} \\mid W = \\textsf{Sun}) = 0.2$\n",
        "  * $\\Pr(Y = \\textsf{Go} \\mid W = \\textsf{Rain}) = 0.1$\n",
        "  * $\\Pr(Y = \\textsf{Stay} \\mid W = \\textsf{Rain}) = 0.9$\n",
        "\n",
        ":::: {layout=\"[1,1]\"}\n",
        "::: {#fig-partier-dgp}\n",
        "\n",
        "![](images/pgm.svg){fig-align=\"center\" width=\"400\"}\n",
        "\n",
        "Our PGM of the Partier's Dilemma\n",
        ":::\n",
        "::: {#fig-partier-cpt}\n",
        "\n",
        "| | $\\Pr(Y = \\textsf{Stay} \\mid W)$ | $\\Pr(Y = \\textsf{Go} \\mid W)$ |\n",
        "|-:|:-:|:-:|\n",
        "| $W = \\textsf{Sun}$ | 0.2 | 0.8 |\n",
        "| $W = \\textsf{Rain}$ | 0.9 | 0.1 |\n",
        "\n",
        "The Conditional Probability Table (CPT) for the edge $\\pedge{W}{Y}$ in @fig-partier-dgp\n",
        ":::\n",
        "::::\n",
        "\n",
        "## Observed vs. Latent Nodes\n",
        "\n",
        "* PGMs help us make **valid (Bayesian) inferences** about the world in the face of **incomplete information**!\n",
        "* Key remaining tool: separation of nodes into two categories:\n",
        "  * **Observed nodes** (shaded)\n",
        "  * **Latent nodes** (unshaded)\n",
        "* $\\Rightarrow$ Can use our PGM as a **weather-inference machine!**\n",
        "* If we **observe** $i$ at a party, what can we infer about the **weather** outside?\n",
        "\n",
        "## Observed Partier, Latent Weather {.title-09}\n",
        "\n",
        "* We can draw this situation as a PGM with **shaded** and **unshaded nodes**, distinguishing what we **know** from what we'd like to **infer**:\n",
        "\n",
        "![](images/pgm_yobs.svg){fig-align=\"center\" width=\"400\"}\n",
        "\n",
        "| | | |\n",
        "|:-:|:-:|:-:|\n",
        "| ‚ùì | &nbsp; | ‚úÖ |\n",
        "\n",
        ": {tbl-colwidths=\"[18,64,18]\"}\n",
        "\n",
        "* And we can now use Bayes' Rule to compute how observed information ($i$ at party $\\Rightarrow [Y = \\textsf{Go}]$) \"flows\" back into $W$\n",
        "\n",
        "## Computation via Bayes' Rule {.smaller .crunch-title .crunch-ul .crunch-math .math-80}\n",
        "\n",
        "* Bayes' Rule, $\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}$, tells us how to use info about $\\Pr(B \\mid A)$ to obtain info about $\\Pr(A \\mid B)$!\n",
        "* We use it to obtain a distribution for $W$ **updated to incorporate** new info $[Y = \\textsf{Go}]$:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "&\\Pr(W = \\textsf{Sun} \\mid Y = \\textsf{Go}) \n",
        "= \\frac{\\Pr(Y = \\textsf{Go} \\mid W = \\textsf{Sun}) \\Pr(W = \\textsf{Sun})}{\\Pr(Y = \\textsf{Go})} \\\\\n",
        "=\\, &\\frac{\\Pr(Y = \\textsf{Go} \\mid W = \\textsf{Sun}) \\Pr(W = \\textsf{Sun})}{\\Pr(Y = \\textsf{Go} \\mid W = \\textsf{Sun}) \\Pr(W = \\textsf{Sun}) + \\Pr(Y = \\textsf{Go} \\mid W = \\textsf{Rain}) \\Pr(W = \\textsf{Rain})}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "* Plug in info from CPT to obtain our new (conditional) probability of interest:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\Pr(W = \\textsf{Sun} \\mid Y = \\textsf{Go}) &= \\frac{(0.8)(0.5)}{(0.8)(0.5) + (0.1)(0.5)} = \\frac{0.4}{0.4 + 0.05} \\approx 0.89\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "* We've learned something interesting! Observing $i$ at the party $\\leadsto$ probability of sun jumps from $0.5$ (**\"prior\"** estimate of $W$, best guess without any other relevant info) to $0.89$ (**\"posterior\"** estimate of $W$, best guess after incorporating relevant info).\n",
        "\n",
        "## References\n",
        "\n",
        "::: {#refs}\n",
        ":::\n",
        "\n",
        "## Appendix: Zero Probabilities {.smaller}\n",
        "\n",
        "From @koller_probabilistic_2009, pp. 66-67:\n",
        "\n",
        "> **Zero probabilities**: A common mistake is to assign a probability of zero to an event that is extremely unlikely, but not impossible. The problem is that one can never condition away a zero probability, no matter how much evidence we get. When an event is unlikely but not impossible, giving it probability zero is guaranteed to lead to irrecoverable errors. For example, in one of the early versions of the the Pathfinder system (box 3.D), **10 percent of the misdiagnoses were due to zero probability estimates given by the expert to events that were unlikely but not impossible.**\n",
        "\n",
        "[&larr; Back to slide](#so-whats-the-problem)"
      ],
      "id": "7742274b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/jpj/.pyenv/versions/3.11.5/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}