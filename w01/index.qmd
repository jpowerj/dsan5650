---
title: "Week 1: Science from Particles to People"
subtitle: "*DSAN 5650: Causal Inference for Computational Social Science*<br><span class='subsubtitle'>Summer 2025, Georgetown University</span>"
author: "Jeff Jacobs"
institute: "[`jj1088@georgetown.edu`](mailto:jj1088@georgetown.edu)"
bibliography: "../_DSAN5650.bib"
date: 2025-05-21
date-format: full
lecnum: 1
categories:
  - "Class Sessions"
format:
  revealjs:
    df-print: kable
    footer: "DSAN 5650 Week 1: {{< var w01.footer >}}"
    output-file: "slides.html"
    html-math-method: mathjax
    scrollable: true
    link-external-icon: true
    link-external-newwindow: true
    theme: [default, "../dsan-globals/jjquarto.scss"]
    include-in-header:
      text: "<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css'><link rel='stylesheet' type='text/css' href='https://cdn.jsdelivr.net/gh/dreampulse/computer-modern-web-font@master/fonts.css'><link rel='preconnect' href='https://fonts.googleapis.com'><link rel='preconnect' href='https://fonts.gstatic.com' crossorigin><link href='https://fonts.googleapis.com/css2?family=Barrio&family=Yuji+Boku&family=Orbitron:wght@400..900&display=swap' rel='stylesheet'>"
    css: "../dsan-globals/jjstyles.css"
    slide-number: true
    simplemenu:
      flat: true
      barhtml:
        header: "<div class='menubar'><span style='position: absolute; left: 8; padding-left: 8px;'><a href='./index.html'>&larr; Return to Notes</a></span><ul class='menu'></ul></div>"
      scale: 0.5
    revealjs-plugins:
      - simplemenu
  html:
    df-print: kable
    output-file: "index.html"
    html-math-method: mathjax
    link-external-icon: true
    link-external-newwindow: true
---

::: {.content-visible unless-format="revealjs"}

<center>
<a class="h2" href="./slides.html" target="_blank">Open slides in new window &rarr;</a>
</center>

:::

# Schedule {.smaller .crunch-title .crunch-callout .code-90 data-name="Schedule"}

Today's Planned Schedule:

| | Start | End | Topic |
|:- |:- |:- |:- |
| **Lecture** | 6:30pm | 6:45pm | [Quick Hello Hi Everyone Style Intro &rarr;](#who-am-i-why-is-georgetown-having-me-teach-this) |
| | 6:45pm | 7:00pm | [[science]{.orbitron-jj} $\leadsto$ [Social Science]{.barrio-jj} "Phase Transition" &rarr;](#the-science.orbitron-jj-leadsto-social-science.barrio-jj-phase-transition) |
| | 7:00pm | 7:25pm | [Motivating Examples I: Social Science &rarr;](#motivation-i-humble-bayesian-social-science) |(#soci) |
| | 7:25pm | 7:50pm | [Motivating Examples II: Causal Inference &rarr;](#motivation-ii-causal-inference) |
| **Break!** | 7:50pm | 8:00pm | |
| | 8:00pm | 8:30pm | [Ulysses and the \[Computational\] Sirens &rarr;]() |
| | 8:30pm | 9:00pm | [Course Logistics &rarr;](#course-logistics) |

: {tbl-colwidths="[12,12,12,64]"}

{{< include ../dsan-globals/_globals-py.qmd >}}

{{< include ../dsan-globals/_globals-tex.qmd >}}

::: {.hidden}

```{=html}
<style>
.orbitron-jj {
  font-family: "Orbitron", sans-serif;
  font-optical-sizing: auto;
  font-style: normal;
}
.barrio-jj {
  font-family: "Barrio", system-ui;
  /* font-weight: 400; */
  font-style: normal;
}
.yuji-boku-jj {
  font-family: "Yuji Boku", serif;
  /* font-weight: 400; */
  font-style: normal;
}
</style>
```

:::

# Who Am I? Why Is Georgetown Having Me Teach This? {data-stack-name="Intro"}

## Prof. Jeff Introduction! {.crunch-title}

* Born in **NW DC** &rarr; high school in **Rockville, MD**
* **University of Maryland**: Computer Science, Math, Econ

![](images/jj_dc_map.png){fig-align="center"}

## The World Outside of DC {.crunch-title}

<i class='bi bi-1-circle'></i> Studied abroad in **Beijing** (Peking University/åŒ—å¤§) &rarr; internship with Huawei in **Hong Kong** (HKUST)

::: {style="float: right; margin-left: 8px"}

![](images/bay_area_crop.png){width="600"}

:::

<i class='bi bi-2-circle'></i> **Stanford**, MS in Computer Science

<i class='bi bi-3-circle'></i> Research Economist, **UC Berkeley**

<i class='bi bi-4-circle'></i> **Columbia**, PhD in Political Economy


## Why Is Georgetown Having Me Teach This? {.smaller .crunch-title .crunch-ul .crunch-li-8 .crunch-quarto-layout-panel .crunch-quarto-figure}

::: {layout="[55,45]" layout-align="center" layout-valign="top"}
::: {#why-background-left}

* Quanty things $\leadsto$ PhD in **Political Economy**
* PhD exam major: **Political Philosophy**
* PhD exam minor: **International Relations**
* PhD exam paper: "How to Do Things with Translations"
* Game-changing Research Fellowships at... (Nothing was the same -drake):
* [Santa Fe Institute](https://en.wikipedia.org/wiki/Santa_Fe_Institute): *dedicated to the multidisciplinary study of complex systems: physical, computational, biological, social*

:::
::: {#fig-background-right}
<center>

```{python}
#| label: bg-sunburst
#| fig-align: center
#| align: center
#| echo: false
import plotly.express as px
import plotly.io as pio
pio.renderers.default = "notebook"
import pandas as pd
year_df = pd.DataFrame({
  'field': ['Math<br>(BS)','CS<br>(BS,MS)','Pol Phil<br>(PhD Pt 1)','Econ<br>(BS+Job)','Pol Econ<br>(PhD Pt 2)'],
  'cat': ['Quant','Quant','Humanities','Social Sci','Social Sci'],
  'yrs': [4, 6, 3, 6, 5]
})
fig = px.sunburst(
    year_df, path=['cat','field'], values='yrs',
    width=450, height=400, color='cat',
    color_discrete_map={'Quant': cb_palette[0], 'Humanities': cb_palette[1], 'Social Sci': cb_palette[2]},
    hover_data=[]
)
fig.update_traces(
   hovertemplate=None,
   hoverinfo='skip'
)
# Update layout for tight margin
# See https://plotly.com/python/creating-and-updating-figures/
fig.update_layout(margin = dict(t=0, l=0, r=0, b=0))
fig.show()
```
</center>

Years spent questing in dungeons of academia
:::
:::

* [Centre for the Study of the History of Political Thought](https://projects.history.qmul.ac.uk/hpt/), Queen Mary University of London (QMUL): *New approaches to the history of political thought [Quentin Skinner, "Cambridge School"] have changed how we study ideas from the past and their relevance to contemporary politics. The focus of the Centre is to explore [ts].*

## Dissertation (NLP x History) {.crunch-title}

*"Our Word is Our Weapon": Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada*

![](images/diss.png){fig-align="center"}

## (IR Part) Wars of Ideas I: Cold War {.smaller .crunch-img}

* Cold War arms shipments (SIPRI) vs. propaganda (*ÐŸÐµÑ‡Ð°Ñ‚ÑŒ Ð¡Ð¡Ð¡Ð *): here, to ðŸ‡ªðŸ‡¹

![](images/eth_arms.svg){fig-align="center"}

## (Middle East Part) Wars of Ideas II: First Intifada, 1987-1993 {.smaller .crunch-title .title-08}

![](images/hamas-unc.jpg){fig-align="center"}

## Research Nowadays

* Most cited paper: "Monopsony in Online Labor Markets" (Uses Double-Debiased ML for Causal Inference!)
* Most recent paper: "Operationalizing Freedom as Non-Domination in the Labor Market" (Cambridge U Press)
* Rarely cited paper but often-thought-about obsession: "How To Do Things With Translations"
* Related thing you can buy in a bookstore: [Editorial board for new translation of] *Capital, Vol. 1* by Karl Marx (Princeton U Press)

## But Now... Teaching! {.smaller}

* Growth mindset: "I can't do this" $\leadsto$ "I can't do this *yet*!"
* Think of anything you're able to do... There was a point in life when you didn't know how to do it! What happened? Your brain **established** and/or **rearranged** neural pathways as you **struggled** with it!
* How does this neural re-arrangement work? One "cheatcode" is **spaced repetition**:

![[Image source](https://www.osmosis.org/learn/Spaced_repetition)](images/forgetting-curve.webp){fig-align="center"}

## Lil Wayne on Spaced Repetition {.smaller .crunch-title .crunch-quarto-figure}

::: {#fig-lilwayne}

{{< video https://jpj.georgetown.domains/ppol6805-scratch/repetition.mp4 >}}

From [The Carter (Documentary)](https://en.wikipedia.org/wiki/The_Carter){target='_blank'}
:::

## Maria Montessori on Your Final Project {.title-09 .aside-05}

> Our teaching should be governed, not by a desire to **make** students learn things, but by the endeavor to **keep burning within them** that light which is called **curiosity**. [@montessori_spontaneous_1916]^[*"Couldn't do classes, them lessons used to bore me, I was tryna school heads like Waldorf and Montessori"* -Bar dropped by local rapper one day in freestyle that I never forgot]

* To this end: your final project is to explore some potential **causal linkage** from $X$ to $Y$ (more later!)
* The sole requirement is: sufficient **curiosity** to serve as **fuel** for your journey from **associational** world to **causal** world

# The [Science]{.orbitron-jj} $\leadsto$ [Social Science]{.barrio-jj} "Phase Transition" {data-stack-name="Science &rarr; Social Science"}

## Coarse-Graining Units of Observation {.smaller .table-85}

```{=html}
<table>
<thead>
<tr>
  <th>Field</th>
  <th colspan="2">Example Unit of Observation</td>
</tr>
</thead>
<tbody>
<tr>
  <td width="20%">Physics</td>
  <td width="30%"><span data-qmd="Particle"></span></td>
  <td width="50%" align="right"><span data-qmd="\[Particle = **Fine-Graining** of Molecules\]"></span></td>
</tr>
<tr>
  <td>Chemistry</td>
  <td><span data-qmd="Molecule = $\cup$(Particles)"></span></td>
  <td><span data-qmd="\[Molecule = **Coarse-Graining** of Particles\]"></span></td>
</tr>
<tr>
  <td>Biology</td>
  <td colspan="2"><span data-qmd="Cell = $\cup$(Molecules)"></span></td>
</tr>
<tr>
  <td>Neuro/Cog Sci</td>
  <td colspan="2"><span data-qmd="Brain = $\cup$(Cells)"></span></td>
</tr>
<tr>
  <td>Human Physiology</td>
  <td colspan="2"><span data-qmd="Body = Brain $\cup$ Other Organs"></span></td>
</tr>
<tr style="border-top: 5px solid #e69f00; border-bottom: 5px solid #e69f00;">
  <td colspan="3" align="center" class='cb1a-bg'><span data-qmd="&uarr; [Science]{.orbitron-jj} &nbsp;&nbsp; ðŸ§ **something happens here...** ðŸ¤” &nbsp;&nbsp; &darr; [Social Science]{.barrio-jj}"></span></td>
</tr>
<tr>
  <td>Anthropology</td>
  <td colspan="2"><span data-qmd="Human-Relational System (e.g., Kinship) = $\cup$(Brains) $\times$ Natural Environment"></span></td>
</tr>
<tr>
  <td>Economics</td>
  <td colspan="2"><span data-qmd="Economy = Specific relational system of *exchange* w.r.t. scarce resources"></span></td>
</tr>
<tr>
  <td>Political Economy</td>
  <td colspan="2"><span data-qmd="Economy-Context = Economic Exchange $\cap$ Relational Power"></span></td>
</tr>
<tr>
  <td>Sociology</td>
  <td colspan="2"><span data-qmd="Society = $\cup$(Relational Systems: Kinship, Friendship, Authority, Power, Violence)"></span></td>
</tr>
<tr>
  <td>History</td>
  <td colspan="2"><span data-qmd="[*Longue-DurÃ©e*](https://en.wikipedia.org/wiki/Longue_dur%C3%A9e) = Evolution of Societies over Time and Space"></span></td>
</tr>
</tbody>
</table>
```

## *Homo sapiens*/*Homo arbitratus*/*Homo mischievous* {.title-08 .crunch-title .crunch-ul}

* Latin [*sapiens*](https://en.wiktionary.org/wiki/sapiens#Latin) denotes being "discerning" or "wise"

:::: {layout="[66,34]" layout-valign="center"}
::: {#homo-mischief}

* But... technically nothing stops us from **choosing** to be "unwise" whenever we'd like... bc **free will**
* $\Rightarrow$ For this class, humans are *Homo arbitratus*: [*arbitratus*](https://en.wiktionary.org/wiki/arbitratus#Latin) denotes **choosing** what to do, after we've sapiently "discerned"/thought about it

:::
::: {#mischievous}

![](images/mood_crop.jpg){fig-align="center" width="300"}

:::
::::

## Laws of Physics vs. "Laws" of Social Science {.title-08 .crunch-title .crunch-ul .crunch-quarto-figure .aside-05 .crunch-li-8}

* If we tell an inanimate object that we've discovered a **law** saying that it will accelerate towards Earth at $9.8~\textrm{m}/\textrm{s}^2$
  * ...It will likely^[Obligatory quantum mechanics footnote: human agency [maybe] plays a role, in a quirky way, in physics at tiny subatomic scales... but once we **coarse grain** to atoms (and avoid speed of light), Newton's Laws accurate to many decimals ðŸ¤¯] still accelerate towards Earth at $9.8~\textrm{m}/\textrm{s}^2$

:::: {layout="[70,30]"}
::: {#human-law}

* If we tell a **human** we've discovered a **law** saying they will quack like a duck at 7:30pm EDT every Wednesday
  * ...They can utilize their **free will** to violate this "law"

:::
::: {#cause-problems}

![](images/cause_problems.jpg){fig-align="center"}

:::
::::

## Strangely-Relevant CS Topic: The Halting Problem {.smaller .title-09 .table-75 .crunch-title .crunch-ul .crunch-li-8}

* Kurt GÃ¶del $\leftrightarrow$ Alan Turing: [*Entscheidungsproblem*](https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf)
* **Theorem**: It is not possible to write a computer program $P(x)$ that detects whether or not a computer program $x$ will eventually halt (as opposed to, e.g., looping forever)
* **Proof**: Assume $P(x)$ *is* possible to write. Run it on `mischievous_program.py`. Infinite contradiction loop.

:::: {.columns}
::: {.column width="60%"}

``` {.python filename="halting_problem_solver.py" style="margin-bottom: 25px;"}
def will_it_halt(program, input):
  # Put code you think will work here
  # Return True if program will halt, False otherwise
```

``` {.python filename="mischievous_program.py"}
def my_mischievous_function(input):
  if will_it_halt(my_mischevious_function, input):
    while True: pass # Infinite loop
  else:
    return # Halt
```

:::
::: {.column width="40%"}

```{=html}
<center>

<table>
<thead>
<tr>
  <th><span data-qmd="Input&rarr;<br>&darr;Program"></span></th>
  <th align="center">0</th>
  <th align="center">1</th>
  <th align="center">2</th>
  <th align="center"><span data-qmd="$\cdots$"></span></th>
</tr>
</thead>
<tbody>
<tr>
  <td>0</td>
  <td class='cb1a-bg' align="center"><span data-qmd="**Halt**"></span></td>
  <td align="center">Loop</td>
  <td align="center">Loop</td>
  <td align="center"><span data-qmd="$\cdots$"></span></td>
</tr>
<tr>
  <td>1</td>
  <td>Loop</td>
  <td class='cb1a-bg'><span data-qmd="**Loop**"></span></td>
  <td>Halt</td>
  <td><span data-qmd="$\cdots$"></span></td>
</tr>
<tr>
  <td>2</td>
  <td>Loop</td>
  <td>Loop</td>
  <td class='cb1a-bg'><span data-qmd="**Loop**"></span></td>
  <td><span data-qmd="$\cdots$"></span></td>
</tr>
<tr>
  <td><span data-qmd="$\vdots$"></span></td>
  <td><span data-qmd="$\vdots$"></span></td>
  <td><span data-qmd="$\vdots$"></span></td>
  <td><span data-qmd="$\vdots$"></span></td>
  <td class='cb1a-bg'><span data-qmd="$\mathbf{\ddots}$"></span></td>
</tr>
<tr style="border-top: 3px solid black;">
  <td align="center"><span data-qmd="![](images/mood_face.jpg){width='50'}"></span></td>
  <td class='cb1a-bg' style="vertical-align: middle;"><span data-qmd="**Loop**"></span></td>
  <td class='cb1a-bg' style="vertical-align: middle;"><span data-qmd="**Halt**"></span></td>
  <td class='cb1a-bg' style="vertical-align: middle;"><span data-qmd="**Halt**"></span></td>
  <td class='cb1a-bg' style="vertical-align: middle;"><span data-qmd="$\mathbf{\cdots}$"></span></td>
</tr>
</tbody>
</table>

</center>
```

:::
::::

## The Takeaway: [Bayesian] Humility! {.crunch-title .title-09 .crunch-ul .crunch-li-8 .aside-05 .text-90}

* Social [science]{.orbitron-jj}, with ["science"]{.orbitron-jj} used in the same sense as for physics, may be a quixotic endeavor^[At least, for the time being... BUT see @sperber_explaining_1996, which will come up later]
* Instead, we'll do [**social science**]{.barrio-jj}, where we use data to...
* <i class='bi bi-1-circle'></i> Infer **tendencies**: $\mathcal{H}$ = Â«$X$ tends to cause $Y$Â»
* <i class='bi bi-2-circle'></i> With some degree of **veracity**: $\Pr(\mathcal{H}) \approx 0.7$
* <i class='bi bi-3-circle'></i> Construct models that we can **update** with **new evidence**: Bayes' rule! $\Pr(\mathcal{H} \mid E) = \frac{\Pr(E \mid \mathcal{H} ) \Pr(\mathcal{H})}{\Pr(E)} \approx 0.8$
* Pls notice "slippage" between **aleatory probability** *within* $\mathcal{H}$ ("tends to") vs. **epistemic probability** "outside of", talking *about* $\mathcal{H}$ ("I'm 70\% confident about $\mathcal{H}$")

# Motivation I: Humble-Bayesian Social Science

## The Logic of Violence in Civil War

## Particularly Fun Non-"Standard" Examples

* DeDeo, French Revolution
* Grimmer, Mirrors for Sultans and Princes

# Motivation II: Causal Inference {data-stack-name="Causal Inference"}

* The *methodology* we'll use to *draw inferences* about social phenomena from data

## Disclaimer: Unfortunate Side Effects of Engaging Seriously with Causality {.smaller .crunch-title .title-10 .crunch-p .crunch-img}

:::: {.columns}
::: {.column width="50%"}

<i class='bi bi-1-circle'></i> You'll no longer be able to read "scientific" writing without striking this expression (involuntarily):

:::
::: {.column width="50%"}

<i class='bi bi-2-circle'></i> "Scientific" talks will begin to sound like the following:

:::
::::

:::: {layout="[5,5]" layout-valign="default"}
::: {#expression}

![](images/hrngg.png){fig-align="center" width="300"}

:::
::: {#looked-at-the-data}

{{< video https://jpj.georgetown.domains/dsan5650-scratch/looked_at_the_data.mp4 >}}

:::
::::

## Blasting Off Into Causality! {.title-10 .crunch-title .not-title-slide}

![](images/posadism_causal.jpg){fig-align="center"}

## Data-Generating Processes (DGPs) {.title-09 .text-85 .crunch-title .crunch-ul .crunch-quarto-figure .crunch-quarto-layout-panel .crunch-li-5}

:::: {layout="[55,45]" layout-align="center" layout-valign="center"}
::: {#dgps-5100}

* You saw this in DSAN 5100!
* Â«$X_1, \ldots, X_n$ drawn i.i.d. Normal, mean $\mu$ variance $\sigma^2$Â» characterizes **DGP of $(X_1, \ldots, X_n)$**

:::

![](images/hmm_clusters_single_dist.svg){fig-align="center" width="280"}

::::

* 5650: **Dive into DGPs**, rather than treating as black box/footnote to Law of Large Numbers, so we can move [*asymptotically!*]...
* **From *associational* statements**:
  * Â«$\underbrace{\text{An increase}}_{\small\text{noun}}$ in $X$ by 1 is associated with increase in $Y$ by $\beta$Â»
* **To *causal* ones**: Â«$\underbrace{\text{Increasing}}_{\small\text{verb}}$ $X$ by 1 *causes* $Y$ to increase by $\beta$Â»

## DGPs and the Emergence of Order {.crunch-title .crunch-quarto-layout-panel .title-09 .crunch-quarto-figure}

::: {layout="[1,1]"}

* Who can guess the state of this process after 10 steps, with 1 person?
* 10 people? 50? 100? (If they find themselves on the same spot, they stand on each other's heads)
* 100 steps? 1000?

![](images/random_walk.svg){fig-align="center" width="430"}

:::

## The Result: 16 Steps

![](images/random-walk-16-1.png){fig-align="center"}

## The Result: 64 Steps

![](images/random-walk-64-1.png){fig-align="center"}

## "Mathematical/Scientific Modeling" {.smaller .crunch-title .crunch-ul}

* Thing we observe (poking out of water): **data**
* Hidden but possibly discoverable via deeper dive (ecosystem under surface): **DGP**

<!-- My sincere belief and definitely not an image forwarded to me unironically by a family member when I was a tween -->

![](images/fwds_from_grandma.jpg){fig-align="center"}

## So What's the Problem? {.crunch-title .crunch-ul .crunch-li-8 .inline-90}

* Non-probabilistic models: High potential for being garbage
  * *tldr: even if SUPER certain, using $\Pr(\mathcal{H}) = 1-\varepsilon$ with tiny $\varepsilon$ has literal life-saving advantages* [@finetti_probability_1972]
* Probabilistic models: Getting there, still looking at "surface"
  * Of the $N = 100$ times we observed event $X$ occurring, event $Y$ also occurred $90$ of those times
  * $\implies \Pr(Y \mid X) = \frac{\#[X, Y]}{\#[X]} = \frac{90}{100} = 0.9$
* Causal models: Does $Y$ happen **because of** $X$ happening? For that, need to start modeling **what's happening under the surface** making $X$ and $Y$ **"pop up" together** so often

## The *Shallow* Problem of Causal Inference {.title-08}

:::: {.columns}
::: {.column width="65%"}

![](images/ski-revenue-lawyers-1.png){fig-align="center"}

:::
::: {.column width="35%"}

``` {.r style="font-size: 72%;"}
cor(ski_df$value, law_df$value)
```

```
[1] 0.9921178
```

::: {style="font-size: 50% !important;"}
(Data from Vigen, <a href='http://web.archive.org/web/20191006000802/http://tylervigen.com/view_correlation?id=29272' target='_blank'>Spurious Correlations</a>)
:::

This, however, is only a *mini-boss*. Beyond it lies the truly invincible **FINAL BOSS**... ðŸ™€

:::
::::

## The *Fundamental* Problem of Causal Inference {.crunch-title .crunch-ul .crunch-callout .title-07}

The only workable definition of Â«$X$ causes $Y$Â»:

::: {.callout-note icon="false" title="<i class='bi bi-info-circle pe-1'></i> Defining Causality [@hume_treatise_1739, ruining everything as usual ðŸ˜¤]"}

$X$ causes $Y$ if and only if:

1. $X$ *temporally precedes* $Y$ and
2. 
    * In **two worlds** $W_0$ and $W_1$ where
    * everything is exactly the same **except that** $X = 0$ in $W_0$ and $X = 1$ in $W_1$,
    * $Y = 0$ in $W_0$ and $Y = 1$ in $W_1$

:::

* The problem? We live in **one** world, not two identical worlds simultaneously ðŸ˜­

## What Is To Be Done?

![](images/face_everything_and_rise.jpg){fig-align="center"}

## Probability++ {.crunch-title}
  
* Tools from prob/stats (RVs, CDFs, Conditional Probability) **necessary but not sufficient** for causal inference!
* Example: Say we use DSAN 5100 tools to discover:
  * Probability that event $E_1$ occurs is $\Pr(E_1) = 0.5$
  * Probability that $E_1$ occurs **conditional on** another event $E_0$ occurring is $\Pr(E_1 \mid E_0) = 0.75$
* Unfortunately, we still **cannot** infer that the occurrence of $E_0$ **causes** an increase in the likelihood of $E_1$ occurring.

## Beyond Conditional Probability {.crunch-title .text-90}

* This issue (that **conditional probabilities** could not be interpreted causally) at first represented a kind of dead end for scientists interested in employing probability theory to study causal relationships...
* Recent decades: researchers have built up an additional "layer" of modeling tools, augmenting existing machinery of probability to address causality head-on!
* @pearl_causality_2000: Formal proofs that ($\Pr$ axioms) $\cup$ ($\textsf{do}$ axioms) $\Rightarrow$ causal inference procedures successfully recover causal effects

## Preview: do-Calculus {.crunch-title .crunch-math .text-85 .table-85 .crunch-ul .inline-90 .math-90 .crunch-li-6}

* *Extends* core of probability to incorporate causality, via $\textsf{do}$ operator
* $\textsf{do}(X = 5)$ is a "special" **event**, representing **intervention in DGP** to **force** $X \leftarrow 5$... $\textsf{do}(X = 5)$ **not the same event** as $X = 5$!

| $X = 5$ | $\neq$ | $\textsf{do}(X = 5)$ |
|:-:|:-:|:-:|
| *Observing* that $X$ took on value 5 (for some possibly-unknown reason) | $\neq$ | *Intervening* to force $X \leftarrow 5$, all else in DGP remaining the same (intervention then "flows" through rest of DGP) |

: {tbl-colwidths="[46,2,52]"}

* Probably the most difficult thing in 5650 to wrap head around
* "Special": $\Pr(\textsf{do}(X = 5))$ *not* well-defined, only $\Pr(Y = 6 \mid \textsf{do}(X = 5))$
* To emphasize special-ness, we may use notation like:

  $$
  \Pr(Y = 6 \mid \textsf{do}(X = 5)) \equiv \textstyle \Pr_{\textsf{do}(X = 5)}(Y = 6)
  $$

  to avoid confusion with "normal" events

## Causal World Unlocked ðŸ˜Ž (With Great Power Comes Great Responsibility...) {.title-08 .crunch-title .crunch-ul}

* With $\textsf{do}(\cdot)$ in hand... (Alongside DGP satisfying axioms slightly more strict than core probability axioms)
* We *can* make causal inferences from similar pair of facts! If:
  * Probability that event $E_1$ occurs is $\Pr(E_1) = 0.5$,
  * The probability that $E_1$ occurs **conditional on** the event $\textsf{do}(E_0)$ occurring is $\Pr(E_1 \mid \textsf{do}(E_0)) = 0.75$,
* **Now** we can actually infer that the occurrence of $E_0$ **caused** an increase in the likelihood of $E_1$ occurring!

# Ulysses and the [Computational] Sirens

## 

# Course Logistics {data-stack-name="Logistics"}

## Meta-Logistics: Spaced Repetition

## Meta-Logistics: Maria Montessori and Your Final Projects

## Your Final Projects

## JupyterHub

[https://guhub.io](https://guhub.io)

## Assignments / Midterm

## References

::: {#refs}
:::
