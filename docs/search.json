[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Morgan and Winship, Counterfactuals and Causal Inference: Methods and Principles for Social Research (Morgan and Winship 2015) [PDF]\n\nThe book which comes closest to being an all-encompassing, single textbook for the class. It brings together different “strands” of causal modeling research (since each field—economics, bioinformatics, sociology, etc.—tends to use its own notation and vocabulary), unifying them into a single approach. The only reason we can’t use it as the main textbook is because it hasn’t been updated since 2015, and most of the assignments in this class use computational tools from 2018 onwards!\n\nAngrist and Pischke, Mastering ’Metrics: The Path from Cause to Effect (Angrist and Pischke 2014) [PDF]\n\nThis book is included as the second of the three “core” texts mainly because, it uses the language of causality specific to Econometrics, the language that is most familiar to me from my PhD training in Political Economy. However, if you tend to learn better by example, it also does a good job of foregrounding specific examples (like evaluating charter schools and community policing policies), so that the methods emerging naturally from attempts to solve these puzzles when association methods like linear regression fail to capture their causal linkages.\n\nPearl and Mackenzie, The Book of Why: The New Science of Cause and Effect (Pearl and Mackenzie 2018) [EPUB]\n\nThis book contrasts with the Angrist and Pischke book in using the language of causality formed within Computer Science rather than Economics. It can be a good starting point especially if you’re unfamiliar with the heavy use of diagrams for scientific modeling—basically, whereas Angrist and Pischke’s first instinct is to use (sometimes informal) equations like \\(y = mx + b\\) to explain steps in the procedures, Pearl and Mackenzie’s instinct would be to instead use something like \\(\\require{enclose}\\enclose{circle}{\\kern .01em ~x~\\kern .01em} \\overset{\\small m, b}{\\longrightarrow} \\enclose{circle}{\\kern.01em y~\\kern .01em}\\) to represent the same concept (in this case, a line with slope \\(m\\) and intercept \\(b\\)!).",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#core-textbooks",
    "href": "resources.html#core-textbooks",
    "title": "Resources",
    "section": "",
    "text": "Morgan and Winship, Counterfactuals and Causal Inference: Methods and Principles for Social Research (Morgan and Winship 2015) [PDF]\n\nThe book which comes closest to being an all-encompassing, single textbook for the class. It brings together different “strands” of causal modeling research (since each field—economics, bioinformatics, sociology, etc.—tends to use its own notation and vocabulary), unifying them into a single approach. The only reason we can’t use it as the main textbook is because it hasn’t been updated since 2015, and most of the assignments in this class use computational tools from 2018 onwards!\n\nAngrist and Pischke, Mastering ’Metrics: The Path from Cause to Effect (Angrist and Pischke 2014) [PDF]\n\nThis book is included as the second of the three “core” texts mainly because, it uses the language of causality specific to Econometrics, the language that is most familiar to me from my PhD training in Political Economy. However, if you tend to learn better by example, it also does a good job of foregrounding specific examples (like evaluating charter schools and community policing policies), so that the methods emerging naturally from attempts to solve these puzzles when association methods like linear regression fail to capture their causal linkages.\n\nPearl and Mackenzie, The Book of Why: The New Science of Cause and Effect (Pearl and Mackenzie 2018) [EPUB]\n\nThis book contrasts with the Angrist and Pischke book in using the language of causality formed within Computer Science rather than Economics. It can be a good starting point especially if you’re unfamiliar with the heavy use of diagrams for scientific modeling—basically, whereas Angrist and Pischke’s first instinct is to use (sometimes informal) equations like \\(y = mx + b\\) to explain steps in the procedures, Pearl and Mackenzie’s instinct would be to instead use something like \\(\\require{enclose}\\enclose{circle}{\\kern .01em ~x~\\kern .01em} \\overset{\\small m, b}{\\longrightarrow} \\enclose{circle}{\\kern.01em y~\\kern .01em}\\) to represent the same concept (in this case, a line with slope \\(m\\) and intercept \\(b\\)!).",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#econometric-policy-evaluation",
    "href": "resources.html#econometric-policy-evaluation",
    "title": "Resources",
    "section": "Econometric Policy Evaluation",
    "text": "Econometric Policy Evaluation\n\n(bjorkegren_machine_2022?), “(Machine) Learning what Policymakers Value”, EAAMO (Equity and Access in Algorithms, Mechanisms, and Optimization) [PDF]",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "midterm.html",
    "href": "midterm.html",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "",
    "text": "The DSAN 5450 in-class midterm will start at 3:30pm on Wednesday, February 26th. It is intended to take only 1.5 hours, but you will have 3 hours to take it just in case, so that it will be due by 6:30pm.\nWe’ve covered a lot of… sometimes-disjointed topics thus far, so our goal for the midterm is to emphasize the most important takeaways from across the first six weeks of the class, by putting them in your brain’s short-term memory one more time before we dive into the second, policy-focused half of the course when you come back from spring break! As a reminder, there is a very good reason to continually try and re-remember the same course topics, coming from studies of long-term memory retention:"
  },
  {
    "objectID": "midterm.html#overview",
    "href": "midterm.html#overview",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "",
    "text": "The DSAN 5450 in-class midterm will start at 3:30pm on Wednesday, February 26th. It is intended to take only 1.5 hours, but you will have 3 hours to take it just in case, so that it will be due by 6:30pm.\nWe’ve covered a lot of… sometimes-disjointed topics thus far, so our goal for the midterm is to emphasize the most important takeaways from across the first six weeks of the class, by putting them in your brain’s short-term memory one more time before we dive into the second, policy-focused half of the course when you come back from spring break! As a reminder, there is a very good reason to continually try and re-remember the same course topics, coming from studies of long-term memory retention:"
  },
  {
    "objectID": "midterm.html#part-1-high-level-data-ethics-considerations",
    "href": "midterm.html#part-1-high-level-data-ethics-considerations",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 1: High-Level Data Ethics Considerations",
    "text": "Part 1: High-Level Data Ethics Considerations\nThis part corresponds roughly to the first two sessions of the course, where we talked about key “high-level” questions in data ethics.\n\n(1.1) The Library of Missing Datasets\nWhy does some information already exist in the form of nicely-formatted, easily-accessible datasets, while other information does not?\n\nHere the specific reference in class was to the Library of Missing Datasets, so you can check out the photos at that link for examples of missing datasets.\nThe midterm question here could, therefore, ask you to think through the process by which a certain dataset came into existence as (e.g.) a clean, easily-available .csv file, and/or why another set of data might not exist in this form.\n\n\n\n(1.2) Operationalization\nWhat types of data-ethical issues arise because of the “gap” between conceptual variables and operationalized variables?\n\nHere the main reference for you is this slide from Week 2\nFor the possible midterm question here, specifically, you should focus on the idea behind the book on the right side of that slide: “Mis-Measuring Our Lives”. That book points out the gap between the conceptual variable [economic well-being] and its operationalization as [GDP].\n\nSo, for the midterm, we might ask you to consider a conceptual variable like “fairness” or “privacy”, and think through different ways they could be operationalized as measurable quantities."
  },
  {
    "objectID": "midterm.html#part-2-ethical-frameworks",
    "href": "midterm.html#part-2-ethical-frameworks",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 2: Ethical Frameworks",
    "text": "Part 2: Ethical Frameworks\n\n(2.1) Descriptive vs. Normative\nI think you all did a great job of demonstrating that you understand this distinction, through homeworks and discussions (in class and in office hours)! So, on this topic I think you can just review the basic “gist” of how this works:\nTwo types of Descriptive statements:\n\nNon-implicational statements that describe facts, like \\(1 + 1 = 2\\), are descriptive but indeterminate without a set of axioms (definitions for the symbols, in this case)\nImplicational statements that describe facts, like \\(ZFC \\implies 1 + 1 = 2\\), are descriptive and also determinate (in this case, determinately true)\n\nTwo types of Normative statements:\n\nWhen the statements are not descriptions of empirically/observationally (and intersubjectively) verifiable predicates about how things are (“Grass is green”), but are instead prescriptions of how things ought to be (“Grass ought to be green”/“It is good for grass to be green and bad for grass to be blue”), they have additional normative dimensions\nHowever, in the same way that the descriptive statement \\(1 + 1 = 2\\) goes from indeterminate to determine when we provide a set of axioms, normative statements are also transformed from indeterminate to determinate when we provide an ethical framework within which the normative statement can be evaluated.\n\n\n\n(2.2) Consequentialism vs. Deontological Ethics\nThis portion would also very much involve the two most common concrete versions of these two ethical frameworks:\n\nUtilitarianism as the most common consequentialist framework\nKantian Ethics as the most common deontological-ethical framework\n\nOn the latter two points specifically, I didn’t make the distinction as clearly as I should have in class, so I’m making it here!\nQuestion 2.5 from Homework 1 provided the following statement:\n\n«Lying is bad, since you wouldn’t want others to lie to you.»\n\nAnd then, between Consequentialism and Deontological Ethics, the correct answer was that this statement is more straightforwardly implied by Deontological Ethics. I know this one is particularly difficult to think through, but I wanted to highlight it here because this is the question that really reveals the subtle-but-important distinction between these two systems:\n\nA consequentialist approach to “resolving” a dilemma around lying would, crucially, be based on a prediction of the actual consequences that would result from a possible choice, whereas\nA deontological approach differs from this in considering what makes a possible choice good or bad in-and-of-itself, without reference to the predicted consequences.\n\nThe reason I phrase the distinction in this way is because, in the above statement, you can focus on the portion after the word “since” (“since you wouldn’t want others to lie to you”):\n\nWithin a consequentialist framework, this reasoning would not itself constitute a justification for not lying, since it would have to be paired with a statement like “If I lie, then it is likely that others will lie to me”, which is not true in general! The idiom of a “white lie”, for example, comes precisely from the fact that there are often times when we feel like we should lie to people to avoid the consequence of hurting them.\nWithin a deontological framework, on the other hand, this reasoning would constitute a justification for not lying, since it corresponds precisely to the rule that was mentioned in the prior two questions: Kant’s Categorical Imperative.\nThis Categorical Imperative rule is of special interest, relative to the full set of “ethical rules” you could imagine using, because it is a rule for making ethical decisions without reference to the consequences of a particular choice:\n\nInstead of predicting what might happen if I make this choice, and judging whether it is an ethical choice on that basis…\nI now imagine what would happen hypothetically if everyone else in the world made the choice, whether or not my action would in fact make everyone else in the world make the same choice!\n\n\nI hope that explanation, and the reference to “white lies” as an example, can help make it more clear why the answer to Question 2.5 was “Deontological Ethics”. As one final point, to make it super concrete:\n\nThe reason why the answer is not Consequentialism here is because, a Consequentialist might agree that “I wouldn’t want others to lie to me”, and yet also think “But that’s not a good reason to not lie, since I could lie here without it causing others to lie to me.”\nThat is what would enable “white lies” to be acceptable under consequentialism: since you only consider the predicted consequences of your action in the “real world”, rather than in a hypothetical world where everyone does the same action, you are then able to move to a comparison of whether the benefits of lying outweigh the costs of lying, as one way to make the decision (by “calculating” the consequences!)."
  },
  {
    "objectID": "midterm.html#part-3-context-free-fairness-and-proxy-variables",
    "href": "midterm.html#part-3-context-free-fairness-and-proxy-variables",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 3: Context-Free Fairness and Proxy Variables",
    "text": "Part 3: Context-Free Fairness and Proxy Variables\nHere the main idea will be to think through the fairness definitions introduced in this part:\n\nFairness Through Unawareness (Removing “sensitive” variables from the dataset)\nFairness as Equalized Positive Rate\nFairness as Equalized False Positive Rate\nFairness as Equalized False Negative Rate\nFairness as Calibration\n\nAnd especially to be able to understand the “simple” cases when these might work, but also the non-simple cases where these fail to capture what we’d like a robust / actually-usable fairness measure to capture. Some straightforward questions to guide you in this thinking for this part would be, e.g.:\n\nCan we have all of these measures at once?\n\nShort answer: No. But, you should also have some degree of intuition from class about why we can’t (the impossibility results)\n\nThe first four are probably more straightforward, as things we can achieve by dropping variables (Unawarness) or by reading the entries in a confusion matrix. Calibration, however, requires a bit more thought:\n\nHow is calibration defined? The most succinct definition would just be: the requirement that the value of the risk score \\(r(X)\\) that “underlies” the decision-making algorithm (in that it is used to produce our predictions \\(\\widehat{Y}\\)) is itself a probability value—namely, the probability that a person with attributes \\(X\\) has associated outcome \\(Y\\).\nWhy is calibration desirable? Why does it help us in terms of assessing fairness? The definition in the previous bullet point is not very easy-to-understand (to me, at least), so that I interpret it as just a requirement that the risk score “tracks” the relationship between \\(X\\) and \\(Y\\) in a direct way: for example, high values of \\(\\Pr(Y \\mid X)\\) mean high values of the underlying representation \\(r(X)\\) that is used to generate \\(\\widehat{Y}\\) as a prediction of \\(Y\\).\nViewed in this way, then, I hope it makes sense that this property would be desirable in terms of interpretability: it means that, if we wanted to know why our prediction algorithm was producing some specific prediction \\(\\widehat{Y}_i\\) for a person with attributes \\(X_i\\), we could “open up the black box” of the algorithm and look directly at the risk score \\(r(X_i)\\) with respect to the risk score function \\(r(\\cdot)\\) in general, to see why it produced such a high/low value of \\(\\widehat{Y}_i\\).\nI know even that last point can still be confusing, so to me the final “piece” for understanding is to think about how: if we didn’t have calibration, then we would have no natural way of interpreting the risk function \\(r(\\cdot)\\). Since without calibration it is not constrained to represent a probability, it could take on any value—\\(\\pi\\), \\(-1000\\), \\(\\sqrt{2^{100}}\\)—and we would have no way of knowing the relationship between these values and the resulting predictions \\(\\widehat{Y}\\); no way of knowing, for example, why plugging in a person with characteristics \\(X_i\\) produced \\(r(X_i) = \\pi\\) which then led to the prediction \\(\\widehat{Y}_i = 1\\), to detain this person until trial!"
  },
  {
    "objectID": "midterm.html#part-4-context-sensitive-fairness",
    "href": "midterm.html#part-4-context-sensitive-fairness",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 4: Context-Sensitive Fairness",
    "text": "Part 4: Context-Sensitive Fairness\nWe spent some amount of time critiquing the fairness definitions mentioned in the previous section. This was not for the sake of judging whether they’re “good” or “bad” as such, but rather, for the sake of understanding specifically what they’re missing. Two different characterizations of what they’re missing give us our two key context-sensitive approaches to fairness, discussed in the next two sections:\n\n(4.1) Individual-Similarity-Based Fairness\n\nThe Context-Free measures fail to consider how satisfying a criterion (e.g., Equalized False Positive Rate) at a group level could trample over the rights of individuals.\n\nThe illustration of this failure that I mentioned in class boiled down to:\n\nLet \\(A_i\\) represent a sensitive attribute of individuals, such that \\(A_i = 0\\) if person \\(i\\) is white, and \\(A_i = 1\\) if person \\(i\\) is black.\nIf a police department finds itself failing to satisfy a fairness criterion like Equality of Positive Rates, in the sense that their arrest rate \\(r_1\\) for individuals with \\(A_i = 1\\) is higher than their arrest rate \\(r_0\\) for individuals with \\(A_i = 0\\), then…\nThey can quickly “resolve” this failure and satisfy the criterion by running outside and arresting the first \\(N\\) white people they see, where \\(N\\) is the number of additional white arrestees that would be necessary to make \\(r_0 = r_1\\).\n\nHowever, as this illustration hopefully makes clear, this procedure would allow satisfaction of the group-level fairness criterion, but only at the expense of violating our intuitive notions of fairness towards individuals.\nAlthough there are lots and lots of ways that this notion of individual-level fairness could be incorporated into the Context-Free fairness measures to make them Context-Sensitive, one of the most popular and straightforward ways is by constructing an indiviudal-similarity-based fairness measure, and then using it to constrain the space of possible decisions by enforcing the rule that:\n\n\n\n\n\n\nFairness Through Awareness (dwork_fairness_2011?)\n\n\n\nIndividuals who are similar with respect to a task should be classified similarly.\n\n\nThe first thing I want you to note about this approach is that it specifically aims to resolve the issue we’ve already seen with utilitarianism, namely, that * Optimizing society-level desiderata (like “overall happiness”) may lead to * individuals being brutally mistreated (e.g., having their rights violated)\nYou can also hopefully see how this notion (Fairness Through Awarness) could provide a Rawls-style ordering: individual fairness lexically prior to group-level fairness (optimize group-level fairness once individual-level is satisfied).\nThen lastly, as you saw on HW2, this general notion of Fairness Through Awareness can be operationalized as a measurable quantity by, for example, implementing what is generally called metric fairness: Given a similarity metric \\(m: \\mathcal{I} \\times \\mathcal{I} \\rightarrow \\mathbb{R}\\), where \\(\\mathcal{I}\\) is the set of all individuals,\n\\[\n|D_i - D_j| \\leq m(i, j)\n\\]\nfor all pairs of individuals \\((i, j)\\). Or in other words, that the difference between the decisions \\(D_i\\) and \\(D_j\\) should be bounded above by the similarity \\(m(i,j)\\) between \\(i\\) and \\(j\\).\nThis, to me, is already slightly more than you need to know for the midterm, but if you want to dive into this Context-Sensitive approach specifically, Section 5.1 of (mitchell_algorithmic_2021?) has a really great discussion of Metric Fairness specifically.\n\n\n(4.2) Causal Fairness\nThis is the capital-B capital-D Big Deal approach to fairness, in my view, but you’ve already heard enough about that in class and on HW2!\nSo, for the midterm, instead I will just say that the key thing I want you to be comfortable with for now is drawing and interpreting Causal Diagrams like the ones I’ve shown in the slides and drawn on the board in class.\nFirst and foremost, if you absorb the Quick Intro to Probabilistic Graphical Models writeup, you are most of the way there to understanding Causal Diagrams in general, since (sweeping some details under the rug) these Causal Diagrams are primarily just PGMs where we interpret the edges (the arrows in the PGMs) as hypothesized causal effects.\nThus, for the midterm, my first goal is to test your ability to read these PGMs and understand what they’re positing (“saying”) about the world. For example, if I give you a hypothesis like\n\n\\(H_1\\): Individual \\(i\\) was arrested because they are black\n\nYou should be able to “translate” this into a causal diagram based on:\n\nA random variable \\(Y_i\\) representing whether or not an individual \\(i\\) was arrested (where we use the letter \\(Y\\) here speicifcally because we’re representing an outcome that we’re hoping to explain)\nA random variable \\(A_i\\) representing the race of individual \\(i\\), and\nAn edge \\(A_i \\rightarrow Y_i\\), representing the hypothesis that individual \\(i\\)’s specific \\(A_i\\) value (\\(A_i = a_i\\)) is what caused \\(Y_i\\) to take on individual \\(i\\)’s specific \\(Y_i\\) value (\\(Y_i = y_i = 1\\), in this case).\n\nThen, once you’re comfortable with this process of “implementing” hypotheses by constructing causal diagrams, the only other thing I think will be important for the midterm is your ability to adjudicate between two or more such diagrams on the basis of their plausibility.\nWhat I mean by that is… keep in mind the definition of causality that was given in a slide in class:\n\n\n\n\n\n\nDefining Causality (hume_treatise_1739?)\n\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\n\\(X\\) temporally precedes \\(Y\\) and\n\nIn two worlds \\(W_0\\) and \\(W_1\\) where\neverything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\),\n\\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\).\n\n\n\n\nYou should be able to use this definition to (for example) eliminate implausible causal diagrams, namely, causal diagrams which violate the basic predicates within this definition. So, for example, say I gave you the following causal diagram as a causal hypothesis regarding how toasters toast a piece of bread \\(i\\):\n\n\\(T_i\\) is a Random Variable which is \\(0\\) if the bread has not yet been placed in the toaster and \\(1\\) if has been placed in the toaster,\n\\(C_i\\) is a Random Variable which is \\(0\\) if the bread is not cooked, and \\(1\\) if the bread is cooked, and\nThere is an arrow \\(C_i \\rightarrow T_i\\)\n\nYou should be able to identify this as an implausible causal diagram—meaning, a causal diagram representing an implausible hypothesis about how toasters work, relative to the Humean notion of causality—since in our observations of how toasters work, the bread being placed in the toaster (\\(\\text{do}(T_i = 1)\\)) occurs before the bread being cooked \\(C_i = 1\\), temporally."
  },
  {
    "objectID": "midterm.html#part-5-doin-thangs-causality-continued",
    "href": "midterm.html#part-5-doin-thangs-causality-continued",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 5: Doin Thangs (Causality Continued)",
    "text": "Part 5: Doin Thangs (Causality Continued)\nShort story short, the example from the end of our most recent meeting, where we showed how it’s possible to have:\n\n\\(\\Pr(Y = 1) = p_y\\), and\n\\(\\Pr(Y = 1 \\mid X = 1) \\neq p_y\\), and yet\n\\(\\Pr(Y = 1 \\mid \\text{do}(X = 1)) = p_y\\),\n\nThus revealing the fact that \\(\\Pr(Y = 1 \\mid X = 1)\\) does not capture the causal effect of \\(X\\) on \\(Y\\) in this case, which is just one specific instance of the general maxim you already know, that correlation does not imply causation.\nAnd yet, with this \\(\\text{do}(E)\\) operator (where \\(E\\) is some probabilistic event), we have something concrete that we can use to start figuring out when observing a correlation does allow us to infer a causal effect!\nThe actual figuring-out will have to wait until after the midterm. But I want you to have that notion in your head when you see the \\(\\text{do}(\\cdot)\\) operator and/or a causal diagram: that these are the tools that are going to allow us to bridge this gap between correlation and causation, something that probability theory alone (i.e., the stuff you may have learned in DSAN 5100) cannot do!\nAs a preview, which I mentioned at the very very end of the “do-calculus” example I went through on the board: Pearl (2000) is literally a gigantic book that meticulously works through all possible causal diagrams1 and proves a massively important theorem that we’ll see after the midterm, which tells us precisely what conditions need to be met (in a given causal system) for us to be able to infer causal effects from conditional probabilities."
  },
  {
    "objectID": "midterm.html#references",
    "href": "midterm.html#references",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "References",
    "text": "References\n\n\nPearl, Judea. 2000. Causality: Models, Reasoning, and Inference. Cambridge University Press."
  },
  {
    "objectID": "midterm.html#footnotes",
    "href": "midterm.html#footnotes",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNot like, one-by-one, but by mathematically characterizing all of the possibilities, like how we can say that «Assuming Euclid’s 5th Postulate, the interior angles of a triangle sum to 180°», despite not having gone one-by-one through every triangle.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSAN 5650: Causal Inference for Computational Social Science",
    "section": "",
    "text": "Welcome to the homepage for DSAN 5650: Causal Inference for Computational Social Science at Georgetown University, for the Summer 2025 session!\nThe course meets on Wednesdays from 6:30pm to 9:00pm online, via the Zoom Link provided in the sidebar.\nCheck out the syllabus (or any other link in the sidebar) for more info! Or, use the following links to view notes for individual weeks:\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1: Introduction to the Course\n\n\nMay 21\n\n\n\n\n\nNo matching items\n\n\nCourse Description:\nThis course provides students with the opportunity to take the analytical skills, machine learning algorithms, and statistical methods learned throughout their first year in the program and explore how they can be employed towards carrying out rigorous, original research in the behavioral and social sciences. With a particular emphasis on tackling the additional challenges which arise when moving from associational to causal inference, particularly when only observational (as opposed to experimental) data is available, students will become proficient in cutting-edge causal Machine Learning techniques such as propensity score matching, synthetic controls, causal program evaluation, inverse social welfare function estimation from panel data, and Double-Debiased Machine Learning.\nIn-class examples will cover continuous, discrete-choice, and textual data from a wide swath of social and behavioral sciences: economics, political science, sociology, anthropology, quantitative history, and digital humanities. After gaining experience through in-class labs and homework assignments focused on reproducing key findings from recent journal articles in each of these disciplines, students will spend the final weeks of the course on a final project demonstrating their ability to develop, evaluate, and test the robustness of a causal hypothesis.\nPrerequisites: DSAN 5000, DSAN 5100 (DSAN 5300 recommended but not required)",
    "crumbs": [
      "<i class='bi bi-house pe-1'></i> Home"
    ]
  },
  {
    "objectID": "writeups/pgm-intro/index.html",
    "href": "writeups/pgm-intro/index.html",
    "title": "A Quick Introduction to Probabilistic Graphical Models",
    "section": "",
    "text": "A Probabilistic Graphical Model (PGM) is just a formal mathematical representation of a data-generating process. So, if we wanted to model the relationship between weather and a person’s choice of whether to go out and party or stay in and watch a movie on a given Saturday evening, we could begin by proposing the following data-generating process:\nNow, given the description of a PGM given above (nodes as variables, edges as relationships between variables), we can perform the move alluded to in the previous section: we can convert our data-generating process into a PGM, by defining nodes (variables) and edges (relationships) as follows:\nThe resulting PGM, in graphical form1, is presented below, followed by the Conditional Probability Table describing the edge from the \\(W\\) node to the \\(Y\\) node.\nPGMs can help us make inferences about the world in the face of incomplete information, which is the situation in nearly every real-world problem. The key tool here is the separation of nodes into two categories: observed (represented graphically as a shaded node) and latent (represented graphically as an unshaded node).\nThus we can now use our model as a weather-inference machine: if we observe that the person we’re modeling is out at a party with us, what can we infer from this information about the weather outside? We can draw this situation as a PGM with shaded and unshaded nodes, as in the figure below, and then use Bayes’ Rule to perform calculations over the network, to see how the observed information about the person at the party “flows” back into the node representing the weather.\nKeeping in mind that Bayes’ Rule tells us, for any two events \\(A\\) and \\(B\\), how to use information about \\(\\Pr(B \\mid A)\\) to obtain information about \\(\\Pr(A \\mid B)\\):\n\\[\n\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)},\n\\]\nWe can now apply this rule to obtain our new probability distribution over the weather, taking into account the new information that the person has chosen to go out:\n\\[\n\\begin{align*}\n&\\Pr(W = \\textsf{Sunny} \\mid Y = \\textsf{Go Out})\n= \\frac{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny})}{\\Pr(Y = \\textsf{Go Out})} \\\\\n= &\\frac{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny})}{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny}) + \\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Rainy})}\n\\end{align*}\n\\]\nAnd now we simply plug in the information we already have from our conditional probability table to obtain our new (conditional) probability of interest:\n\\[\n\\begin{align*}\n\\Pr(W = \\textsf{Sunny} \\mid Y = \\textsf{Go Out}) &= \\frac{(0.8)(0.5)}{(0.8)(0.5) + (0.1)(0.5)} \\\\\n&= \\frac{0.4}{0.4 + 0.05} = \\frac{0.4}{0.45} \\approx 0.89.\n\\end{align*}\n\\]\nWe have learned something interesting: now that we’ve observed the person out at a party, the probability that it is sunny out jumps from \\(0.5\\) (called the “prior” estimate of \\(W\\), i.e., our best guess without any other relevant information) to \\(0.89\\) (called the “posterior” estimate of \\(W\\), i.e., our best guess after incorporating relevant information)."
  },
  {
    "objectID": "writeups/pgm-intro/index.html#footnotes",
    "href": "writeups/pgm-intro/index.html#footnotes",
    "title": "A Quick Introduction to Probabilistic Graphical Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe term “Graphical” in Probabilistic Graphical Model is not used in the same sense as the “graphical” we’re used to from vernacular English. Capital-G Graphical denotes that the Probabilistic Model is represented as a Graph, a well-defined mathematical object consisting of nodes and edges, which does not have to be represented graphically (though it could be, like in our example here with circles and arrows). In fact, when a computer program is estimating a PGM, it is by definition not in a graphical form—it’s in the form of 0s and 1s, stored in the computer’s memory.↩︎"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignment Point Distributions",
    "section": "",
    "text": "Use the tabs below to view the point distributions for different assignments.\nThe distributions are imported from Google Sheets mainly for transparency: so that you can see exactly how totals are computed as a sum of the individual points allocated for each test!\n\nHW1HW2\n\n\n\n\n\n\n\n\n\npart\nqid\ntest_type\npoints\npart_total\n\n\n\n\n1\nQ1.1\npublic\n0\n12\n\n\n\nQ1.1\nhidden\n1\n\n\n\n\nQ1.2\npublic\n0\n\n\n\n\nQ1.2\nhidden\n1\n\n\n\n\nQ1.3\npublic\n0\n\n\n\n\nQ1.3\nhidden\n1\n\n\n\n\nQ1.4\npublic\n0\n\n\n\n\nQ1.4\nhidden\n1\n\n\n\n\nQ1.5\npublic\n0\n\n\n\n\nQ1.5\nhidden\n1\n\n\n\n\nQ1.6\npublic\n0\n\n\n\n\nQ1.6\nhidden\n1\n\n\n\n\nQ1.7\npublic\n0\n\n\n\n\nQ1.7\nhidden\n1\n\n\n\n\nQ1.8\npublic\n0\n\n\n\n\nQ1.8\nhidden\n1\n\n\n\n\nQ1.9\npublic\n0\n\n\n\n\nQ1.9\nhidden\n1\n\n\n\n\nQ1.10\npublic\n0\n\n\n\n\nQ1.10\nhidden\n1\n\n\n\n\nQ1.11\npublic\n0\n\n\n\n\nQ1.11\nhidden\n1\n\n\n\n\nQ1.12\npublic\n0\n\n\n\n\nQ1.12\nhidden\n1\n\n\n\n2\nQ2.1\npublic\n0\n7\n\n\n\nQ2.1\nhidden\n1\n\n\n\n\nQ2.2\npublic\n0\n\n\n\n\nQ2.2\nhidden\n1\n\n\n\n\nQ2.3\npublic\n0\n\n\n\n\nQ2.3\nhidden\n1\n\n\n\n\nQ2.4\npublic\n0\n\n\n\n\nQ2.4\nhidden\n1\n\n\n\n\nQ2.5\npublic\n0\n\n\n\n\nQ2.5\nhidden\n1\n\n\n\n\nQ2.6\npublic\n0\n\n\n\n\nQ2.6\nhidden\n2\n\n\n\n3\nQ3.1\npublic\n0\n5\n\n\n\nQ3.1\nhidden\n1\n\n\n\n\nQ3.2\npublic\n0\n\n\n\n\nQ3.2\nhidden\n1\n\n\n\n\nQ3.3a\npublic\n0\n\n\n\n\nQ3.3a\nhidden\n1\n\n\n\n\nQ3.3b\npublic\n0\n\n\n\n\nQ3.3b\nhidden\n1\n\n\n\n\nQ3.3c\npublic\n0\n\n\n\n\nQ3.3c\nhidden\n1\n\n\n\n4.1\nQ4.1.1\npublic\n1\n13\n\n\n\nQ4.1.1\nhidden\n2\n\n\n\n\nQ4.1.2\npublic\n1\n\n\n\n\nQ4.1.2\nhidden\n2\n\n\n\n\nQ4.1.3\npublic\n1\n\n\n\n\nQ4.1.3\nhidden\n1\n\n\n\n\nQ4.1.4\npublic\n1\n\n\n\n\nQ4.1.4\nhidden\n2\n\n\n\n\nQ4.1.5\npublic\n1\n\n\n\n\nQ4.1.5\nhidden\n1\n\n\n\n4.2\nQ4.2.1\npublic\n1\n4\n\n\n\nQ4.2.1\nhidden\n1\n\n\n\n\nQ4.2.2\npublic\n1\n\n\n\n\nQ4.2.2\nhidden\n1\n\n\n\n4.3\nQ4.3.1\npublic\n1\n4\n\n\n\nQ4.3.1\nhidden\n1\n\n\n\n\nQ4.3.2\npublic\n1\n\n\n\n\nQ4.3.2\nhidden\n1\n\n\n\n4.4\nQ4.4.1\npublic\n1\n3\n\n\n\nQ4.4.1\nhidden\n2\n\n\n\n4.5\nQ4.5.1\npublic\n1\n4\n\n\n\nQ4.5.1\nhidden\n2\n\n\n\n\nQ4.5.2\npublic\n0\n\n\n\n\nQ4.5.2\nhidden\n1\n\n\n\n4.6\nQ4.6.1\npublic\n1\n3\n\n\n\nQ4.6.1\nhidden\n2\n\n\n\n4.7\nQ4.7.1\npublic\n1\n5\n\n\n\nQ4.7.1\nhidden\n2\n\n\n\n\nQ4.7.2\npublic\n1\n\n\n\n\nQ4.7.2\nhidden\n1\n\n\n\n4.8\nQ4.8.1\npublic\n1\n11\n\n\n\nQ4.8.1\nhidden\n2\n\n\n\n\nQ4.8.2\npublic\n0\n\n\n\n\nQ4.8.2\nhidden\n1\n\n\n\n\nQ4.8.3\npublic\n0\n\n\n\n\nQ4.8.3\nhidden\n1\n\n\n\n\nQ4.8.4\npublic\n1\n\n\n\n\nQ4.8.4\nhidden\n2\n\n\n\n\nQ4.8.5\npublic\n1\n\n\n\n\nQ4.8.5\nhidden\n2\n\n\n\n4.9\nQ4.9.1\npublic\n0\n2\n\n\n\nQ4.9.1\nhidden\n1\n\n\n\n\nQ4.9.2\npublic\n0\n\n\n\n\nQ4.9.2\nhidden\n1\n\n\n\n4.10\nQ4.10.1\npublic\n0\n8\n\n\n\nQ4.10.1\nhidden\n1\n\n\n\n\nQ4.10.2\npublic\n0\n\n\n\n\nQ4.10.2\nhidden\n1\n\n\n\n\nQ4.10.3\npublic\n1\n\n\n\n\nQ4.10.3\nhidden\n2\n\n\n\n\nQ4.10.4\npublic\n1\n\n\n\n\nQ4.10.4\nhidden\n2\n\n\n\n4.11\nQ4.11.1\npublic\n1\n6\n\n\n\nQ4.11.1\nhidden\n2\n\n\n\n\nQ4.11.2\npublic\n1\n\n\n\n\nQ4.11.2\nhidden\n2\n\n\n\n4.12\nQ4.12\npublic\n1\n5\n\n\n\nQ4.12\nhidden\n4\n\n\n\n5\nQ5.1\npublic\n0\n8\n\n\n\nQ5.1\nhidden\n2\n\n\n\n\nQ5.2\npublic\n0\n\n\n\n\nQ5.2\nhidden\n2\n\n\n\n\nQ5.3\npublic\n0\n\n\n\n\nQ5.3\nhidden\n2\n\n\n\n\nQ5.4\npublic\n0\n\n\n\n\nQ5.4\nhidden\n2\n\n\n\nTotal\n\n\n100\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart\nqid\ntest_type\npoints\npart_total\n\n\n\n\n1\nQ1.1\npublic\n0\n\n\n\n\nQ1.1\nhidden\n2\n\n\n\n\nQ1.2\npublic\n0\n\n\n\n\nQ1.2\nhidden\n2\n\n\n\n\nQ1.3a\npublic\n0\n\n\n\n\nQ1.3a\nhidden\n2\n\n\n\n\nQ1.3b\npublic\n0\n\n\n\n\nQ1.3b\nhidden\n2\n\n\n\n\nQ1.4a\npublic\n0\n\n\n\n\nQ1.4a\nhidden\n2\n\n\n\n\nQ1.4b\npublic\n0\n\n\n\n\nQ1.4b\nhidden\n2\n\n\n\n\nQ1.5\npublic\n0\n\n\n\n\nQ1.5\nhidden\n2\n\n\n\n\nQ1.6\npublic\n0\n\n\n\n\nQ1.6\nhidden\n2\n\n\n\n\nQ1.7\npublic\n0\n\n\n\n\nQ1.7\nhidden\n2\n\n\n\n\nQ1.8\npublic\n0\n\n\n\n\nQ1.8\nhidden\n2\n20\n\n\n2\nQ2.1\npublic\n0\n\n\n\n\nQ2.1\nhidden\n5\n\n\n\n\nQ2.2\npublic\n0\n\n\n\n\nQ2.2\nhidden\n5\n10\n\n\n3\nQ3.1a\npublic\n0\n\n\n\n\nQ3.1a\nhidden\n2\n\n\n\n\nQ3.1b\npublic\n0\n\n\n\n\nQ3.1b\nhidden\n2\n\n\n\n\nQ3.2a\npublic\n0\n\n\n\n\nQ3.2a\nhidden\n2\n\n\n\n\nQ3.2b\npublic\n0\n\n\n\n\nQ3.2b\nhidden\n2\n\n\n\n\nQ3.3a\npublic\n0\n\n\n\n\nQ3.3a\nhidden\n2\n\n\n\n\nQ3.3b\npublic\n0\n\n\n\n\nQ3.3b\nhidden\n2\n12\n\n\n4\nQ4.1a\npublic\n0\n\n\n\n\nQ4.1a\nhidden\n2\n\n\n\n\nQ4.1b\npublic\n0\n\n\n\n\nQ4.1b\nhidden\n2\n\n\n\n\nQ4.2a\npublic\n0\n\n\n\n\nQ4.2a\nhidden\n2\n\n\n\n\nQ4.2b\npublic\n0\n\n\n\n\nQ4.2b\nhidden\n2\n\n\n\n\nQ4.3a\npublic\n0\n\n\n\n\nQ4.3a\nhidden\n2\n\n\n\n\nQ4.3b\npublic\n0\n\n\n\n\nQ4.3b\nhidden\n2\n12\n\n\n5\nQ5.1\npublic\n0\n\n\n\n\nQ5.1\nhidden\n4\n\n\n\n\nQ5.2\npublic\n0\n\n\n\n\nQ5.2\nhidden\n4\n\n\n\n\nQ5.3\npublic\n0\n\n\n\n\nQ5.3\nhidden\n4\n12\n\n\n6\nQ6.1\npublic\n0\n\n\n\n\nQ6.1\nhidden\n7\n\n\n\n\nQ6.2\npublic\n0\n\n\n\n\nQ6.2\nhidden\n7\n14\n\n\n7\nQ7.1\npublic\n0\n\n\n\n\nQ7.1\nhidden\n5\n\n\n\n\nQ7.2\npublic\n0\n\n\n\n\nQ7.2\nhidden\n5\n\n\n\n\nQ7.3\npublic\n0\n\n\n\n\nQ7.3\nhidden\n5\n\n\n\n\nQ7.4\npublic\n0\n\n\n\n\nQ7.4\nhidden\n5\n20\n\n\nTotal\n\n\n100\n100"
  },
  {
    "objectID": "writeups/index.html",
    "href": "writeups/index.html",
    "title": "Extra Writeups",
    "section": "",
    "text": "Order By\n       Default\n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nLast Updated\n\n\nRelevant To\n\n\nCategory\n\n\n\n\n\n\nHigher-Order DAGs via Block Models\n\n\nThursday, May 1, 2025\n\n\nWeeks 5-7 (Causality)\n\n\nExtra Writeups\n\n\n\n\nA Quick Introduction to Probabilistic Graphical Models\n\n\nSunday, February 18, 2024\n\n\nWeeks 5-7 (Causality)\n\n\nExtra Writeups\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "final.html",
    "href": "final.html",
    "title": "Final Project Specifications",
    "section": "",
    "text": "Our goal is to make the final project as open-ended as possible, to give you the space to explore any particular topic that may have piqued your interest throughout the semester! At the same time, we hope to provide you with guidance and mentorship so that you don’t feel lost as to how to start, how to proceed, and/or what to submit for the final deliverable!1\nSo, given this, we have randomly assigned each of you to a mentor, who will help you select a topic and pursue it in such a way that it fits within the scope of the remaining weeks in the semester. You will receive an email letting you know who your mentor is, by the end of the weekend (Sunday, March 24th). The mentor assignments can always be re-arranged, however! For example, if you decide to pursue a project that another mentor has particular experience with, we can re-assign you to that mentor!\n\n\n\n\n\n\nThe Goal: Research \\(\\rightarrow\\) Policy Recommendation\n\n\n\nAlthough the structure can be mostly similar to projects you’ve done for e.g. DSAN 5000 and 5100, the new element for the DSAN 5450 project is that we want you to develop and argue for a particular policy recommendation that you’d make, for example if you were asked to speak in Congress as a data science expert!\nThis means, for example, that your deliverable can have the following structure in terms of section headings, which should be familiar from DSAN 5000 and 5100 except for the final section:\n\nIntroduction\nLiterature Review\nData and Methods\nResults\nPolicy Recommendation\n\nThe policy recommendation portion will look different depending on the particular topic you decide to explore, but the idea is that it should be somewhat like a policy whitepaper, where you would move away from the details of your study and towards its implications for a (real or imagined) policymaker who is hoping for information about a given topic.\nOne recent example that you can look at as a rough template would be Chris Callison-Burch’s Congressional testimony, given last year as part of a Congressional hearing around issues that LLMs might present for intellectual property and copyright law. Prof. Callison-Burch discusses the process in this podcast episode, so you can listen to that for details about the approach he took towards the invitation from Congress, but the tldr is: he needed to communicate just enough detail to allow the policymakers to understand what he was talking about, but not so much detail that they would need to have a PhD in Computer Science to understand his recommendations."
  },
  {
    "objectID": "final.html#overview",
    "href": "final.html#overview",
    "title": "Final Project Specifications",
    "section": "",
    "text": "Our goal is to make the final project as open-ended as possible, to give you the space to explore any particular topic that may have piqued your interest throughout the semester! At the same time, we hope to provide you with guidance and mentorship so that you don’t feel lost as to how to start, how to proceed, and/or what to submit for the final deliverable!1\nSo, given this, we have randomly assigned each of you to a mentor, who will help you select a topic and pursue it in such a way that it fits within the scope of the remaining weeks in the semester. You will receive an email letting you know who your mentor is, by the end of the weekend (Sunday, March 24th). The mentor assignments can always be re-arranged, however! For example, if you decide to pursue a project that another mentor has particular experience with, we can re-assign you to that mentor!\n\n\n\n\n\n\nThe Goal: Research \\(\\rightarrow\\) Policy Recommendation\n\n\n\nAlthough the structure can be mostly similar to projects you’ve done for e.g. DSAN 5000 and 5100, the new element for the DSAN 5450 project is that we want you to develop and argue for a particular policy recommendation that you’d make, for example if you were asked to speak in Congress as a data science expert!\nThis means, for example, that your deliverable can have the following structure in terms of section headings, which should be familiar from DSAN 5000 and 5100 except for the final section:\n\nIntroduction\nLiterature Review\nData and Methods\nResults\nPolicy Recommendation\n\nThe policy recommendation portion will look different depending on the particular topic you decide to explore, but the idea is that it should be somewhat like a policy whitepaper, where you would move away from the details of your study and towards its implications for a (real or imagined) policymaker who is hoping for information about a given topic.\nOne recent example that you can look at as a rough template would be Chris Callison-Burch’s Congressional testimony, given last year as part of a Congressional hearing around issues that LLMs might present for intellectual property and copyright law. Prof. Callison-Burch discusses the process in this podcast episode, so you can listen to that for details about the approach he took towards the invitation from Congress, but the tldr is: he needed to communicate just enough detail to allow the policymakers to understand what he was talking about, but not so much detail that they would need to have a PhD in Computer Science to understand his recommendations."
  },
  {
    "objectID": "final.html#timeline",
    "href": "final.html#timeline",
    "title": "Final Project Specifications",
    "section": "Timeline",
    "text": "Timeline\nThese are rough estimates, but the project will go most smoothly if you are able to hold yourself to the following schedule:\n\nProposal: Approved by mentor by Wednesday, April 3rd\nFinal Draft: Sent to mentor for review by Wednesday, April 24th\nSubmission: Completed project submitted to course staff by Friday, May 10th, 5:59pm EDT"
  },
  {
    "objectID": "final.html#submission-format",
    "href": "final.html#submission-format",
    "title": "Final Project Specifications",
    "section": "Submission Format",
    "text": "Submission Format\nThere is now an assignment page for the final project (within the Google Classroom site for the course), where you will upload your final submission for grading. The following is a rough sketch of what we’re looking for in terms of the structure of your submission:\n\nHTML format, as a rendered Quarto manuscript, would be optimal, but can be PDF if there are issues with Quarto. If PDF, LaTeX would be preferred, but also can be a Word doc or Google doc\nIf PDF format, 8-20 pages double-spaced, and then the Quarto HTML length can be the equivalent of this (for example, you can print-preview the Quarto doc to see how many pages it would print as)\nIt should have an abstract, a 250-500 word summary at the top, of (a) what you did and (b) the policy recommendation you’re making\nCitations should be set up so that they’re handled automatically, by Quarto’s citation manager for example, or by Bibtex if you use LaTeX to generate a PDF, or by Word/GDocs otherwise."
  },
  {
    "objectID": "final.html#the-proposal-stage",
    "href": "final.html#the-proposal-stage",
    "title": "Final Project Specifications",
    "section": "The Proposal Stage",
    "text": "The Proposal Stage\nOur goal here is for you to have enough time to think through the details in advance, to determine the scope, of the project, before you actually start working on it. This is often (like, almost always) the most difficult part of any project: it’s not a matter of whether you’re capable of doing the project at all—you’re all capable of doing it!—but how feasible it is to do it within the given timeframe.\nSo, this is exactly why there’s a course staff here to help you! We’ve all wrestled with this issue of “scope creep” throughout our own previous projects, which means that our goal in providing feedback on your proposals will be solely to help you brainstorm and then focus in on what you can accomplish by the beginning of May. Thus, to reiterate, you should not view the proposal feedback as some sort of judgement of your innate ability or anything like that! And, to this end, it will not be graded, which we hope will further cement the idea that it is not a judgement process, but a working-together process to arrive at a plan for getting the project done.\nTo conclude, concretely: you’ll be “done” with the proposal stage once you and your mentor are on the same page in terms of\n\nWhat topic you’re going to pursue,\nWhat your final deliverable will look like, and\nA set of milestones you will use from now until the beginning of May to track your progress.\n\nAt that point, you’ll be ready for the implementation stage, described in the next section."
  },
  {
    "objectID": "final.html#the-implementation-stage",
    "href": "final.html#the-implementation-stage",
    "title": "Final Project Specifications",
    "section": "The Implementation Stage",
    "text": "The Implementation Stage\nThis stage is more difficult to describe in advance, since it depends on the specific topic you’ll pursue. But, the main goal is for you to have a draft version of the project ready by Wednesday, April 24th. We choose this date specifically because it corresponds to the final lecture in the course, so that as part of that lecture Jeff can make sure to touch on any remaining issues that might still need to be tackled in order to move from the draft to the submission on the last day of the semester.\nHowever, given this explanation, hopefully it makes sense that the earlier you have a draft, the better, since an earlier draft means that Jeff can also use the lectures before the final lecture to cover any topics which might be relevant to your projects! In other words: the whole reason why the last few lectures of the course are set aside as “Selected Topics” is so that these lectures can adapt to cover whatever might be relevant and important for the range of topics yall choose for your final projects! So, please take advantage of this aspect of the class if you can."
  },
  {
    "objectID": "final.html#example-project-ideas",
    "href": "final.html#example-project-ideas",
    "title": "Final Project Specifications",
    "section": "Example Project Ideas",
    "text": "Example Project Ideas\nNow that you have all of the above info, we wanted to make it clear that it’s okay if you don’t have any idea of what topic you’d like to pursue for the project! Some people come into the course with a very particular interest, whereas others come in for the sake of learning a broad overview of a bunch of topics, and we’re here to accommodate both cases 😁 So, if you don’t have a preexisting idea of what you’d like to pursue, in this section we provide you with a few examples—one example per course topic—that you can choose as-is or modify to suit your interests.\nAs you’ll quickly see if you start reading through the examples, there are tons and tons of details and tons and tons of variations/modifications that could be made, that I’m unable to state in detail without making this a 1000-page document 😜 so, just keep in mind that if anything at all pops into your head while reading through them, even if the thing that pops into your head doesn’t “match” the specific details of one of the projects here, that’s a good thing! You can take that and run with it, turning it from an idea into a full-blown project by talking through it with your mentor.\n\nHigh-Level Data Science Questions\n\nExample 1: Archive of Missing Datasets\nHere there are tons of possibilities for each “sub-topic” that we covered during the broad overview of data science issues given in Week 1 and Week 2. But, one that I think could be interesting and relevant to the policy-focused goal of the final project would be to pursue the idea of the Archive of Missing Datasets:\nYou may have found, when working on your own projects or the DSAN 5000/5100 projects, that there are lots of datasets that you assume must exist somewhere, but you then find to your horror that they actually don’t exist, at least not in a form that would allow for a useful/informative data analysis.\nSo, if you have experienced this, or if you haven’t but you’re interested in discovering what might be egregious/socially-important cases of missing datasets, your final project could revolve around recommending to policymakers that they invest in (as in, allocate resources towards in general, not just money!) the creation of a currently non-existent dataset.\nThis is precisely what has motivated one of the biggest society-wide DSAN 5450-related developments in the US of recent years: in the aftermath of the sudden publicity that rampant police murder of black people across the country received because of cases like the murders of\n\nTrayvon Martin in Florida,\nFreddie Gray in Baltimore, Maryland,\nMichael Brown in Ferguson, Missouri,\nEric Garner in Staten Island, New York,\nGeorge Floyd in Minneapolis, Minnesota, and\nPhilando Castile in St. Paul, Minnesota,\n\nmany people were shocked to learn that the US government doesn’t care enough to keep track of these killings in any systematic way, which led to data-journalistic endeavors like the Washington Post’s “Fatal Force” police killings database.\nOnce these endeavors were established, however, the next “phase” of policy debates on this issue have revolved around whether and/or how data on these types of socially-important phenomena should in fact be collected by publicly-funded government institutions, given that (in this case) the police officers doing the killings are themselves publicly-funded government employees.\nSo, as an example final project on this issue of missing datasets, you could:\n\nIdentify another such socially-important phenomenon for which there is a dearth of available data that would be helpful for some social goal,\nDocument the details around what data already exists regarding this phenomenon (descriptively), and why it is insufficient from a social perspective (normatively), and then\nArgue that the policymaking audience of your project should in fact allocate resources towards the collection of this data (note the shift from descriptive to normative here!): for example, you would need to argue for the feasibility of this collection—providing concrete details about precisely how it could be implemented, in a cost-effective manner, given some budget—as well as its effectiveness with respect to some explicitly-stated social goal (like, in the above example, the goal could simply be to reduce the frequency of police killings).\n\n\n\nExample 2: Operationalization\nIn the Week 1 slides I included a brief discussion of operationalization in terms of a book by \"\"\"Nobel Prize\"\"\"-winning economists2 Joseph Stiglitz and Amartya Sen called Mismeasuring our Lives: Why GDP Doesn’t Add Up (stiglitz_mismeasuring_2010?). This example project outline is sort of a “variation” of Example 1, since basically what I would recommend if you’re interested in this topic would be very similar:\nWhereas the goal of the Archive of Missing Datasets is to point out how there is lots of socially-important information that is not measured at all, Stiglitz and Sen are pointing to equally-urgent and equally-deleterious (often way more urgent/deleterious!) cases where the information is measured, but where the way that it is measured is harmful with respect to the social goal which motivated the measurement in the first place.\nSo, we can take the description of Example 1 above, and basically just replace “missing” with “badly measured”, to see how a project studying operationalization could work:\n\nIdentify a socially-important phenomenon for data does exist but is measured in a way that is relatively unhelpful/non-useful with respect to some social goal (that is, relative to another way of measuring it which could be mroe helpful/useful),\nDocument the details around what data already exists regarding this phenomenon (descriptively), and why it is unhelpful for measuring the social phenomena of interest (normatively), and then\nArgue that the policymaking audience of your project should in fact allocate resources towards the better operationalization that you are proposing (note the shift from descriptive to normative here!): for example, you would need to argue for the feasibility of this new measure—providing concrete details about precisely how it could be implemented, in a cost-effective manner, given some budget—as well as its greater effectiveness than previous ways of measuring, with respect to some explicitly-stated social goal (like, in the earlier example, reducing the frequency of police killings).\n\nAs you can maybe tell by now, the “boundary” between missing data and badly-measured data is sometimes fuzzy: for example, often data-policy debates will say that a certain dataset is missing as shorthand for something more like “it’s measured so badly that, for all intents and purposes it may as well be missing”.\nFor example, technically (until 2019) the FBI used to issue what were called Uniform Crime Reports, but these were based on a “voluntary-reporting” model, meaning that individual police departments could submit whatever data they wanted, and withhold whatever data they wanted, without explanation or documentation, so… from what I can tell, after 2019 they just gave up, since a voluntary-reporting dataset of crime certainly falls under the rubric of may-as-well-be-missing. But, alas, these reports are still used widely in various academic studies of crime, books, journalistic investigations, etc., so if that’s at all interesting to you, it could be studied for a final project that would treat it as a mixture of the missing data and badly-operationalized data issues.\n\n\n\nFairness\nAs we discussed in Week 4 (specifically, I wrote it on the chalkboard and talked through it as an example, on the basis of stuff in those W04 slides), one of the most high-profile cases of algorithmic discrimination in the 21st century emerged out of the ProPublica vs. Northpointe Scandal.\nThe rough summary is that:\n\nAlthough ProPublica meticulously documented anti-black racial discrimination in Northpointe’s COMPAS algorithm in terms of the classification parity fairness measure,\nNorthepointe then responded by meticulously documenting the absence of anti-black racial discrimination in COMPAS in terms of the predictive parity fairness measure\n\nSo, since this is one of the most-often-analyzed datasets in the Fairness in AI literature, your final project could be to pursue this case in a more in-depth way than we were able to cover it in class. This would involve writing a policy paper with two main parts:\n\nExplaining the ProPublica-Northpointe controversy descriptively, by demonstrating how the data simultaneously violates classification parity fairness while satisfying predictive parity fairness. Specifically, this would mean:\n\nExplaining the two fairness definitions to an audience of policymakers and then\nWriting Python or R code which downloads the data and evluates it programmatically on these two different fairness criteria\n\nEvaluating the ProPublic-Northpointe controversy normatively, by providing recommendations for policymakers in terms of how they ought to adjudicate this case. There are several ways you could approach this, but the first two example approaches that come to mind are:\n\nArguing that one of these two fairness criteria better “aligns” with an ethical framework that you think the policymakers should adopt—for example, you could adopt utilitarianism as your ethical “axiom”, and then argue that one of these criteria is more appropriate for evaluating outcomes than the other, and therefore better suited to resolving the dispute in a utilitarian manner\nArguing that neither of the two fairness criteria are sufficient for policymaking, and arguing that policymakers should instead use a framework like \\(\\varepsilon\\)-based fairness or causal fairness to resolve the dispute.\n\n\n\n\nCausality\nAn example project on this topic could pursue the type of approach that appeared on your Homework 2, in Part 3.3, which presented two different hypotheses regarding the causal mechanism by which women experience worse mental health outcomes. You don’t need to pursue this particular question, or use these particular variables in your causal model! But, I am copying some of the key parts of that problem here, along with explanations of how you could pursue this type of analysis in a more in-depth way for a final project.\nThe homework problem presented a simplified version of a causal system studied using causal diagrams in Chapter 16 of Kaufman and Oakes (2006): Glymour (2006), “Using Causal Diagrams to Understand Common Problems in Social Epidemiology”. The idea was to consider an imaginary debate (though one that happens between real people all the time, when taking about this issue!) between:\n\nPerson \\(i\\), who hypothesizes that women have greater rates of depression because they are “‘biologically programmed’ to be depressed” (ibid., pg. 408), and\nPerson \\(j\\), who hypothesizes that women have greater rates of depression because\n\n\n“People get depressed whenever they are sexually harassed” (ibid.), and\n\n\n“Women are more frequently sexually harassed than men” (ibid.)\n\n\n\nIt then took this debate and tried to “zero in” on the particular variables that came into play in the respective arguments:\n\n\\(A\\): The gender of an individual (as before, conceptualized as their self-reported and/or socially-expressed gender), where \\(A = 1\\) for self-reported females and \\(A = 0\\) for those who do not self-report as female\n\\(B\\): An indicator variable representing some biological property of the individual (in these debates, this would most commonly be e.g. \\(B = 1\\) for the presence of at least one Y-chromosome and \\(B = 0\\) otherwise)\n\\(H\\): Whether or not someone experiences sexual harassment, where \\(H = 1\\) represents that the individual has experienced such harassment and \\(H = 0\\) represents that they have not experienced it\n\\(Y\\): The “outcome” of whether or not someone has developed depression, where \\(Y = 1\\) represents an individual with depression and \\(Y = 0\\) represents an individual without depression\n\nAnd, once these variables were established, we were able to “encode” the two hypothesized causal pathways within the same causal diagram:\n\n\n\nWe then looked at two subgraphs of the full causal diagram, with the following subgraph representing person \\(i\\)’s hypothesis:\n\n\n\nAnd this alternative subgraph representing person \\(j\\)’s hypothesis:\n\n\n\nSo, for your final project, you could take a debate around a social issue that is particularly important or particularly interesting to you and perform a causal analysis of it using this general framework.\nThe idea would be to choose a topic where you think that detailing the causal connections between variables in this manner could aid policymakers in addressing the underlying problem.\nLots of examples immediately come to mind (though they are Jeff-style examples so you don’t need to choose any of them, I promise! 😜), but throughout the semester many of the examples in class revolved around the causal pathways linking race with policing, incarceration, and the criminal justice system. From the perspective of a policymaker—the perspective you should have in mind for the final project!—some of the key issues that could be analyzed using frameworks from DSAN 5450 would be:\n\nHow do variables related to social conditions (e.g., poverty, quality of schools) causally interact with variables related to individual choices (e.g., searching for a job, pursuing additional years of school, allocating income between saving and spending) to produce outcomes like career “success” (say, moving into a higher or lower income bracket relative to the bracket one is born into), crime, and/or trust in government?\nHow might it help policymakers to think causally, in terms of how different interventions might counterfactually help or harm some goal that they have?\n\nHere you could choose an existing but vague policy debate like “do police and metal detectors in school help or harm students’ educations?”, and make it more concrete by describing a causally-robust study that could be performed to slightly move this debate away from people-yelling-opinions-at-each-other and towards people-studying-the-causal-impacts-of-interventions… If you were actually able to go out and collect data relevant to these debates, and perform a causal analysis using this data, that would be the holy grail! But, I promise, given the timespan you have, a careful and well-thought-out description of what this type of study would look like and how it could be carried out would be sufficient for the project.\n\n\n\n\nPrivacy and Data Protection Policies\nHere there were a couple of points during Week 8 and Week 9 where I mentioned possible final project ideas, but the first two that come to mind are:\n\nIn this slide during Week 8, I pointed out how there are far too many different data-protection policy frameworks, spanning across too many different countries and states, for me to be able to cover them all. So, your project could be to pursue this further than we were able to in class! But, that’s a bit general, so to make it more specific, the types of projects I briefly outlined in Week 8 were along the lines of:\n\nChoose a country/state that you think is a “policy innovator”, and then see how the data-protection policies from this country/state “diffuse outwards” and get adopted over time by other countries/states. Although one way to do this would be to find a manually-curated dataset which contains (e.g.) 0/1 variables representing whether a given state has adopted a given data-protection policy at a given time (and these datasets definitely exist, and we can help you find them!), to me another cool way to study this would be to use NLP text-reuse detection algorithms like Passim, to “automatically” detect policy adoption by just seeing when text from country \\(A\\)’s data-protection laws appears in another country \\(B\\)’s data-protection laws.\nRather than a diffusion study like this, you could instead carry out what’s called a cross-sectional analysis of countries/states and their data-protection policies: to me, one interesting cross-sectional study could be to see how a country’s form of government relates to the data-protection laws it adopts: are there systematic differences between the data-protection policies adopted by hereditary monarchies in the Middle East like Saudi Arabia or Bahrain and those adopted by comparable (as in, in this case, historically-culturally similar—remember our idea of fair comparison!) Middle Eastern countries with democratic institutions like Yemen or Lebanon?3\n\nOne other potential project I mentioned in both Week 8 and Week 9 would be a project studying how ambiguity is used instrumentally in privacy policies to shift power from users to companies, since these companies possess greater residual rights of control—the right to determine “what happens” when there is ambiguity in a contract—relative to users. The slides for both weeks contained the plot from (wagner_privacy_2023?) showing the growth in “obfuscatory words” in privacy policies over time, but I also mentioned how the goal of (wagner_privacy_2023?) was to point out how NLP could be used to try and “combat” the power imbalances induced by this ambiguity.\nSo, one example of a final project pursuing this thread could be a policy paper wherein you code and demonstrate a proof of concept of how a “privacy policy badness detector” could work: it’s the thing I talked about near the beginning of Week 9, where, you could have a user specify their privacy “boundaries”, and then you could have code that uses NLP tools to parse privacy policies to identify statements which might enable the company to violate these boundaries, highlighting them for the user so that they don’t have to read the entire thing manually!\nScope-wise, that would be pretty ambitious, so to me a very reasonable final project could just be a more “naïve” version of this, where users could just specify key terms of interest to them (say, “medical data”), and then maybe the app could be a browser extension which removes all of the parts of the privacy policy besides the parts which may be relevant to the user’s key terms. Then, in your paper, you would want to make an argument to policymakers on the basis of what you “found” in making the app—for example, if you found that there were clauses that were relevant to medical data but where this relevance was “hidden” because of the ambiguity of the language used, then perhaps you could recommend that they pass a law requiring companies to tag each paragraph of their privacy policies with what aspects of privacy they relate to, as a concrete way to ameliorate the “ambiguity problem”!\n\n\n\nPolicy Evaluation / Recommendation\nSince we haven’t covered this yet, I will just provide an example of a policy-evaluation final project in class this week (Week 10), and then I will copy it into this section."
  },
  {
    "objectID": "final.html#references",
    "href": "final.html#references",
    "title": "Final Project Specifications",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "final.html#footnotes",
    "href": "final.html#footnotes",
    "title": "Final Project Specifications",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you can’t tell, my whole educational philosophy here is just the Montessori system—this approach was originally developed for younger (primary school) children, but lots and lots of recent educational research indicates that it’s an actually an extremely effective way to learn, and to motivate self-learning, for people of any age 😎↩︎\nEven though I’m biased in the opposite direction of belittling them—since Joseph Stiglitz and Amartya Sen are two of my heroes, and Stiglitz even gave me nice comments on my dissertation and stuff since I was at Columbia with him—it’s honestly important to put \"\"\"Nobel Prize in Economics\"\"\" in triple-quotes, since unlike the “real” (non-triple-quoted) Nobel Prizes, the \"\"\"Nobel Prize\"\"\" in economics was actually created about 80 years after the real ones established by Alfred Nobel, and were explicitly part of the movement by the so-called “Chicago School” of economics to legitimize their particular brand of economics as a “““science”““, and thus delegitimze any other approach to economics as”non-scientific”… For a quick overview with a link to a great interview with Philip Mirowski, here’s a FiveThirtyEight article: “The Economics Nobel Isn’t Really A Nobel”. But the full-on, in-depth essay I’d truly recommend is Yasha Levine’s “It’s all a big lie. There is no ‘Nobel Prize’ in Economics.” &lt;/rant&gt;↩︎\nObviously there are tons of details and particular considerations that you might have to take into account for these types of studies, but that’s exactly the type of thing that the TAs and I can help you with! If you go with this particular choice, for example, you’d have to make sure to control for considerations like the fact that these countries vary in terms of ethnic and/or religious “homogeneity”: About 85% of Saudi Arabian citizens are Sunni Muslim Arabs, for example, whereas Lebanon is basically a patchwork of dozens of different salient religious/cultural/ethnic identities, which would be relevant in the sense that different identity groups within a country might have vastly different dispositions towards how their data should be collected and used!↩︎"
  },
  {
    "objectID": "w01/index.html",
    "href": "w01/index.html",
    "title": "Week 1: Introduction to the Course",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#prof.-jeff-introduction",
    "href": "w01/index.html#prof.-jeff-introduction",
    "title": "Week 1: Introduction to the Course",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#grad-school",
    "href": "w01/index.html#grad-school",
    "title": "Week 1: Introduction to the Course",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\n\nColumbia for PhD[+Postdoc] in Political Science (2015-2023)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#dissertation-political-science-history",
    "href": "w01/index.html#dissertation-political-science-history",
    "title": "Week 1: Introduction to the Course",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#references",
    "href": "w01/index.html#references",
    "title": "Week 1: Introduction to the Course",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/slides.html#prof.-jeff-introduction",
    "href": "w01/slides.html#prof.-jeff-introduction",
    "title": "Week 1: Introduction to the Course",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)"
  },
  {
    "objectID": "w01/slides.html#grad-school",
    "href": "w01/slides.html#grad-school",
    "title": "Week 1: Introduction to the Course",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\nColumbia for PhD[+Postdoc] in Political Science (2015-2023)"
  },
  {
    "objectID": "w01/slides.html#dissertation-political-science-history",
    "href": "w01/slides.html#dissertation-political-science-history",
    "title": "Week 1: Introduction to the Course",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada"
  },
  {
    "objectID": "w01/slides.html#references",
    "href": "w01/slides.html#references",
    "title": "Week 1: Introduction to the Course",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "DSAN 5650",
    "section": "",
    "text": "Welcome to DSAN 5650: Causal Inference for Computational Social Science at Georgetown University!\nThe course meets on Wednesdays from 6:30-9pm online via Zoom",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-staff",
    "href": "syllabus.html#course-staff",
    "title": "DSAN 5650",
    "section": "Course Staff",
    "text": "Course Staff\n\nProf. Jeff Jacobs, jj1088@georgetown.edu\n\nOffice hours (Click to schedule): Tuesdays, 3:30-6:30pm\n\nTA Courtney Green, crg123@georgetown.edu\n\nOffice hours by appointment\n\nTA Wendy Hu, lh1078@georgetown.edu\n\nOffice hours by appointment",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "DSAN 5650",
    "section": "Course Description",
    "text": "Course Description\nThis course provides students with the opportunity to take the analytical skills, machine learning algorithms, and statistical methods learned throughout their first year in the program and explore how they can be employed towards carrying out rigorous, original research in the behavioral and social sciences. With a particular emphasis on tackling the additional challenges which arise when moving from associational to causal inference, particularly when only observational (as opposed to experimental) data is available, students will become proficient in cutting-edge causal Machine Learning techniques such as propensity score matching, synthetic controls, causal program evaluation, inverse social welfare function estimation from panel data, and Double-Debiased Machine Learning.\nIn-class examples will cover continuous, discrete-choice, and textual data from a wide swath of social and behavioral sciences: economics, political science, sociology, anthropology, quantitative history, and digital humanities. After gaining experience through in-class labs and homework assignments focused on reproducing key findings from recent journal articles in each of these disciplines, students will spend the final weeks of the course on a final project demonstrating their ability to develop, evaluate, and test the robustness of a causal hypothesis.\nPrerequisites: DSAN 5000, DSAN 5100 (DSAN 5300 recommended but not required)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-overview",
    "href": "syllabus.html#course-overview",
    "title": "DSAN 5650",
    "section": "Course Overview",
    "text": "Course Overview\nThe fundamental building block for the course is the idea of a Data-Generating Process (DGP). You may have encountered this concept in passing during other DSAN courses (for example, in DSAN 5100, a phrase like “Assume \\(X\\) is drawn i.i.d. from a Normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\)” is a statement characterizing the DGP of a Random Variable \\(X\\)), but in this course we will “zoom in” on this concept rather than treating it like a black box or a footnote to e.g. a theorem like the Law of Large Numbers.\nThis deep dive into DGPs is necessary for us here, since our goal in the course is to move from associational statements like “an increase of \\(X\\) by one unit is associated with an increase of \\(Y\\) by \\(\\beta\\) units” to causal statements like “increasing \\(X\\) by one unit causes \\(Y\\) to increase by \\(\\beta\\) units”. As you’ll see in Week 1, the tools from probability theory and statistics that you learned in DSAN 5100—Random Variables, Cumulative Distribution Functions, Conditional Probability, and so on—are necessary but not sufficient to analyze data from a causal perspective.\nFor example, if we use our tools from DSAN 5000 and DSAN 5100 on some dataset to discover that:\n\nThe probability that some event \\(E_1\\) occurs is \\(\\Pr(E_1) = 0.5\\), and\nThe probability that \\(E_1\\) occurs conditional on another event \\(E_0\\) occurring is \\(\\Pr(E_1 \\mid E_0) = 0.75\\),\n\nwe unfortunately cannot infer from these two pieces of information that the occurrence of \\(E_0\\) causes an increase in the likelihood of \\(E_1\\) occurring.\nThis issue (that conditional probabilities could not be interpreted causally) at first represented a kind of dead end for scientists interested in employing probability theory to study causal relationships… In recent decades, however, researchers have built up what amounts to an additional “layer” of modeling tools which augment the existing machinery of probability theory to address causality head-on!1\nFor instance, a modeling approach called “\\(\\textsf{do}\\)-Calculus”, that we will learn in this class, extends the core operations and definitions of probability theory to allow such an move to deriving causality! It does this by introducing a \\(\\textsf{do}(\\cdot)\\) operator that can be applied to Random Variables like \\(X\\), with e.g. \\(\\textsf{do}(X = 5)\\) representing the event wherein someone has intervened in a Data-Generating Process to force the value of \\(X\\) to be 5.\nWith this operator in hand (that is, used alongside an explicit model of a DGP satisfying a set of underlying axioms which are slightly more strict than the axioms of probability theory), it turns out that we can make causal inferences using a very similar pair of facts! If we know that:\n\nThe probability that some event \\(E_1\\) occurs is \\(\\Pr(E_1) = 0.5\\), and\nThe probability that \\(E_1\\) occurs conditional on the event \\(\\textsf{do}(E_0)\\) occurring is \\(\\Pr(E_1 \\mid \\textsf{do}(E_0)) = 0.75\\),\n\nnow we can actually draw the inference that the occurrence of \\(E_0\\) caused an increase in the likelihood of \\(E_1\\) occurring!\nThis stylized comparison (between what’s possible using “core” probability theory and what’s possible when we augment it with additional causal modeling tools) serves as our basic motivation for the course, so that from Week 2 onwards we build upon this foundation to reach the three learning goals described in the next section!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#main-textbooks-resources",
    "href": "syllabus.html#main-textbooks-resources",
    "title": "DSAN 5650",
    "section": "Main Textbooks / Resources",
    "text": "Main Textbooks / Resources\nUnlike the case for topics like calculus or statistical learning, this field is too new (and exciting! with new methods being developed month-to-month) to have a single set of “established” textbooks. Thus, the main collection of resources (books, papers, and explanatory videos) we’ll draw on for this class are available on the resources page. However, there are three “core” textbooks you can draw on which best align with the topics in this course:\n\nMorgan and Winship, Counterfactuals and Causal Inference: Methods and Principles for Social Research (Morgan and Winship 2015) [PDF]\n\nThe book which comes closest to being an all-encompassing, single textbook for the class. It brings together different “strands” of causal modeling research (since each field—economics, bioinformatics, sociology, etc.—tends to use its own notation and vocabulary), unifying them into a single approach. The only reason we can’t use it as the main textbook is because it hasn’t been updated since 2015, and most of the assignments in this class use computational tools from 2018 onwards!\n\nAngrist and Pischke, Mastering ’Metrics: The Path from Cause to Effect (Angrist and Pischke 2014) [PDF]\n\nThis book is included as the second of the three “core” texts mainly because, it uses the language of causality specific to Econometrics, the language that is most familiar to me from my PhD training in Political Economy. However, if you tend to learn better by example, it also does a good job of foregrounding specific examples (like evaluating charter schools and community policing policies), so that the methods emerging naturally from attempts to solve these puzzles when association methods like linear regression fail to capture their causal linkages.\n\nPearl and Mackenzie, The Book of Why: The New Science of Cause and Effect (Pearl and Mackenzie 2018) [EPUB]\n\nThis book contrasts with the Angrist and Pischke book in using the language of causality formed within Computer Science rather than Economics. It can be a good starting point especially if you’re unfamiliar with the heavy use of diagrams for scientific modeling—basically, whereas Angrist and Pischke’s first instinct is to use (sometimes informal) equations like \\(y = mx + b\\) to explain steps in the procedures, Pearl and Mackenzie’s instinct would be to instead use something like \\(\\require{enclose}\\enclose{circle}{\\kern .01em ~x~\\kern .01em} \\overset{\\small m, b}{\\longrightarrow} \\enclose{circle}{\\kern.01em y~\\kern .01em}\\) to represent the same concept (in this case, a line with slope \\(m\\) and intercept \\(b\\)!).",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "DSAN 5650",
    "section": "Schedule",
    "text": "Schedule\nThe following is a rough map of what we will work through together throughout the semester; given that everyone learns at a different pace, my aim is to leave us with a good amount of flexibility in terms of how much time we spend on each topic: if I find that it takes me longer than a week to convey a certain topic in sufficient depth, for example, then I view it as a strength rather than a weakness of the course that we can then rearrange the calendar below by adding an extra week on that particular topic! Similarly, if it seems like I am spending too much time on a topic, to the point that students seem bored or impatient to move onto the next topic, we can move a topic intended for the next week to the current week!\n\n\n\nUnit\nWeek\nDate\nTopic\n\n\n\n\nUnit 1: The Language of Causal Modeling\n1\nMay 21\nThe Language of Causal Modeling\n\n\n\n2\nMay 28\nProbabilistic Graphical Models (PGMs)\n\n\nUnit 2: Matching Apples to Apples\n3\nJun 4\n\n\n\n\n4\nJun 11\n\n\n\n\n5\nJun 18\n\n\n\n\n6\nJun 25\n\n\n\nMidterm\n7\nJul 2\nIn-Class Midterm: Causal Models and Statistical Matching\n\n\nUnit 3: Double-Debiased Machine Learning\n8\nJul 9\n\n\n\n\n9\nJul 16\n\n\n\n\n10\nJul 23\n\n\n\n\n11\nJul 30\n\n\n\nUnit 4: Applications\n12\nAug 6\nFinal Project Details\n\n\n\n13\nAug 13\n\n\n\n\n\nMay 10 (Friday)\n[Deliverable] Final Project",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assignments-and-grading",
    "href": "syllabus.html#assignments-and-grading",
    "title": "DSAN 5650",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThe main assignment in the course will be your policy whitepaper, submitted at the end of the semester. However, there will also be a midterm exam and a series of assignments which exist to let you explore each of the modules of the course, in turn.\n\n\n\n\n\n\n\n\nAssignment\nDue Date\n% of Grade\n\n\n\n\nHW1: Causal Modeling via DAGs and PGMs\nFriday, May 30\n10%\n\n\nHW2: TBD\nFriday, February 21\n10%\n\n\nMidterm\nWednesday, February 28\n30%\n\n\nHW3: TBD\nTBD\n10%\n\n\nHW4: TBD\nTBD\n10%\n\n\nFinal Project\nFriday, May 10\n30%\n\n\n\n\nHomework Lateness Policy\nAfter the due date, for each homework assignment, you will have a grace period of 24 hours to submit the assignment without a lateness penalty. After this 24-hour grace period, late penalties will be applied based on the following scale (unless you obtain an excused lateness from one of the instructional staff!):\n\n0 to 24 hours late: no penalty\n24 to 30 hours late: 2.5% penalty\n30 to 42 hours late: 5% penalty\n42 to 54 hours late: 10% penalty\n54 to 66 hours late: 20% penalty\nMore than 66 hours late: Assignment submissions no longer accepted (without instructor approval)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "DSAN 5650",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPearl (2000) represents a key work in this field of research, as it essentially brought together different pieces of causal models into one unified, rigorous framework.↩︎",
    "crumbs": [
      "Syllabus"
    ]
  }
]