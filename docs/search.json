[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "(hare_language_1952?), The Language of Morals [PDF]\n\nThis is the canonical book that explains, in excruciating but necessary detail, the linguistic “core” of the descriptive-versus-normative distinction. It’s overkill to read from cover-to-cover if you just want the gist of the concepts, but if you’re curious about how we can develop a “logic” of normative statements like we have for descriptive statements, this is the key text imo!\n\n(korsgaard_sources_1996?), The Sources of Normativity [PDF]\n\nThis is… definitely up there among my favorite books of all time on this topic (after wading through many of them during the PhD exam gauntlet I mentioned in Week 1): it does what I wish every ethical-philosophy book did, which is, continuing to ask but why?!? to every theory of ethical justification, until it reaches a perspective which (not coincidentally) is quite close to the perspective we adopt early on in this course!\n\n(roemer_theories_1996?), Theories of Distributive Justice [PDF]\n\nI won’t lie to you, this book is pretty brutal in terms of being a mathematical “deep dive” into how the ethical frameworks we discuss in this class can be built up from a set of axioms. So, I don’t recommend the whole thing (that’s why there are two more Roemer books in this section, which are more applied looks at particular ethical frameworks!)\nThe two parts we will draw on, which I do therefore recommend, are the explanations of utility functions in Chapter 1 and of Social Welfare Functionals in Chapter 4\n\n\n\n\n\n\n(roemer_free_1988?), Free to Lose: An Introduction to Marxist Economic Philosophy [PDF]\n(anderson_private_2017?), Private Government: How Employers Rule Our Lives (And Why We Don’t Talk About It) [PDF] [EPUB] [MOBI]\n(rawls_theory_1971?), A Theory of Justice [PDF]\n(roemer_equality_1998?), Equality of Opportunity [PDF]",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#normative-vs.-descriptive-ethical-frameworks",
    "href": "resources.html#normative-vs.-descriptive-ethical-frameworks",
    "title": "Resources",
    "section": "",
    "text": "(hare_language_1952?), The Language of Morals [PDF]\n\nThis is the canonical book that explains, in excruciating but necessary detail, the linguistic “core” of the descriptive-versus-normative distinction. It’s overkill to read from cover-to-cover if you just want the gist of the concepts, but if you’re curious about how we can develop a “logic” of normative statements like we have for descriptive statements, this is the key text imo!\n\n(korsgaard_sources_1996?), The Sources of Normativity [PDF]\n\nThis is… definitely up there among my favorite books of all time on this topic (after wading through many of them during the PhD exam gauntlet I mentioned in Week 1): it does what I wish every ethical-philosophy book did, which is, continuing to ask but why?!? to every theory of ethical justification, until it reaches a perspective which (not coincidentally) is quite close to the perspective we adopt early on in this course!\n\n(roemer_theories_1996?), Theories of Distributive Justice [PDF]\n\nI won’t lie to you, this book is pretty brutal in terms of being a mathematical “deep dive” into how the ethical frameworks we discuss in this class can be built up from a set of axioms. So, I don’t recommend the whole thing (that’s why there are two more Roemer books in this section, which are more applied looks at particular ethical frameworks!)\nThe two parts we will draw on, which I do therefore recommend, are the explanations of utility functions in Chapter 1 and of Social Welfare Functionals in Chapter 4\n\n\n\n\n\n\n(roemer_free_1988?), Free to Lose: An Introduction to Marxist Economic Philosophy [PDF]\n(anderson_private_2017?), Private Government: How Employers Rule Our Lives (And Why We Don’t Talk About It) [PDF] [EPUB] [MOBI]\n(rawls_theory_1971?), A Theory of Justice [PDF]\n(roemer_equality_1998?), Equality of Opportunity [PDF]",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#fairness-in-ai-context-sensitive-fairness",
    "href": "resources.html#fairness-in-ai-context-sensitive-fairness",
    "title": "Resources",
    "section": "Fairness in AI / Context-Sensitive Fairness",
    "text": "Fairness in AI / Context-Sensitive Fairness\n\n(barocas_fairness_2023?), Fairness and Machine Learning: Limitations and Opportunities [PDF]\n\nThis will be our main reference during this portion of the course, and is available for free (legally!) online!\n\n(kasy_fairness_2021?), “Fairness, Equality, and Power in Algorithmic Decision-Making”, FAccT ’21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency [PDF]",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#econometric-policy-evaluation",
    "href": "resources.html#econometric-policy-evaluation",
    "title": "Resources",
    "section": "Econometric Policy Evaluation",
    "text": "Econometric Policy Evaluation\n\n(bjorkegren_machine_2022?), “(Machine) Learning what Policymakers Value”, EAAMO (Equity and Access in Algorithms, Mechanisms, and Optimization) [PDF]",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "midterm.html",
    "href": "midterm.html",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "",
    "text": "The DSAN 5450 in-class midterm will start at 3:30pm on Wednesday, February 26th. It is intended to take only 1.5 hours, but you will have 3 hours to take it just in case, so that it will be due by 6:30pm.\nWe’ve covered a lot of… sometimes-disjointed topics thus far, so our goal for the midterm is to emphasize the most important takeaways from across the first six weeks of the class, by putting them in your brain’s short-term memory one more time before we dive into the second, policy-focused half of the course when you come back from spring break! As a reminder, there is a very good reason to continually try and re-remember the same course topics, coming from studies of long-term memory retention:",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#overview",
    "href": "midterm.html#overview",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "",
    "text": "The DSAN 5450 in-class midterm will start at 3:30pm on Wednesday, February 26th. It is intended to take only 1.5 hours, but you will have 3 hours to take it just in case, so that it will be due by 6:30pm.\nWe’ve covered a lot of… sometimes-disjointed topics thus far, so our goal for the midterm is to emphasize the most important takeaways from across the first six weeks of the class, by putting them in your brain’s short-term memory one more time before we dive into the second, policy-focused half of the course when you come back from spring break! As a reminder, there is a very good reason to continually try and re-remember the same course topics, coming from studies of long-term memory retention:",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#part-1-high-level-data-ethics-considerations",
    "href": "midterm.html#part-1-high-level-data-ethics-considerations",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 1: High-Level Data Ethics Considerations",
    "text": "Part 1: High-Level Data Ethics Considerations\nThis part corresponds roughly to the first two sessions of the course, where we talked about key “high-level” questions in data ethics.\n\n(1.1) The Library of Missing Datasets\nWhy does some information already exist in the form of nicely-formatted, easily-accessible datasets, while other information does not?\n\nHere the specific reference in class was to the Library of Missing Datasets, so you can check out the photos at that link for examples of missing datasets.\nThe midterm question here could, therefore, ask you to think through the process by which a certain dataset came into existence as (e.g.) a clean, easily-available .csv file, and/or why another set of data might not exist in this form.\n\n\n\n(1.2) Operationalization\nWhat types of data-ethical issues arise because of the “gap” between conceptual variables and operationalized variables?\n\nHere the main reference for you is this slide from Week 2\nFor the possible midterm question here, specifically, you should focus on the idea behind the book on the right side of that slide: “Mis-Measuring Our Lives”. That book points out the gap between the conceptual variable [economic well-being] and its operationalization as [GDP].\n\nSo, for the midterm, we might ask you to consider a conceptual variable like “fairness” or “privacy”, and think through different ways they could be operationalized as measurable quantities.",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#part-2-ethical-frameworks",
    "href": "midterm.html#part-2-ethical-frameworks",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 2: Ethical Frameworks",
    "text": "Part 2: Ethical Frameworks\n\n(2.1) Descriptive vs. Normative\nI think you all did a great job of demonstrating that you understand this distinction, through homeworks and discussions (in class and in office hours)! So, on this topic I think you can just review the basic “gist” of how this works:\nTwo types of Descriptive statements:\n\nNon-implicational statements that describe facts, like \\(1 + 1 = 2\\), are descriptive but indeterminate without a set of axioms (definitions for the symbols, in this case)\nImplicational statements that describe facts, like \\(ZFC \\implies 1 + 1 = 2\\), are descriptive and also determinate (in this case, determinately true)\n\nTwo types of Normative statements:\n\nWhen the statements are not descriptions of empirically/observationally (and intersubjectively) verifiable predicates about how things are (“Grass is green”), but are instead prescriptions of how things ought to be (“Grass ought to be green”/“It is good for grass to be green and bad for grass to be blue”), they have additional normative dimensions\nHowever, in the same way that the descriptive statement \\(1 + 1 = 2\\) goes from indeterminate to determine when we provide a set of axioms, normative statements are also transformed from indeterminate to determinate when we provide an ethical framework within which the normative statement can be evaluated.\n\n\n\n(2.2) Consequentialism vs. Deontological Ethics\nThis portion would also very much involve the two most common concrete versions of these two ethical frameworks:\n\nUtilitarianism as the most common consequentialist framework\nKantian Ethics as the most common deontological-ethical framework\n\nOn the latter two points specifically, I didn’t make the distinction as clearly as I should have in class, so I’m making it here!\nQuestion 2.5 from Homework 1 provided the following statement:\n\n«Lying is bad, since you wouldn’t want others to lie to you.»\n\nAnd then, between Consequentialism and Deontological Ethics, the correct answer was that this statement is more straightforwardly implied by Deontological Ethics. I know this one is particularly difficult to think through, but I wanted to highlight it here because this is the question that really reveals the subtle-but-important distinction between these two systems:\n\nA consequentialist approach to “resolving” a dilemma around lying would, crucially, be based on a prediction of the actual consequences that would result from a possible choice, whereas\nA deontological approach differs from this in considering what makes a possible choice good or bad in-and-of-itself, without reference to the predicted consequences.\n\nThe reason I phrase the distinction in this way is because, in the above statement, you can focus on the portion after the word “since” (“since you wouldn’t want others to lie to you”):\n\nWithin a consequentialist framework, this reasoning would not itself constitute a justification for not lying, since it would have to be paired with a statement like “If I lie, then it is likely that others will lie to me”, which is not true in general! The idiom of a “white lie”, for example, comes precisely from the fact that there are often times when we feel like we should lie to people to avoid the consequence of hurting them.\nWithin a deontological framework, on the other hand, this reasoning would constitute a justification for not lying, since it corresponds precisely to the rule that was mentioned in the prior two questions: Kant’s Categorical Imperative.\nThis Categorical Imperative rule is of special interest, relative to the full set of “ethical rules” you could imagine using, because it is a rule for making ethical decisions without reference to the consequences of a particular choice:\n\nInstead of predicting what might happen if I make this choice, and judging whether it is an ethical choice on that basis…\nI now imagine what would happen hypothetically if everyone else in the world made the choice, whether or not my action would in fact make everyone else in the world make the same choice!\n\n\nI hope that explanation, and the reference to “white lies” as an example, can help make it more clear why the answer to Question 2.5 was “Deontological Ethics”. As one final point, to make it super concrete:\n\nThe reason why the answer is not Consequentialism here is because, a Consequentialist might agree that “I wouldn’t want others to lie to me”, and yet also think “But that’s not a good reason to not lie, since I could lie here without it causing others to lie to me.”\nThat is what would enable “white lies” to be acceptable under consequentialism: since you only consider the predicted consequences of your action in the “real world”, rather than in a hypothetical world where everyone does the same action, you are then able to move to a comparison of whether the benefits of lying outweigh the costs of lying, as one way to make the decision (by “calculating” the consequences!).",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#part-3-context-free-fairness-and-proxy-variables",
    "href": "midterm.html#part-3-context-free-fairness-and-proxy-variables",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 3: Context-Free Fairness and Proxy Variables",
    "text": "Part 3: Context-Free Fairness and Proxy Variables\nHere the main idea will be to think through the fairness definitions introduced in this part:\n\nFairness Through Unawareness (Removing “sensitive” variables from the dataset)\nFairness as Equalized Positive Rate\nFairness as Equalized False Positive Rate\nFairness as Equalized False Negative Rate\nFairness as Calibration\n\nAnd especially to be able to understand the “simple” cases when these might work, but also the non-simple cases where these fail to capture what we’d like a robust / actually-usable fairness measure to capture. Some straightforward questions to guide you in this thinking for this part would be, e.g.:\n\nCan we have all of these measures at once?\n\nShort answer: No. But, you should also have some degree of intuition from class about why we can’t (the impossibility results)\n\nThe first four are probably more straightforward, as things we can achieve by dropping variables (Unawarness) or by reading the entries in a confusion matrix. Calibration, however, requires a bit more thought:\n\nHow is calibration defined? The most succinct definition would just be: the requirement that the value of the risk score \\(r(X)\\) that “underlies” the decision-making algorithm (in that it is used to produce our predictions \\(\\widehat{Y}\\)) is itself a probability value—namely, the probability that a person with attributes \\(X\\) has associated outcome \\(Y\\).\nWhy is calibration desirable? Why does it help us in terms of assessing fairness? The definition in the previous bullet point is not very easy-to-understand (to me, at least), so that I interpret it as just a requirement that the risk score “tracks” the relationship between \\(X\\) and \\(Y\\) in a direct way: for example, high values of \\(\\Pr(Y \\mid X)\\) mean high values of the underlying representation \\(r(X)\\) that is used to generate \\(\\widehat{Y}\\) as a prediction of \\(Y\\).\nViewed in this way, then, I hope it makes sense that this property would be desirable in terms of interpretability: it means that, if we wanted to know why our prediction algorithm was producing some specific prediction \\(\\widehat{Y}_i\\) for a person with attributes \\(X_i\\), we could “open up the black box” of the algorithm and look directly at the risk score \\(r(X_i)\\) with respect to the risk score function \\(r(\\cdot)\\) in general, to see why it produced such a high/low value of \\(\\widehat{Y}_i\\).\nI know even that last point can still be confusing, so to me the final “piece” for understanding is to think about how: if we didn’t have calibration, then we would have no natural way of interpreting the risk function \\(r(\\cdot)\\). Since without calibration it is not constrained to represent a probability, it could take on any value—\\(\\pi\\), \\(-1000\\), \\(\\sqrt{2^{100}}\\)—and we would have no way of knowing the relationship between these values and the resulting predictions \\(\\widehat{Y}\\); no way of knowing, for example, why plugging in a person with characteristics \\(X_i\\) produced \\(r(X_i) = \\pi\\) which then led to the prediction \\(\\widehat{Y}_i = 1\\), to detain this person until trial!",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#part-4-context-sensitive-fairness",
    "href": "midterm.html#part-4-context-sensitive-fairness",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 4: Context-Sensitive Fairness",
    "text": "Part 4: Context-Sensitive Fairness\nWe spent some amount of time critiquing the fairness definitions mentioned in the previous section. This was not for the sake of judging whether they’re “good” or “bad” as such, but rather, for the sake of understanding specifically what they’re missing. Two different characterizations of what they’re missing give us our two key context-sensitive approaches to fairness, discussed in the next two sections:\n\n(4.1) Individual-Similarity-Based Fairness\n\nThe Context-Free measures fail to consider how satisfying a criterion (e.g., Equalized False Positive Rate) at a group level could trample over the rights of individuals.\n\nThe illustration of this failure that I mentioned in class boiled down to:\n\nLet \\(A_i\\) represent a sensitive attribute of individuals, such that \\(A_i = 0\\) if person \\(i\\) is white, and \\(A_i = 1\\) if person \\(i\\) is black.\nIf a police department finds itself failing to satisfy a fairness criterion like Equality of Positive Rates, in the sense that their arrest rate \\(r_1\\) for individuals with \\(A_i = 1\\) is higher than their arrest rate \\(r_0\\) for individuals with \\(A_i = 0\\), then…\nThey can quickly “resolve” this failure and satisfy the criterion by running outside and arresting the first \\(N\\) white people they see, where \\(N\\) is the number of additional white arrestees that would be necessary to make \\(r_0 = r_1\\).\n\nHowever, as this illustration hopefully makes clear, this procedure would allow satisfaction of the group-level fairness criterion, but only at the expense of violating our intuitive notions of fairness towards individuals.\nAlthough there are lots and lots of ways that this notion of individual-level fairness could be incorporated into the Context-Free fairness measures to make them Context-Sensitive, one of the most popular and straightforward ways is by constructing an indiviudal-similarity-based fairness measure, and then using it to constrain the space of possible decisions by enforcing the rule that:\n\n\n\n\n\n\nFairness Through Awareness (dwork_fairness_2011?)\n\n\n\nIndividuals who are similar with respect to a task should be classified similarly.\n\n\nThe first thing I want you to note about this approach is that it specifically aims to resolve the issue we’ve already seen with utilitarianism, namely, that * Optimizing society-level desiderata (like “overall happiness”) may lead to * individuals being brutally mistreated (e.g., having their rights violated)\nYou can also hopefully see how this notion (Fairness Through Awarness) could provide a Rawls-style ordering: individual fairness lexically prior to group-level fairness (optimize group-level fairness once individual-level is satisfied).\nThen lastly, as you saw on HW2, this general notion of Fairness Through Awareness can be operationalized as a measurable quantity by, for example, implementing what is generally called metric fairness: Given a similarity metric \\(m: \\mathcal{I} \\times \\mathcal{I} \\rightarrow \\mathbb{R}\\), where \\(\\mathcal{I}\\) is the set of all individuals,\n\\[\n|D_i - D_j| \\leq m(i, j)\n\\]\nfor all pairs of individuals \\((i, j)\\). Or in other words, that the difference between the decisions \\(D_i\\) and \\(D_j\\) should be bounded above by the similarity \\(m(i,j)\\) between \\(i\\) and \\(j\\).\nThis, to me, is already slightly more than you need to know for the midterm, but if you want to dive into this Context-Sensitive approach specifically, Section 5.1 of (mitchell_algorithmic_2021?) has a really great discussion of Metric Fairness specifically.\n\n\n(4.2) Causal Fairness\nThis is the capital-B capital-D Big Deal approach to fairness, in my view, but you’ve already heard enough about that in class and on HW2!\nSo, for the midterm, instead I will just say that the key thing I want you to be comfortable with for now is drawing and interpreting Causal Diagrams like the ones I’ve shown in the slides and drawn on the board in class.\nFirst and foremost, if you absorb the Quick Intro to Probabilistic Graphical Models writeup, you are most of the way there to understanding Causal Diagrams in general, since (sweeping some details under the rug) these Causal Diagrams are primarily just PGMs where we interpret the edges (the arrows in the PGMs) as hypothesized causal effects.\nThus, for the midterm, my first goal is to test your ability to read these PGMs and understand what they’re positing (“saying”) about the world. For example, if I give you a hypothesis like\n\n\\(H_1\\): Individual \\(i\\) was arrested because they are black\n\nYou should be able to “translate” this into a causal diagram based on:\n\nA random variable \\(Y_i\\) representing whether or not an individual \\(i\\) was arrested (where we use the letter \\(Y\\) here speicifcally because we’re representing an outcome that we’re hoping to explain)\nA random variable \\(A_i\\) representing the race of individual \\(i\\), and\nAn edge \\(A_i \\rightarrow Y_i\\), representing the hypothesis that individual \\(i\\)’s specific \\(A_i\\) value (\\(A_i = a_i\\)) is what caused \\(Y_i\\) to take on individual \\(i\\)’s specific \\(Y_i\\) value (\\(Y_i = y_i = 1\\), in this case).\n\nThen, once you’re comfortable with this process of “implementing” hypotheses by constructing causal diagrams, the only other thing I think will be important for the midterm is your ability to adjudicate between two or more such diagrams on the basis of their plausibility.\nWhat I mean by that is… keep in mind the definition of causality that was given in a slide in class:\n\n\n\n\n\n\nDefining Causality (hume_treatise_1739?)\n\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\n\\(X\\) temporally precedes \\(Y\\) and\n\nIn two worlds \\(W_0\\) and \\(W_1\\) where\neverything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\),\n\\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\).\n\n\n\n\nYou should be able to use this definition to (for example) eliminate implausible causal diagrams, namely, causal diagrams which violate the basic predicates within this definition. So, for example, say I gave you the following causal diagram as a causal hypothesis regarding how toasters toast a piece of bread \\(i\\):\n\n\\(T_i\\) is a Random Variable which is \\(0\\) if the bread has not yet been placed in the toaster and \\(1\\) if has been placed in the toaster,\n\\(C_i\\) is a Random Variable which is \\(0\\) if the bread is not cooked, and \\(1\\) if the bread is cooked, and\nThere is an arrow \\(C_i \\rightarrow T_i\\)\n\nYou should be able to identify this as an implausible causal diagram—meaning, a causal diagram representing an implausible hypothesis about how toasters work, relative to the Humean notion of causality—since in our observations of how toasters work, the bread being placed in the toaster (\\(\\text{do}(T_i = 1)\\)) occurs before the bread being cooked \\(C_i = 1\\), temporally.",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#part-5-doin-thangs-causality-continued",
    "href": "midterm.html#part-5-doin-thangs-causality-continued",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 5: Doin Thangs (Causality Continued)",
    "text": "Part 5: Doin Thangs (Causality Continued)\nShort story short, the example from the end of our most recent meeting, where we showed how it’s possible to have:\n\n\\(\\Pr(Y = 1) = p_y\\), and\n\\(\\Pr(Y = 1 \\mid X = 1) \\neq p_y\\), and yet\n\\(\\Pr(Y = 1 \\mid \\text{do}(X = 1)) = p_y\\),\n\nThus revealing the fact that \\(\\Pr(Y = 1 \\mid X = 1)\\) does not capture the causal effect of \\(X\\) on \\(Y\\) in this case, which is just one specific instance of the general maxim you already know, that correlation does not imply causation.\nAnd yet, with this \\(\\text{do}(E)\\) operator (where \\(E\\) is some probabilistic event), we have something concrete that we can use to start figuring out when observing a correlation does allow us to infer a causal effect!\nThe actual figuring-out will have to wait until after the midterm. But I want you to have that notion in your head when you see the \\(\\text{do}(\\cdot)\\) operator and/or a causal diagram: that these are the tools that are going to allow us to bridge this gap between correlation and causation, something that probability theory alone (i.e., the stuff you may have learned in DSAN 5100) cannot do!\nAs a preview, which I mentioned at the very very end of the “do-calculus” example I went through on the board: (pearl_causality_2000?) is literally a gigantic book that meticulously works through all possible causal diagrams1 and proves a massively important theorem that we’ll see after the midterm, which tells us precisely what conditions need to be met (in a given causal system) for us to be able to infer causal effects from conditional probabilities.",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#references",
    "href": "midterm.html#references",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "midterm.html#footnotes",
    "href": "midterm.html#footnotes",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNot like, one-by-one, but by mathematically characterizing all of the possibilities, like how we can say that «Assuming Euclid’s 5th Postulate, the interior angles of a triangle sum to 180°», despite not having gone one-by-one through every triangle.↩︎",
    "crumbs": [
      "Midterm"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSAN 5650: Causal Inference for Computational Social Science",
    "section": "",
    "text": "Welcome to the homepage for DSAN 5650: Causal Inference for Computational Social Science at Georgetown University, for the Summer 2025 session!\nThe course meets on Wednesdays from 6:30pm to 9:00pm online, via the Zoom Link provided in the sidebar.\nCheck out the syllabus (or any other link in the sidebar) for more info! Or, use the following links to view notes for individual weeks:\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1: Introduction to the Course\n\n\nMay 15\n\n\n\n\n\nNo matching items\n\n\nCourse Description:\nThis course provides students with the opportunity to take the analytical skills, machine learning algorithms, and statistical methods learned throughout their first year in the program and explore how they can be employed towards carrying out rigorous, original research in the behavioral and social sciences. With a particular emphasis on tackling the additional challenges which arise when moving from associational to causal inference, particularly when only observational (as opposed to experimental) data is available, students will become proficient in cutting-edge causal Machine Learning techniques such as propensity score matching, synthetic controls, causal program evaluation, inverse social welfare function estimation from panel data, and Double-Debiased Machine Learning.\nIn-class examples will cover continuous, discrete-choice, and textual data from a wide swath of social and behavioral sciences: economics, political science, sociology, anthropology, quantitative history, and digital humanities. After gaining experience through in-class labs and homework assignments focused on reproducing key findings from recent journal articles in each of these disciplines, students will spend the final weeks of the course on a final project demonstrating their ability to develop, evaluate, and test the robustness of a causal hypothesis.\nPrerequisites: DSAN 5000, DSAN 5100 (DSAN 5300 recommended but not required)",
    "crumbs": [
      "<i class='bi bi-house pe-1'></i> Home"
    ]
  },
  {
    "objectID": "writeups/index.html",
    "href": "writeups/index.html",
    "title": "Extra Writeups",
    "section": "",
    "text": "Title\n\n\nLast Updated\n\n\nRelevant To\n\n\nCategory\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Writeups"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignment Point Distributions",
    "section": "",
    "text": "Use the tabs below to view the point distributions for different assignments.\nThe distributions are imported from Google Sheets mainly for transparency: so that you can see exactly how totals are computed as a sum of the individual points allocated for each test!\n\nHW1HW2\n\n\n\n\n\n\n\n\n\npart\nqid\ntest_type\npoints\npart_total\n\n\n\n\n1\nQ1.1\npublic\n0\n12\n\n\n\nQ1.1\nhidden\n1\n\n\n\n\nQ1.2\npublic\n0\n\n\n\n\nQ1.2\nhidden\n1\n\n\n\n\nQ1.3\npublic\n0\n\n\n\n\nQ1.3\nhidden\n1\n\n\n\n\nQ1.4\npublic\n0\n\n\n\n\nQ1.4\nhidden\n1\n\n\n\n\nQ1.5\npublic\n0\n\n\n\n\nQ1.5\nhidden\n1\n\n\n\n\nQ1.6\npublic\n0\n\n\n\n\nQ1.6\nhidden\n1\n\n\n\n\nQ1.7\npublic\n0\n\n\n\n\nQ1.7\nhidden\n1\n\n\n\n\nQ1.8\npublic\n0\n\n\n\n\nQ1.8\nhidden\n1\n\n\n\n\nQ1.9\npublic\n0\n\n\n\n\nQ1.9\nhidden\n1\n\n\n\n\nQ1.10\npublic\n0\n\n\n\n\nQ1.10\nhidden\n1\n\n\n\n\nQ1.11\npublic\n0\n\n\n\n\nQ1.11\nhidden\n1\n\n\n\n\nQ1.12\npublic\n0\n\n\n\n\nQ1.12\nhidden\n1\n\n\n\n2\nQ2.1\npublic\n0\n7\n\n\n\nQ2.1\nhidden\n1\n\n\n\n\nQ2.2\npublic\n0\n\n\n\n\nQ2.2\nhidden\n1\n\n\n\n\nQ2.3\npublic\n0\n\n\n\n\nQ2.3\nhidden\n1\n\n\n\n\nQ2.4\npublic\n0\n\n\n\n\nQ2.4\nhidden\n1\n\n\n\n\nQ2.5\npublic\n0\n\n\n\n\nQ2.5\nhidden\n1\n\n\n\n\nQ2.6\npublic\n0\n\n\n\n\nQ2.6\nhidden\n2\n\n\n\n3\nQ3.1\npublic\n0\n5\n\n\n\nQ3.1\nhidden\n1\n\n\n\n\nQ3.2\npublic\n0\n\n\n\n\nQ3.2\nhidden\n1\n\n\n\n\nQ3.3a\npublic\n0\n\n\n\n\nQ3.3a\nhidden\n1\n\n\n\n\nQ3.3b\npublic\n0\n\n\n\n\nQ3.3b\nhidden\n1\n\n\n\n\nQ3.3c\npublic\n0\n\n\n\n\nQ3.3c\nhidden\n1\n\n\n\n4.1\nQ4.1.1\npublic\n1\n13\n\n\n\nQ4.1.1\nhidden\n2\n\n\n\n\nQ4.1.2\npublic\n1\n\n\n\n\nQ4.1.2\nhidden\n2\n\n\n\n\nQ4.1.3\npublic\n1\n\n\n\n\nQ4.1.3\nhidden\n1\n\n\n\n\nQ4.1.4\npublic\n1\n\n\n\n\nQ4.1.4\nhidden\n2\n\n\n\n\nQ4.1.5\npublic\n1\n\n\n\n\nQ4.1.5\nhidden\n1\n\n\n\n4.2\nQ4.2.1\npublic\n1\n4\n\n\n\nQ4.2.1\nhidden\n1\n\n\n\n\nQ4.2.2\npublic\n1\n\n\n\n\nQ4.2.2\nhidden\n1\n\n\n\n4.3\nQ4.3.1\npublic\n1\n4\n\n\n\nQ4.3.1\nhidden\n1\n\n\n\n\nQ4.3.2\npublic\n1\n\n\n\n\nQ4.3.2\nhidden\n1\n\n\n\n4.4\nQ4.4.1\npublic\n1\n3\n\n\n\nQ4.4.1\nhidden\n2\n\n\n\n4.5\nQ4.5.1\npublic\n1\n4\n\n\n\nQ4.5.1\nhidden\n2\n\n\n\n\nQ4.5.2\npublic\n0\n\n\n\n\nQ4.5.2\nhidden\n1\n\n\n\n4.6\nQ4.6.1\npublic\n1\n3\n\n\n\nQ4.6.1\nhidden\n2\n\n\n\n4.7\nQ4.7.1\npublic\n1\n5\n\n\n\nQ4.7.1\nhidden\n2\n\n\n\n\nQ4.7.2\npublic\n1\n\n\n\n\nQ4.7.2\nhidden\n1\n\n\n\n4.8\nQ4.8.1\npublic\n1\n11\n\n\n\nQ4.8.1\nhidden\n2\n\n\n\n\nQ4.8.2\npublic\n0\n\n\n\n\nQ4.8.2\nhidden\n1\n\n\n\n\nQ4.8.3\npublic\n0\n\n\n\n\nQ4.8.3\nhidden\n1\n\n\n\n\nQ4.8.4\npublic\n1\n\n\n\n\nQ4.8.4\nhidden\n2\n\n\n\n\nQ4.8.5\npublic\n1\n\n\n\n\nQ4.8.5\nhidden\n2\n\n\n\n4.9\nQ4.9.1\npublic\n0\n2\n\n\n\nQ4.9.1\nhidden\n1\n\n\n\n\nQ4.9.2\npublic\n0\n\n\n\n\nQ4.9.2\nhidden\n1\n\n\n\n4.10\nQ4.10.1\npublic\n0\n8\n\n\n\nQ4.10.1\nhidden\n1\n\n\n\n\nQ4.10.2\npublic\n0\n\n\n\n\nQ4.10.2\nhidden\n1\n\n\n\n\nQ4.10.3\npublic\n1\n\n\n\n\nQ4.10.3\nhidden\n2\n\n\n\n\nQ4.10.4\npublic\n1\n\n\n\n\nQ4.10.4\nhidden\n2\n\n\n\n4.11\nQ4.11.1\npublic\n1\n6\n\n\n\nQ4.11.1\nhidden\n2\n\n\n\n\nQ4.11.2\npublic\n1\n\n\n\n\nQ4.11.2\nhidden\n2\n\n\n\n4.12\nQ4.12\npublic\n1\n5\n\n\n\nQ4.12\nhidden\n4\n\n\n\n5\nQ5.1\npublic\n0\n8\n\n\n\nQ5.1\nhidden\n2\n\n\n\n\nQ5.2\npublic\n0\n\n\n\n\nQ5.2\nhidden\n2\n\n\n\n\nQ5.3\npublic\n0\n\n\n\n\nQ5.3\nhidden\n2\n\n\n\n\nQ5.4\npublic\n0\n\n\n\n\nQ5.4\nhidden\n2\n\n\n\nTotal\n\n\n100\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart\nqid\ntest_type\npoints\npart_total\n\n\n\n\n1\nQ1.1\npublic\n0\n\n\n\n\nQ1.1\nhidden\n2\n\n\n\n\nQ1.2\npublic\n0\n\n\n\n\nQ1.2\nhidden\n2\n\n\n\n\nQ1.3a\npublic\n0\n\n\n\n\nQ1.3a\nhidden\n2\n\n\n\n\nQ1.3b\npublic\n0\n\n\n\n\nQ1.3b\nhidden\n2\n\n\n\n\nQ1.4a\npublic\n0\n\n\n\n\nQ1.4a\nhidden\n2\n\n\n\n\nQ1.4b\npublic\n0\n\n\n\n\nQ1.4b\nhidden\n2\n\n\n\n\nQ1.5\npublic\n0\n\n\n\n\nQ1.5\nhidden\n2\n\n\n\n\nQ1.6\npublic\n0\n\n\n\n\nQ1.6\nhidden\n2\n\n\n\n\nQ1.7\npublic\n0\n\n\n\n\nQ1.7\nhidden\n2\n\n\n\n\nQ1.8\npublic\n0\n\n\n\n\nQ1.8\nhidden\n2\n20\n\n\n2\nQ2.1\npublic\n0\n\n\n\n\nQ2.1\nhidden\n5\n\n\n\n\nQ2.2\npublic\n0\n\n\n\n\nQ2.2\nhidden\n5\n10\n\n\n3\nQ3.1a\npublic\n0\n\n\n\n\nQ3.1a\nhidden\n2\n\n\n\n\nQ3.1b\npublic\n0\n\n\n\n\nQ3.1b\nhidden\n2\n\n\n\n\nQ3.2a\npublic\n0\n\n\n\n\nQ3.2a\nhidden\n2\n\n\n\n\nQ3.2b\npublic\n0\n\n\n\n\nQ3.2b\nhidden\n2\n\n\n\n\nQ3.3a\npublic\n0\n\n\n\n\nQ3.3a\nhidden\n2\n\n\n\n\nQ3.3b\npublic\n0\n\n\n\n\nQ3.3b\nhidden\n2\n12\n\n\n4\nQ4.1a\npublic\n0\n\n\n\n\nQ4.1a\nhidden\n2\n\n\n\n\nQ4.1b\npublic\n0\n\n\n\n\nQ4.1b\nhidden\n2\n\n\n\n\nQ4.2a\npublic\n0\n\n\n\n\nQ4.2a\nhidden\n2\n\n\n\n\nQ4.2b\npublic\n0\n\n\n\n\nQ4.2b\nhidden\n2\n\n\n\n\nQ4.3a\npublic\n0\n\n\n\n\nQ4.3a\nhidden\n2\n\n\n\n\nQ4.3b\npublic\n0\n\n\n\n\nQ4.3b\nhidden\n2\n12\n\n\n5\nQ5.1\npublic\n0\n\n\n\n\nQ5.1\nhidden\n4\n\n\n\n\nQ5.2\npublic\n0\n\n\n\n\nQ5.2\nhidden\n4\n\n\n\n\nQ5.3\npublic\n0\n\n\n\n\nQ5.3\nhidden\n4\n12\n\n\n6\nQ6.1\npublic\n0\n\n\n\n\nQ6.1\nhidden\n7\n\n\n\n\nQ6.2\npublic\n0\n\n\n\n\nQ6.2\nhidden\n7\n14\n\n\n7\nQ7.1\npublic\n0\n\n\n\n\nQ7.1\nhidden\n5\n\n\n\n\nQ7.2\npublic\n0\n\n\n\n\nQ7.2\nhidden\n5\n\n\n\n\nQ7.3\npublic\n0\n\n\n\n\nQ7.3\nhidden\n5\n\n\n\n\nQ7.4\npublic\n0\n\n\n\n\nQ7.4\nhidden\n5\n20\n\n\nTotal\n\n\n100\n100",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "final.html",
    "href": "final.html",
    "title": "Final Project Specifications",
    "section": "",
    "text": "Our goal is to make the final project as open-ended as possible, to give you the space to explore any particular topic that may have piqued your interest throughout the semester! At the same time, we hope to provide you with guidance and mentorship so that you don’t feel lost as to how to start, how to proceed, and/or what to submit for the final deliverable!1\nSo, given this, we have randomly assigned each of you to a mentor, who will help you select a topic and pursue it in such a way that it fits within the scope of the remaining weeks in the semester. You will receive an email letting you know who your mentor is, by the end of the weekend (Sunday, March 24th). The mentor assignments can always be re-arranged, however! For example, if you decide to pursue a project that another mentor has particular experience with, we can re-assign you to that mentor!\n\n\n\n\n\n\nThe Goal: Research \\(\\rightarrow\\) Policy Recommendation\n\n\n\nAlthough the structure can be mostly similar to projects you’ve done for e.g. DSAN 5000 and 5100, the new element for the DSAN 5450 project is that we want you to develop and argue for a particular policy recommendation that you’d make, for example if you were asked to speak in Congress as a data science expert!\nThis means, for example, that your deliverable can have the following structure in terms of section headings, which should be familiar from DSAN 5000 and 5100 except for the final section:\n\nIntroduction\nLiterature Review\nData and Methods\nResults\nPolicy Recommendation\n\nThe policy recommendation portion will look different depending on the particular topic you decide to explore, but the idea is that it should be somewhat like a policy whitepaper, where you would move away from the details of your study and towards its implications for a (real or imagined) policymaker who is hoping for information about a given topic.\nOne recent example that you can look at as a rough template would be Chris Callison-Burch’s Congressional testimony, given last year as part of a Congressional hearing around issues that LLMs might present for intellectual property and copyright law. Prof. Callison-Burch discusses the process in this podcast episode, so you can listen to that for details about the approach he took towards the invitation from Congress, but the tldr is: he needed to communicate just enough detail to allow the policymakers to understand what he was talking about, but not so much detail that they would need to have a PhD in Computer Science to understand his recommendations.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#overview",
    "href": "final.html#overview",
    "title": "Final Project Specifications",
    "section": "",
    "text": "Our goal is to make the final project as open-ended as possible, to give you the space to explore any particular topic that may have piqued your interest throughout the semester! At the same time, we hope to provide you with guidance and mentorship so that you don’t feel lost as to how to start, how to proceed, and/or what to submit for the final deliverable!1\nSo, given this, we have randomly assigned each of you to a mentor, who will help you select a topic and pursue it in such a way that it fits within the scope of the remaining weeks in the semester. You will receive an email letting you know who your mentor is, by the end of the weekend (Sunday, March 24th). The mentor assignments can always be re-arranged, however! For example, if you decide to pursue a project that another mentor has particular experience with, we can re-assign you to that mentor!\n\n\n\n\n\n\nThe Goal: Research \\(\\rightarrow\\) Policy Recommendation\n\n\n\nAlthough the structure can be mostly similar to projects you’ve done for e.g. DSAN 5000 and 5100, the new element for the DSAN 5450 project is that we want you to develop and argue for a particular policy recommendation that you’d make, for example if you were asked to speak in Congress as a data science expert!\nThis means, for example, that your deliverable can have the following structure in terms of section headings, which should be familiar from DSAN 5000 and 5100 except for the final section:\n\nIntroduction\nLiterature Review\nData and Methods\nResults\nPolicy Recommendation\n\nThe policy recommendation portion will look different depending on the particular topic you decide to explore, but the idea is that it should be somewhat like a policy whitepaper, where you would move away from the details of your study and towards its implications for a (real or imagined) policymaker who is hoping for information about a given topic.\nOne recent example that you can look at as a rough template would be Chris Callison-Burch’s Congressional testimony, given last year as part of a Congressional hearing around issues that LLMs might present for intellectual property and copyright law. Prof. Callison-Burch discusses the process in this podcast episode, so you can listen to that for details about the approach he took towards the invitation from Congress, but the tldr is: he needed to communicate just enough detail to allow the policymakers to understand what he was talking about, but not so much detail that they would need to have a PhD in Computer Science to understand his recommendations.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#timeline",
    "href": "final.html#timeline",
    "title": "Final Project Specifications",
    "section": "Timeline",
    "text": "Timeline\nThese are rough estimates, but the project will go most smoothly if you are able to hold yourself to the following schedule:\n\nProposal: Approved by mentor by Wednesday, April 3rd\nFinal Draft: Sent to mentor for review by Wednesday, April 24th\nSubmission: Completed project submitted to course staff by Friday, May 10th, 5:59pm EDT",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#submission-format",
    "href": "final.html#submission-format",
    "title": "Final Project Specifications",
    "section": "Submission Format",
    "text": "Submission Format\nThere is now an assignment page for the final project (within the Google Classroom site for the course), where you will upload your final submission for grading. The following is a rough sketch of what we’re looking for in terms of the structure of your submission:\n\nHTML format, as a rendered Quarto manuscript, would be optimal, but can be PDF if there are issues with Quarto. If PDF, LaTeX would be preferred, but also can be a Word doc or Google doc\nIf PDF format, 8-20 pages double-spaced, and then the Quarto HTML length can be the equivalent of this (for example, you can print-preview the Quarto doc to see how many pages it would print as)\nIt should have an abstract, a 250-500 word summary at the top, of (a) what you did and (b) the policy recommendation you’re making\nCitations should be set up so that they’re handled automatically, by Quarto’s citation manager for example, or by Bibtex if you use LaTeX to generate a PDF, or by Word/GDocs otherwise.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#the-proposal-stage",
    "href": "final.html#the-proposal-stage",
    "title": "Final Project Specifications",
    "section": "The Proposal Stage",
    "text": "The Proposal Stage\nOur goal here is for you to have enough time to think through the details in advance, to determine the scope, of the project, before you actually start working on it. This is often (like, almost always) the most difficult part of any project: it’s not a matter of whether you’re capable of doing the project at all—you’re all capable of doing it!—but how feasible it is to do it within the given timeframe.\nSo, this is exactly why there’s a course staff here to help you! We’ve all wrestled with this issue of “scope creep” throughout our own previous projects, which means that our goal in providing feedback on your proposals will be solely to help you brainstorm and then focus in on what you can accomplish by the beginning of May. Thus, to reiterate, you should not view the proposal feedback as some sort of judgement of your innate ability or anything like that! And, to this end, it will not be graded, which we hope will further cement the idea that it is not a judgement process, but a working-together process to arrive at a plan for getting the project done.\nTo conclude, concretely: you’ll be “done” with the proposal stage once you and your mentor are on the same page in terms of\n\nWhat topic you’re going to pursue,\nWhat your final deliverable will look like, and\nA set of milestones you will use from now until the beginning of May to track your progress.\n\nAt that point, you’ll be ready for the implementation stage, described in the next section.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#the-implementation-stage",
    "href": "final.html#the-implementation-stage",
    "title": "Final Project Specifications",
    "section": "The Implementation Stage",
    "text": "The Implementation Stage\nThis stage is more difficult to describe in advance, since it depends on the specific topic you’ll pursue. But, the main goal is for you to have a draft version of the project ready by Wednesday, April 24th. We choose this date specifically because it corresponds to the final lecture in the course, so that as part of that lecture Jeff can make sure to touch on any remaining issues that might still need to be tackled in order to move from the draft to the submission on the last day of the semester.\nHowever, given this explanation, hopefully it makes sense that the earlier you have a draft, the better, since an earlier draft means that Jeff can also use the lectures before the final lecture to cover any topics which might be relevant to your projects! In other words: the whole reason why the last few lectures of the course are set aside as “Selected Topics” is so that these lectures can adapt to cover whatever might be relevant and important for the range of topics yall choose for your final projects! So, please take advantage of this aspect of the class if you can.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#example-project-ideas",
    "href": "final.html#example-project-ideas",
    "title": "Final Project Specifications",
    "section": "Example Project Ideas",
    "text": "Example Project Ideas\nNow that you have all of the above info, we wanted to make it clear that it’s okay if you don’t have any idea of what topic you’d like to pursue for the project! Some people come into the course with a very particular interest, whereas others come in for the sake of learning a broad overview of a bunch of topics, and we’re here to accommodate both cases 😁 So, if you don’t have a preexisting idea of what you’d like to pursue, in this section we provide you with a few examples—one example per course topic—that you can choose as-is or modify to suit your interests.\nAs you’ll quickly see if you start reading through the examples, there are tons and tons of details and tons and tons of variations/modifications that could be made, that I’m unable to state in detail without making this a 1000-page document 😜 so, just keep in mind that if anything at all pops into your head while reading through them, even if the thing that pops into your head doesn’t “match” the specific details of one of the projects here, that’s a good thing! You can take that and run with it, turning it from an idea into a full-blown project by talking through it with your mentor.\n\nHigh-Level Data Science Questions\n\nExample 1: Archive of Missing Datasets\nHere there are tons of possibilities for each “sub-topic” that we covered during the broad overview of data science issues given in Week 1 and Week 2. But, one that I think could be interesting and relevant to the policy-focused goal of the final project would be to pursue the idea of the Archive of Missing Datasets:\nYou may have found, when working on your own projects or the DSAN 5000/5100 projects, that there are lots of datasets that you assume must exist somewhere, but you then find to your horror that they actually don’t exist, at least not in a form that would allow for a useful/informative data analysis.\nSo, if you have experienced this, or if you haven’t but you’re interested in discovering what might be egregious/socially-important cases of missing datasets, your final project could revolve around recommending to policymakers that they invest in (as in, allocate resources towards in general, not just money!) the creation of a currently non-existent dataset.\nThis is precisely what has motivated one of the biggest society-wide DSAN 5450-related developments in the US of recent years: in the aftermath of the sudden publicity that rampant police murder of black people across the country received because of cases like the murders of\n\nTrayvon Martin in Florida,\nFreddie Gray in Baltimore, Maryland,\nMichael Brown in Ferguson, Missouri,\nEric Garner in Staten Island, New York,\nGeorge Floyd in Minneapolis, Minnesota, and\nPhilando Castile in St. Paul, Minnesota,\n\nmany people were shocked to learn that the US government doesn’t care enough to keep track of these killings in any systematic way, which led to data-journalistic endeavors like the Washington Post’s “Fatal Force” police killings database.\nOnce these endeavors were established, however, the next “phase” of policy debates on this issue have revolved around whether and/or how data on these types of socially-important phenomena should in fact be collected by publicly-funded government institutions, given that (in this case) the police officers doing the killings are themselves publicly-funded government employees.\nSo, as an example final project on this issue of missing datasets, you could:\n\nIdentify another such socially-important phenomenon for which there is a dearth of available data that would be helpful for some social goal,\nDocument the details around what data already exists regarding this phenomenon (descriptively), and why it is insufficient from a social perspective (normatively), and then\nArgue that the policymaking audience of your project should in fact allocate resources towards the collection of this data (note the shift from descriptive to normative here!): for example, you would need to argue for the feasibility of this collection—providing concrete details about precisely how it could be implemented, in a cost-effective manner, given some budget—as well as its effectiveness with respect to some explicitly-stated social goal (like, in the above example, the goal could simply be to reduce the frequency of police killings).\n\n\n\nExample 2: Operationalization\nIn the Week 1 slides I included a brief discussion of operationalization in terms of a book by \"\"\"Nobel Prize\"\"\"-winning economists2 Joseph Stiglitz and Amartya Sen called Mismeasuring our Lives: Why GDP Doesn’t Add Up (stiglitz_mismeasuring_2010?). This example project outline is sort of a “variation” of Example 1, since basically what I would recommend if you’re interested in this topic would be very similar:\nWhereas the goal of the Archive of Missing Datasets is to point out how there is lots of socially-important information that is not measured at all, Stiglitz and Sen are pointing to equally-urgent and equally-deleterious (often way more urgent/deleterious!) cases where the information is measured, but where the way that it is measured is harmful with respect to the social goal which motivated the measurement in the first place.\nSo, we can take the description of Example 1 above, and basically just replace “missing” with “badly measured”, to see how a project studying operationalization could work:\n\nIdentify a socially-important phenomenon for data does exist but is measured in a way that is relatively unhelpful/non-useful with respect to some social goal (that is, relative to another way of measuring it which could be mroe helpful/useful),\nDocument the details around what data already exists regarding this phenomenon (descriptively), and why it is unhelpful for measuring the social phenomena of interest (normatively), and then\nArgue that the policymaking audience of your project should in fact allocate resources towards the better operationalization that you are proposing (note the shift from descriptive to normative here!): for example, you would need to argue for the feasibility of this new measure—providing concrete details about precisely how it could be implemented, in a cost-effective manner, given some budget—as well as its greater effectiveness than previous ways of measuring, with respect to some explicitly-stated social goal (like, in the earlier example, reducing the frequency of police killings).\n\nAs you can maybe tell by now, the “boundary” between missing data and badly-measured data is sometimes fuzzy: for example, often data-policy debates will say that a certain dataset is missing as shorthand for something more like “it’s measured so badly that, for all intents and purposes it may as well be missing”.\nFor example, technically (until 2019) the FBI used to issue what were called Uniform Crime Reports, but these were based on a “voluntary-reporting” model, meaning that individual police departments could submit whatever data they wanted, and withhold whatever data they wanted, without explanation or documentation, so… from what I can tell, after 2019 they just gave up, since a voluntary-reporting dataset of crime certainly falls under the rubric of may-as-well-be-missing. But, alas, these reports are still used widely in various academic studies of crime, books, journalistic investigations, etc., so if that’s at all interesting to you, it could be studied for a final project that would treat it as a mixture of the missing data and badly-operationalized data issues.\n\n\n\nFairness\nAs we discussed in Week 4 (specifically, I wrote it on the chalkboard and talked through it as an example, on the basis of stuff in those W04 slides), one of the most high-profile cases of algorithmic discrimination in the 21st century emerged out of the ProPublica vs. Northpointe Scandal.\nThe rough summary is that:\n\nAlthough ProPublica meticulously documented anti-black racial discrimination in Northpointe’s COMPAS algorithm in terms of the classification parity fairness measure,\nNorthepointe then responded by meticulously documenting the absence of anti-black racial discrimination in COMPAS in terms of the predictive parity fairness measure\n\nSo, since this is one of the most-often-analyzed datasets in the Fairness in AI literature, your final project could be to pursue this case in a more in-depth way than we were able to cover it in class. This would involve writing a policy paper with two main parts:\n\nExplaining the ProPublica-Northpointe controversy descriptively, by demonstrating how the data simultaneously violates classification parity fairness while satisfying predictive parity fairness. Specifically, this would mean:\n\nExplaining the two fairness definitions to an audience of policymakers and then\nWriting Python or R code which downloads the data and evluates it programmatically on these two different fairness criteria\n\nEvaluating the ProPublic-Northpointe controversy normatively, by providing recommendations for policymakers in terms of how they ought to adjudicate this case. There are several ways you could approach this, but the first two example approaches that come to mind are:\n\nArguing that one of these two fairness criteria better “aligns” with an ethical framework that you think the policymakers should adopt—for example, you could adopt utilitarianism as your ethical “axiom”, and then argue that one of these criteria is more appropriate for evaluating outcomes than the other, and therefore better suited to resolving the dispute in a utilitarian manner\nArguing that neither of the two fairness criteria are sufficient for policymaking, and arguing that policymakers should instead use a framework like \\(\\varepsilon\\)-based fairness or causal fairness to resolve the dispute.\n\n\n\n\nCausality\nAn example project on this topic could pursue the type of approach that appeared on your Homework 2, in Part 3.3, which presented two different hypotheses regarding the causal mechanism by which women experience worse mental health outcomes. You don’t need to pursue this particular question, or use these particular variables in your causal model! But, I am copying some of the key parts of that problem here, along with explanations of how you could pursue this type of analysis in a more in-depth way for a final project.\nThe homework problem presented a simplified version of a causal system studied using causal diagrams in Chapter 16 of Kaufman and Oakes (2006): Glymour (2006), “Using Causal Diagrams to Understand Common Problems in Social Epidemiology”. The idea was to consider an imaginary debate (though one that happens between real people all the time, when taking about this issue!) between:\n\nPerson \\(i\\), who hypothesizes that women have greater rates of depression because they are “‘biologically programmed’ to be depressed” (ibid., pg. 408), and\nPerson \\(j\\), who hypothesizes that women have greater rates of depression because\n\n\n“People get depressed whenever they are sexually harassed” (ibid.), and\n\n\n“Women are more frequently sexually harassed than men” (ibid.)\n\n\n\nIt then took this debate and tried to “zero in” on the particular variables that came into play in the respective arguments:\n\n\\(A\\): The gender of an individual (as before, conceptualized as their self-reported and/or socially-expressed gender), where \\(A = 1\\) for self-reported females and \\(A = 0\\) for those who do not self-report as female\n\\(B\\): An indicator variable representing some biological property of the individual (in these debates, this would most commonly be e.g. \\(B = 1\\) for the presence of at least one Y-chromosome and \\(B = 0\\) otherwise)\n\\(H\\): Whether or not someone experiences sexual harassment, where \\(H = 1\\) represents that the individual has experienced such harassment and \\(H = 0\\) represents that they have not experienced it\n\\(Y\\): The “outcome” of whether or not someone has developed depression, where \\(Y = 1\\) represents an individual with depression and \\(Y = 0\\) represents an individual without depression\n\nAnd, once these variables were established, we were able to “encode” the two hypothesized causal pathways within the same causal diagram:\n\n\n\nWe then looked at two subgraphs of the full causal diagram, with the following subgraph representing person \\(i\\)’s hypothesis:\n\n\n\nAnd this alternative subgraph representing person \\(j\\)’s hypothesis:\n\n\n\nSo, for your final project, you could take a debate around a social issue that is particularly important or particularly interesting to you and perform a causal analysis of it using this general framework.\nThe idea would be to choose a topic where you think that detailing the causal connections between variables in this manner could aid policymakers in addressing the underlying problem.\nLots of examples immediately come to mind (though they are Jeff-style examples so you don’t need to choose any of them, I promise! 😜), but throughout the semester many of the examples in class revolved around the causal pathways linking race with policing, incarceration, and the criminal justice system. From the perspective of a policymaker—the perspective you should have in mind for the final project!—some of the key issues that could be analyzed using frameworks from DSAN 5450 would be:\n\nHow do variables related to social conditions (e.g., poverty, quality of schools) causally interact with variables related to individual choices (e.g., searching for a job, pursuing additional years of school, allocating income between saving and spending) to produce outcomes like career “success” (say, moving into a higher or lower income bracket relative to the bracket one is born into), crime, and/or trust in government?\nHow might it help policymakers to think causally, in terms of how different interventions might counterfactually help or harm some goal that they have?\n\nHere you could choose an existing but vague policy debate like “do police and metal detectors in school help or harm students’ educations?”, and make it more concrete by describing a causally-robust study that could be performed to slightly move this debate away from people-yelling-opinions-at-each-other and towards people-studying-the-causal-impacts-of-interventions… If you were actually able to go out and collect data relevant to these debates, and perform a causal analysis using this data, that would be the holy grail! But, I promise, given the timespan you have, a careful and well-thought-out description of what this type of study would look like and how it could be carried out would be sufficient for the project.\n\n\n\n\nPrivacy and Data Protection Policies\nHere there were a couple of points during Week 8 and Week 9 where I mentioned possible final project ideas, but the first two that come to mind are:\n\nIn this slide during Week 8, I pointed out how there are far too many different data-protection policy frameworks, spanning across too many different countries and states, for me to be able to cover them all. So, your project could be to pursue this further than we were able to in class! But, that’s a bit general, so to make it more specific, the types of projects I briefly outlined in Week 8 were along the lines of:\n\nChoose a country/state that you think is a “policy innovator”, and then see how the data-protection policies from this country/state “diffuse outwards” and get adopted over time by other countries/states. Although one way to do this would be to find a manually-curated dataset which contains (e.g.) 0/1 variables representing whether a given state has adopted a given data-protection policy at a given time (and these datasets definitely exist, and we can help you find them!), to me another cool way to study this would be to use NLP text-reuse detection algorithms like Passim, to “automatically” detect policy adoption by just seeing when text from country \\(A\\)’s data-protection laws appears in another country \\(B\\)’s data-protection laws.\nRather than a diffusion study like this, you could instead carry out what’s called a cross-sectional analysis of countries/states and their data-protection policies: to me, one interesting cross-sectional study could be to see how a country’s form of government relates to the data-protection laws it adopts: are there systematic differences between the data-protection policies adopted by hereditary monarchies in the Middle East like Saudi Arabia or Bahrain and those adopted by comparable (as in, in this case, historically-culturally similar—remember our idea of fair comparison!) Middle Eastern countries with democratic institutions like Yemen or Lebanon?3\n\nOne other potential project I mentioned in both Week 8 and Week 9 would be a project studying how ambiguity is used instrumentally in privacy policies to shift power from users to companies, since these companies possess greater residual rights of control—the right to determine “what happens” when there is ambiguity in a contract—relative to users. The slides for both weeks contained the plot from (wagner_privacy_2023?) showing the growth in “obfuscatory words” in privacy policies over time, but I also mentioned how the goal of (wagner_privacy_2023?) was to point out how NLP could be used to try and “combat” the power imbalances induced by this ambiguity.\nSo, one example of a final project pursuing this thread could be a policy paper wherein you code and demonstrate a proof of concept of how a “privacy policy badness detector” could work: it’s the thing I talked about near the beginning of Week 9, where, you could have a user specify their privacy “boundaries”, and then you could have code that uses NLP tools to parse privacy policies to identify statements which might enable the company to violate these boundaries, highlighting them for the user so that they don’t have to read the entire thing manually!\nScope-wise, that would be pretty ambitious, so to me a very reasonable final project could just be a more “naïve” version of this, where users could just specify key terms of interest to them (say, “medical data”), and then maybe the app could be a browser extension which removes all of the parts of the privacy policy besides the parts which may be relevant to the user’s key terms. Then, in your paper, you would want to make an argument to policymakers on the basis of what you “found” in making the app—for example, if you found that there were clauses that were relevant to medical data but where this relevance was “hidden” because of the ambiguity of the language used, then perhaps you could recommend that they pass a law requiring companies to tag each paragraph of their privacy policies with what aspects of privacy they relate to, as a concrete way to ameliorate the “ambiguity problem”!\n\n\n\nPolicy Evaluation / Recommendation\nSince we haven’t covered this yet, I will just provide an example of a policy-evaluation final project in class this week (Week 10), and then I will copy it into this section.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#references",
    "href": "final.html#references",
    "title": "Final Project Specifications",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final.html#footnotes",
    "href": "final.html#footnotes",
    "title": "Final Project Specifications",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you can’t tell, my whole educational philosophy here is just the Montessori system—this approach was originally developed for younger (primary school) children, but lots and lots of recent educational research indicates that it’s an actually an extremely effective way to learn, and to motivate self-learning, for people of any age 😎↩︎\nEven though I’m biased in the opposite direction of belittling them—since Joseph Stiglitz and Amartya Sen are two of my heroes, and Stiglitz even gave me nice comments on my dissertation and stuff since I was at Columbia with him—it’s honestly important to put \"\"\"Nobel Prize in Economics\"\"\" in triple-quotes, since unlike the “real” (non-triple-quoted) Nobel Prizes, the \"\"\"Nobel Prize\"\"\" in economics was actually created about 80 years after the real ones established by Alfred Nobel, and were explicitly part of the movement by the so-called “Chicago School” of economics to legitimize their particular brand of economics as a “““science”““, and thus delegitimze any other approach to economics as”non-scientific”… For a quick overview with a link to a great interview with Philip Mirowski, here’s a FiveThirtyEight article: “The Economics Nobel Isn’t Really A Nobel”. But the full-on, in-depth essay I’d truly recommend is Yasha Levine’s “It’s all a big lie. There is no ‘Nobel Prize’ in Economics.” &lt;/rant&gt;↩︎\nObviously there are tons of details and particular considerations that you might have to take into account for these types of studies, but that’s exactly the type of thing that the TAs and I can help you with! If you go with this particular choice, for example, you’d have to make sure to control for considerations like the fact that these countries vary in terms of ethnic and/or religious “homogeneity”: About 85% of Saudi Arabian citizens are Sunni Muslim Arabs, for example, whereas Lebanon is basically a patchwork of dozens of different salient religious/cultural/ethnic identities, which would be relevant in the sense that different identity groups within a country might have vastly different dispositions towards how their data should be collected and used!↩︎",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "w01/index.html",
    "href": "w01/index.html",
    "title": "Week 1: Introduction to the Course",
    "section": "",
    "text": "Open slides in new window →",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#prof.-jeff-introduction",
    "href": "w01/index.html#prof.-jeff-introduction",
    "title": "Week 1: Introduction to the Course",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#grad-school",
    "href": "w01/index.html#grad-school",
    "title": "Week 1: Introduction to the Course",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\n\nColumbia for PhD[+Postdoc] in Political Science (2015-2023)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#dissertation-political-science-history",
    "href": "w01/index.html#dissertation-political-science-history",
    "title": "Week 1: Introduction to the Course",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#why-is-georgetown-having-me-teach-this",
    "href": "w01/index.html#why-is-georgetown-having-me-teach-this",
    "title": "Week 1: Introduction to the Course",
    "section": "Why Is Georgetown Having Me Teach This?",
    "text": "Why Is Georgetown Having Me Teach This?\n\n\n\n\n\n\n\nQuanty things, but then PhD major was Political Philosophy (concentration in International Relations)\nWhat most interested me: unraveling history; Easy to get lost in “present-day” details of e.g. debiasing algorithms and fairness in AI, but these questions go back literally thousands of years!\nPol philosophers distinguish “ancients” and “moderns” based on a crucial shift in perspective: ancients sought perfection, while (rousseau_social_1762?) “took men [sic] as they are, and laws as they could be”.\n\n\n\n\n\n\n\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\nimport pandas as pd\nyear_df = pd.DataFrame({\n  'field': ['Math&lt;br&gt;(BS)','CS&lt;br&gt;(BS,MS)','Pol Phil&lt;br&gt;(PhD Pt 1)','Econ&lt;br&gt;(BS+Job)','Pol Econ&lt;br&gt;(PhD Pt 2)'],\n  'cat': ['Quant','Quant','Humanities','Social Sci','Social Sci'],\n  'yrs': [4, 6, 3, 6, 5]\n})\nfig = px.sunburst(\n    year_df, path=['cat','field'], values='yrs',\n    width=450, height=400, color='cat',\n    color_discrete_map={'Quant': cb_palette[0], 'Humanities': cb_palette[1], 'Social Sci': cb_palette[2]},\n    hover_data=[]\n)\nfig.update_traces(\n   hovertemplate=None,\n   hoverinfo='skip'\n)\n# Update layout for tight margin\n# See https://plotly.com/python/creating-and-updating-figures/\nfig.update_layout(margin = dict(t=0, l=0, r=0, b=0))\nfig.show()\n\n                                                \n\n\n\n\n\nFigure 1: Years spent questing in various dungeons of academia\n\n\n\n\n\n\n\nBut is separation of ethics from politics possible? (bowles_moral_2016?) Should we accept “human nature” as immutable/eternal? My answer: yes AND no simultaneously…",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#dialectics",
    "href": "w01/index.html#dialectics",
    "title": "Week 1: Introduction to the Course",
    "section": "Dialectics",
    "text": "Dialectics",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#my-biases",
    "href": "w01/index.html#my-biases",
    "title": "Week 1: Introduction to the Course",
    "section": "My Biases",
    "text": "My Biases\n\n\n\n\n\n\n\nUpbringing: religious Jewish, right-wing (Revisionist Zionist) Republican environment\n“Encouraged” to emigrate to Israel for IDF service, but after learning history I renounced citizenship etc., family no longer big fans of me (Traumatic and scary to talk about, tbh 🙈)\n2015-present: Teach CS + design thinking in refugee camps in West Bank and Gaza each summer (Code for Palestine)\nMetaethics: Learn about the world, challenge+update prior beliefs (Bayes’ rule!); I hope to challenge+update them throughout semester, with your help 🙂",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#on-the-one-hand",
    "href": "w01/index.html#on-the-one-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the One Hand…",
    "text": "On the One Hand…",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#on-the-other-hand",
    "href": "w01/index.html#on-the-other-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the Other Hand…",
    "text": "On the Other Hand…",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#remembering-why-it-matters",
    "href": "w01/index.html#remembering-why-it-matters",
    "title": "Week 1: Introduction to the Course",
    "section": "Remembering Why It Matters",
    "text": "Remembering Why It Matters",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#rules-of-thumb",
    "href": "w01/index.html#rules-of-thumb",
    "title": "Week 1: Introduction to the Course",
    "section": "Rules of Thumb",
    "text": "Rules of Thumb\n\n\n\n\n\n\n\nAsk questions about power \\(\\leadsto\\) inequities, but especially about structures/processes that give rise to them!\n“Philosophers have hitherto only tried to understand the world; the point, however, is to change it.” (marx_thesen_1845?)\nDialectical implication: the more we understand it the better we’ll be at changing it\n\n\n\n\n\n\nRicardo Morales Art Studio / My office",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#axiomatics",
    "href": "w01/index.html#axiomatics",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatics",
    "text": "Axiomatics\n\n\n\n\n\n\n\n\nPopular understanding of math: Deals with Facts, statements are true or false\n\nEx: \\(1 + 1 = 2\\) is “true”\n\nReality: No statements in math are absolutely true! Only conditional statements are possible to prove!\nWe cannot prove atomic statements \\(q\\), only implicational statements: \\(p \\implies q\\) for some axiom(s) \\(p\\).\n\n\\(1 + 1 = 2\\) is indeterminate without definitions of \\(1\\), \\(+\\), \\(=\\), and \\(2\\)!\n(Easy counterexample for math/CS majors: \\(1 + 1 = 0\\) in \\(\\mathbb{Z}_2\\))\n\n\n\n\n\n\n\n\n(steingart_axiomatics_2023?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#example-1-1-2",
    "href": "w01/index.html#example-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: \\(1 + 1 = 2\\)",
    "text": "Example: \\(1 + 1 = 2\\)\n\n\n\n\n\n\n\nHow it’s taught: this is a rule, and if you don’t follow it you will be banished to eternal hellfire\nHow it’s proved: \\(ZFC \\implies [1 + 1 = 2]\\), where \\(ZFC\\) stands for the Zermelo-Fraenkel Axioms with the Axiom of Choice!\n\n\n\n\n\n\n(whitehead_principia_1910?), p. 83. See here for page in context",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#proving-1-1-2",
    "href": "w01/index.html#proving-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Proving \\(1 + 1 = 2\\)",
    "text": "Proving \\(1 + 1 = 2\\)\n(A non-formal proof that still captures the gist:)\n\nAxiom 1: There is a type of thing that can hold other things, which we’ll call a set. We’ll represent it like: \\(\\{ \\langle \\text{\\textit{stuff in the set}} \\rangle \\}\\).\nAxiom 2: Start with the set with nothing in it, \\(\\{\\}\\), and call it “\\(0\\)”.\nAxiom 3: If we put this set \\(0\\) inside of an empty set, we get a new set \\(\\{0\\} = \\{\\{\\}\\}\\), which we’ll call “\\(1\\)”.\nAxiom 4: If we put this set \\(1\\) inside of another set, we get another new set \\(\\{1\\} = \\{\\{\\{\\}\\}\\}\\), which we’ll call “\\(2\\)”.\nAxiom 5: This operation (creating a “next number” by placing a given number inside an empty set) we’ll call succession: \\(S(x) = \\{x\\}\\)\nAxiom 6: We’ll define addition, \\(a + b\\), as applying this succession operation \\(S\\) to \\(a\\), \\(b\\) times. Thus \\(a + b = \\underbrace{S(S(\\cdots (S(}_{b\\text{ times}}a))\\cdots ))\\)\nResult: (Axioms 1-6) \\(\\implies 1 + 1 = S(1) = S(\\{\\{\\}\\}) = \\{\\{\\{\\}\\}\\} = 2. \\; \\blacksquare\\)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#how-is-this-relevant-to-ethics",
    "href": "w01/index.html#how-is-this-relevant-to-ethics",
    "title": "Week 1: Introduction to the Course",
    "section": "How Is This Relevant to Ethics?",
    "text": "How Is This Relevant to Ethics?\n(Thank you for bearing with me on that 😅)\n\nJust as mathematicians slowly came to the realization that\n\n\\[\n\\textbf{mathematical results} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nI hope to help you see how\n\n\\[\n\\textbf{ethical conclusions} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nWhen someone says \\(1 + 1 = 2\\), you are allowed to question them, and ask, “On what basis? Please explain…”.\n\nHere the only valid answer is a collection of axioms which entail \\(1 + 1 = 2\\)\n\nWhen someone says Israel has the right to defend itself, you are allowed to question them, and ask, “On what basis? Please explain…”\n\nHere the only valid answer is an ethical framework which entails that Israel has the right to defend itself.",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#axiomatic-systems-statements-can-be-true-and-false",
    "href": "w01/index.html#axiomatic-systems-statements-can-be-true-and-false",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatic Systems: Statements Can Be True And False",
    "text": "Axiomatic Systems: Statements Can Be True And False\n\nLet \\(T\\) be the sum of the interior angles of a triangle. We’re taught \\(T = 180^\\circ\\) is a “rule”\nEuclid’s Fifth Postulate \\(P_5\\): Given a line and a point not on it, exactly one line parallel to the given line can be drawn through the point.\n\n\n\n\n\n\n\n\n\n\\(P_5 \\implies T = 180^\\circ\\)\n\n\n(Euclidean Geometry)\n\n\n\n\n\\(\\neg P_5 \\implies T \\neq 180^\\circ\\)\n\n\n(Non-Euclidean Geometry)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#ethical-systems-promise-keeping",
    "href": "w01/index.html#ethical-systems-promise-keeping",
    "title": "Week 1: Introduction to the Course",
    "section": "Ethical Systems: Promise-Keeping",
    "text": "Ethical Systems: Promise-Keeping\n\nScenario: You just baked a pie, and you promised your friend you’d give them the pie. You’re walking over to the friend’s house to give them the pie.\nSuddenly, you turn the corner to encounter a hostage situation: the hostage-taker is going to kill their hostage unless someone gives them a pie in the next 30 seconds\nDo you give the hostage-taker the pie?\n\n\n\n\n\n\n\n\nConsequentialist Ethics \\(\\implies\\) Yes\n\n\nTo be ethical is to weigh consequences of your actions\nThe positive consequences of giving the pie to the hostage-taker (saving a life) outweigh the negative consequences (breaking your promise to your friend)\n(Ex: Utilitarianism, associated with British philosopher Jeremy Bentham)\n\n\n\n\nDeontological Ethics \\(\\implies\\) No\n\n\nTo be ethical is to live by rules which you would want everyone to follow.\nAs a rule (a “categorical imperative”), you must not break promises. (Breaking this rule \\(\\implies\\) others can also “pick and choose” when to honor promises to you)\n(Ex: Kantian Ethics, associated with German philosopher Immanuel Kant)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#descriptive-vs.-normative",
    "href": "w01/index.html#descriptive-vs.-normative",
    "title": "Week 1: Introduction to the Course",
    "section": "Descriptive vs. Normative",
    "text": "Descriptive vs. Normative\n\n\n\n\n\n\n\n \n  \n \n\n\n\n\n\n\n(binladen_messages_2005?)\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptive Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years”\nNormative Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years, and that is a good justification”\n\n\nDescriptively True (empirically verifiable)\nNormatively True (entailed by axioms + descriptive facts) in some ethical systems, Normatively False (not entailed by axioms + descriptive facts) in others",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#the-is-ought-distinction",
    "href": "w01/index.html#the-is-ought-distinction",
    "title": "Week 1: Introduction to the Course",
    "section": "The Is-Ought Distinction",
    "text": "The Is-Ought Distinction\n\n\n\n\n\n\nHume on Is vs. Ought (hume_treatise_1739?)\n\n\n\n\nthe author proceeds for some time in the ordinary way of reasoning\nsuddenly, instead of the usual copulations of propositions is and is not,\nI meet with no proposition that is not connected with an ought, or an ought not.\nThis change is imperceptible; but is, however, of the last consequence.\n\n\n\n\n\n\nDescriptive (Is)\nNormative (Ought)\n\n\n\n\nGrass is green (true)\nGrass ought to be green (?)\n\n\nGrass is blue (false)\nGrass ought to be blue (?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#what-happens-when-we-confuse-the-two",
    "href": "w01/index.html#what-happens-when-we-confuse-the-two",
    "title": "Week 1: Introduction to the Course",
    "section": "What Happens When We Confuse The Two?",
    "text": "What Happens When We Confuse The Two?\n\n\n\n\n\n\n\nMakes it impossible to “cross the boundary” between your own and others’ beliefs\nCollective welfare: Bad on its own terms (see: wars, racism, etc.)\nSelf-interest: Prevents us from convincing other people of our arguments\n\n\n\n\n\n\n(geertz_interpretation_1973?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#collective-vs.-self-interest",
    "href": "w01/index.html#collective-vs.-self-interest",
    "title": "Week 1: Introduction to the Course",
    "section": "Collective vs. Self-Interest",
    "text": "Collective vs. Self-Interest\n\n\n\n\n\n\n\nGood for collection of people \\(\\; \\nimplies\\) good for each individual person! (😰)\n\\(p\\) = Unions improve everyone’s workplace conditions, whether or not they pay dues\n\\(q\\) = Union dues are voluntary\n\\(p \\wedge q \\implies\\) I can obtain benefits of unions without paying\n\\(\\implies\\) Individually rational to not pay dues\n(Think also about how this applies to climate change policy) 🤔\n\n\n\n\n\n\n(olson_logic_1965?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#modeling-individual-vs.-societal-outcomes",
    "href": "w01/index.html#modeling-individual-vs.-societal-outcomes",
    "title": "Week 1: Introduction to the Course",
    "section": "Modeling Individual vs. Societal Outcomes",
    "text": "Modeling Individual vs. Societal Outcomes\n\nIndividual Perspective: Individual \\(i\\) chooses whether or not to pay union dues\n\n\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: No Union\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: Union Possible\n\n\nKey reading: (schelling_micromotives_1978?), Micromotives and Macrobehavior",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#takeaway-for-policy-whitepapers",
    "href": "w01/index.html#takeaway-for-policy-whitepapers",
    "title": "Week 1: Introduction to the Course",
    "section": "Takeaway for Policy Whitepapers",
    "text": "Takeaway for Policy Whitepapers\n\n\n\n\n\n\n\nYou cannot (just) say, “doing \\(x\\) will be better for society”\nYou must also justify benefits to individuals, or at minimum, the individual organization and its stakeholders!\n(Is this a normative or descriptive claim?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#data-science-for-who",
    "href": "w01/index.html#data-science-for-who",
    "title": "Week 1: Introduction to the Course",
    "section": "Data Science for Who?",
    "text": "Data Science for Who?\n\nWhat are the processes by which data is (or is not) measured, recorded, and distributed?\nWho are the agents doing or not-doing these things?\n\n\n\n\nThe Library of Missing Datasets. From (dignazio_data_2020?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#example-measuring-freedom-and-human-rights",
    "href": "w01/index.html#example-measuring-freedom-and-human-rights",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#methodological-individualism",
    "href": "w01/index.html#methodological-individualism",
    "title": "Week 1: Introduction to the Course",
    "section": "Methodological Individualism",
    "text": "Methodological Individualism\n\nAtoms exhibit properties which are fruitful for understanding the physical world: we can study these properties as “building blocks” \\(\\leadsto\\) interactions among atoms with various properties give rise to higher-level physical “things” (molecules, chemicals, cells, organisms)\nIndividuals exhibit properties which are fruitful for understanding the social world: we can study these properties as “building blocks” \\(\\leadsto\\) interactions among individuals with various properties give rise to higher-level social processes (dyads, groups, institutions)\n\n\n\nFor overthinkers: quarks \\(\\leadsto\\) atoms as mental modules \\(\\leadsto\\) individuals 😉 (fodor_modularity_1983?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#structural-domination-the-grapes-of-wrath",
    "href": "w01/index.html#structural-domination-the-grapes-of-wrath",
    "title": "Week 1: Introduction to the Course",
    "section": "Structural Domination: The Grapes of Wrath",
    "text": "Structural Domination: The Grapes of Wrath\n\nBut… I built it with my hands! Straightened old nails to put the sheathing on!\nIt’s not me. There’s nothing I can do. I’ll lose my job if I don’t do it. And look—suppose you kill me? They’ll hang you, and long before you’re hung there’ll be another guy here, he’ll bump the house down. You’re not killing the right guy.\nThat’s so… Who gave you orders? I’ll go after him. He’s the one to kill.\nYou’re wrong. He got his orders from the bank. ‘Clear those people out or it’s your job.’\nWell, there’s a president of the bank. A board of directors. I’ll fill up my rifle, head to the bank.\nThe bank gets orders from the East. ‘Make the land show profit or we’ll close you up.’ We’re sorry. It’s not us. It’s the monster. The bank isn’t like a man.\nYes, but the bank is only made of men!\nNo, you’re wrong there—quite wrong. The bank is something else than men. It happens nowadays that every man in a bank hates what the bank does, and yet the bank does it. The bank is something more than men, I tell you.\nI got to figure… We all got to figure. There’s some way to stop this. There’s got to be some way to stop this. It’s not like lightning or earthquakes. We’ve got a bad thing made by men, and by God, isn’t that something we should be able to change? (steinbeck_grapes_1939?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#ontology-individuals-and-structures",
    "href": "w01/index.html#ontology-individuals-and-structures",
    "title": "Week 1: Introduction to the Course",
    "section": "Ontology: Individuals and Structures",
    "text": "Ontology: Individuals and Structures\nMethodological Individualism and Structural Domination!\n\n\n\nNo longer much preoccupied with such crudities as ‘conspiracy theory’, [progressives] have become quite monolithic in attributing all things negative to handy abstractions like ‘capitalism’, ‘the state’, ‘structural oppression’, and ‘hierarchy’. Hence they have been able to conjure what might be termed the ‘miracle of immaculate genocide’, a form of genocide, that is, in which there are no actual perpetrators and no one who might ‘really’ be deemed culpable […] The parallels between this ‘cutting edge’ conception and the defense mounted by postwar Germans are as eerie as they are obvious. (churchill_justice_2003?)\n\n\n\n\n\n(giddens_central_1979?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#operationalization",
    "href": "w01/index.html#operationalization",
    "title": "Week 1: Introduction to the Course",
    "section": "Operationalization",
    "text": "Operationalization\n\n\n\nThink of claims commonly made based on “data”:\n\nMarkets create economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured? Who is measuring? Mechanisms for feedback \\(\\leadsto\\) updates?\n\n\n\n\n\n\n\n\n(stiglitz_mismeasuring_2010?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#what-is-being-compared",
    "href": "w01/index.html#what-is-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "What Is Being Compared?",
    "text": "What Is Being Compared?\n\n\n\n\n\n\n\n\nApples\nOranges\nPears\n\n\n\n\nPolities w/250-500M people (US ~335M, UP ~250M, EU ~450M)\nPolities w/11M people in the Caribbean (Cuba, Haiti, Dominican Republic)\nPolities w/over 1 billion people (China ~1.4B, India ~1.4B, Africa ~1.4B, ⬆️+⬇️ America ~1B)\n\n\nDemocracies (US)\nDemocracies til they democratically elected someone US didn’t like (Iran, Guatemala, Chile)\nNon-democracies which brutally repress democratic movements w/US arms (Saudi Arabia)\n\n\nColonizing polities (US)\nPolities colonized by them (Philippines)\nNon-colonized polities (Ethiopia, Thailand)\n\n\nPolities w/infrastructure built up over 250+ yrs via slave labor (US 🇺🇸)\nPolities populated by former slaves (Liberia 🇱🇷)\nPolities that paid reparations to descendants of [certain] enslaved groups (Germany)\n\n\nPolities independent since 1776 (US)\nPolities independent since 1990 (Namibia)\nNon-self-governing polities (Puerto Rico, Palestine, New Caledonia)\n\n\nPolities enforcing a 60 yr embargo on Cuba (US)\nPolities with a 60 yr embargo imposed on them by US (Cuba)\nPolities without a 60 yr embargo imposed on them by US (…)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#how-are-they-being-compared",
    "href": "w01/index.html#how-are-they-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "How Are They Being Compared?",
    "text": "How Are They Being Compared?\n\nWhat metric? Over what timespan?\nWhat unit of obs \\(\\leadsto\\) agg function \\(\\leadsto\\) level of aggregation?\n\n\n\n\n(dreze_china_1991?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#there-is-still-hope-i-promise",
    "href": "w01/index.html#there-is-still-hope-i-promise",
    "title": "Week 1: Introduction to the Course",
    "section": "…There is Still Hope! I Promise!",
    "text": "…There is Still Hope! I Promise!\n\nFair Comparison through Statistical Matching:\n(lyall_divided_2020?): “Treating certain ethnic groups as second-class citizens […] leads victimized soldiers to subvert military authorities once war begins. The higher an army’s inequality, the greater its rates of desertion, side-switching, and casualties”\n\n\nMatching constructs pairs of belligerents that are similar across a wide range of traits thought to dictate battlefield performance but that vary in levels of prewar inequality. The more similar the belligerents, the better our estimate of inequality’s effects, as all other traits are shared and thus cannot explain observed differences in performance, helping assess how battlefield performance would have improved (declined) if the belligerent had a lower (higher) level of prewar inequality.\nSince [non-matched] cases are dropped […] selected cases are more representative of average belligerents/wars than outliers with few or no matches, [providing] surer ground for testing generalizability of the book’s claims than focusing solely on canonical but unrepresentative usual suspects (Germany, the United States, Israel)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#does-inequality-cause-poor-military-performance",
    "href": "w01/index.html#does-inequality-cause-poor-military-performance",
    "title": "Week 1: Introduction to the Course",
    "section": "Does Inequality Cause Poor Military Performance?",
    "text": "Does Inequality Cause Poor Military Performance?\n\n\n\n\n\n\n\n\nCovariates\nSultanate of Morocco Spanish-Moroccan War, 1859-60\nKhanate of Kokand War with Russia, 1864-65\n\n\n\n\n\\(X\\): Military Inequality\nLow (0.01)\nExtreme (0.70)\n\n\n\\(\\mathbf{Z}\\): Matched Covariates:\n\n\n\n\nInitial relative power\n66%\n66%\n\n\nTotal fielded force\n55,000\n50,000\n\n\nRegime type\nAbsolutist Monarchy (−6)\nAbsolute Monarchy (−7)\n\n\nDistance from capital\n208km\n265km\n\n\nStanding army\nYes\nYes\n\n\nComposite military\nYes\nYes\n\n\nInitiator\nNo\nNo\n\n\nJoiner\nNo\nNo\n\n\nDemocratic opponent\nNo\nNo\n\n\nGreat Power\nNo\nNo\n\n\nCivil war\nNo\nNo\n\n\nCombined arms\nYes\nYes\n\n\nDoctrine\nOffensive\nOffensive\n\n\nSuperior weapons\nNo\nNo\n\n\nFortifications\nYes\nYes\n\n\nForeign advisors\nYes\nYes\n\n\nTerrain\nSemiarid coastal plain\nSemiarid grassland plain\n\n\nTopography\nRugged\nRugged\n\n\nWar duration\n126 days\n378 days\n\n\nRecent war history w/opp\nYes\nYes\n\n\nFacing colonizer\nYes\nYes\n\n\nIdentity dimension\nSunni Islam/Christian\nSunni Islam/Christian\n\n\nNew leader\nYes\nYes\n\n\nPopulation\n8–8.5 million\n5–6 million\n\n\nEthnoling fractionalization (ELF)\nHigh\nHigh\n\n\nCiv-mil relations\nRuler as commander\nRuler as commander\n\n\n\\(Y\\): Battlefield Performance:\n\n\n\n\nLoss-exchange ratio\n0.43\n0.02\n\n\nMass desertion\nNo\nYes\n\n\nMass defection\nNo\nNo\n\n\nFratricidal violence\nNo\nYes",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#bro-snapped",
    "href": "w01/index.html#bro-snapped",
    "title": "Week 1: Introduction to the Course",
    "section": "Bro Snapped",
    "text": "Bro Snapped\n(I have no dog in this fight, I’m not trying to improve military performance of an army, but got damn)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#implementation",
    "href": "w01/index.html#implementation",
    "title": "Week 1: Introduction to the Course",
    "section": "Implementation",
    "text": "Implementation\n\n\n\n\n\n\n\n\n\nFrom (dignazio_data_2020?), Ch. 6 (see also)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom (lerman_arresting_2014?) (see also)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#fairness",
    "href": "w01/index.html#fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "Fairness… 🧐",
    "text": "Fairness… 🧐\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Lily Hu, Direct Effects: How Should We Measure Racial Discrimination?, Phenomenal World, 25 September 2020\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: From (kasy_fairness_2021?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#and-inverse-fairness",
    "href": "w01/index.html#and-inverse-fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "…And INVERSE Fairness 🤯",
    "text": "…And INVERSE Fairness 🤯\n\n\n\nFrom Machine Learning What Policymakers Value (bjorkegren_machine_2022?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#facial-recognition-algorithms",
    "href": "w01/index.html#facial-recognition-algorithms",
    "title": "Week 1: Introduction to the Course",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n\n\n\n\n\n\n\n\n\n(facia.ai_facial_2023?)\n\n\n\n\n\n\n\n(wellcomecollection_composite_1890?)\n\n\n\n\n\n\n\n\n\n(ouz_google_2023?)\n\n\n\n\n\n\n\n(wang_deep_2018?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#large-language-models",
    "href": "w01/index.html#large-language-models",
    "title": "Week 1: Introduction to the Course",
    "section": "Large Language Models",
    "text": "Large Language Models\n\n\n\nWhen to retain biases…\n\n\n\n…and when to debias\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: From (schiebinger_machine_2020?)\n\n\n\n\n\n\n\n\n\n\nFigure 5: From DeepLearning.AI’s Deep Learning course",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#military-and-police-applications-of-ai",
    "href": "w01/index.html#military-and-police-applications-of-ai",
    "title": "Week 1: Introduction to the Course",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\n\n\n\n(ayyub_app_2019?)\n\n\n\n\n\n\n\n(mcneil_israel_2022?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#from-week-7-onwards-you-work-at-a-think-tank",
    "href": "w01/index.html#from-week-7-onwards-you-work-at-a-think-tank",
    "title": "Week 1: Introduction to the Course",
    "section": "From Week 7 Onwards, You Work At A Think Tank",
    "text": "From Week 7 Onwards, You Work At A Think Tank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(morozov_socialize_2015?)\n\n\n\n\n\n\n\nFrom (ames_techtopus_2014?)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#references",
    "href": "w01/index.html#references",
    "title": "Week 1: Introduction to the Course",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/slides.html#prof.-jeff-introduction",
    "href": "w01/slides.html#prof.-jeff-introduction",
    "title": "Week 1: Introduction to the Course",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)"
  },
  {
    "objectID": "w01/slides.html#grad-school",
    "href": "w01/slides.html#grad-school",
    "title": "Week 1: Introduction to the Course",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\nColumbia for PhD[+Postdoc] in Political Science (2015-2023)"
  },
  {
    "objectID": "w01/slides.html#dissertation-political-science-history",
    "href": "w01/slides.html#dissertation-political-science-history",
    "title": "Week 1: Introduction to the Course",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada"
  },
  {
    "objectID": "w01/slides.html#why-is-georgetown-having-me-teach-this",
    "href": "w01/slides.html#why-is-georgetown-having-me-teach-this",
    "title": "Week 1: Introduction to the Course",
    "section": "Why Is Georgetown Having Me Teach This?",
    "text": "Why Is Georgetown Having Me Teach This?\n\n\n\n\n\n\n\nQuanty things, but then PhD major was Political Philosophy (concentration in International Relations)\nWhat most interested me: unraveling history; Easy to get lost in “present-day” details of e.g. debiasing algorithms and fairness in AI, but these questions go back literally thousands of years!\nPol philosophers distinguish “ancients” and “moderns” based on a crucial shift in perspective: ancients sought perfection, while (rousseau_social_1762?) “took men [sic] as they are, and laws as they could be”.\n\n\n\n\n\n\n\n\n\n                                                \n\n\n\n\n\nFigure 1: Years spent questing in various dungeons of academia\n\n\n\n\n\n\n\nBut is separation of ethics from politics possible? (bowles_moral_2016?) Should we accept “human nature” as immutable/eternal? My answer: yes AND no simultaneously…"
  },
  {
    "objectID": "w01/slides.html#dialectics",
    "href": "w01/slides.html#dialectics",
    "title": "Week 1: Introduction to the Course",
    "section": "Dialectics",
    "text": "Dialectics"
  },
  {
    "objectID": "w01/slides.html#my-biases",
    "href": "w01/slides.html#my-biases",
    "title": "Week 1: Introduction to the Course",
    "section": "My Biases",
    "text": "My Biases\n\n\n\n\n\n\n\nUpbringing: religious Jewish, right-wing (Revisionist Zionist) Republican environment\n“Encouraged” to emigrate to Israel for IDF service, but after learning history I renounced citizenship etc., family no longer big fans of me (Traumatic and scary to talk about, tbh 🙈)\n2015-present: Teach CS + design thinking in refugee camps in West Bank and Gaza each summer (Code for Palestine)\nMetaethics: Learn about the world, challenge+update prior beliefs (Bayes’ rule!); I hope to challenge+update them throughout semester, with your help 🙂"
  },
  {
    "objectID": "w01/slides.html#on-the-one-hand",
    "href": "w01/slides.html#on-the-one-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the One Hand…",
    "text": "On the One Hand…"
  },
  {
    "objectID": "w01/slides.html#on-the-other-hand",
    "href": "w01/slides.html#on-the-other-hand",
    "title": "Week 1: Introduction to the Course",
    "section": "On the Other Hand…",
    "text": "On the Other Hand…"
  },
  {
    "objectID": "w01/slides.html#remembering-why-it-matters",
    "href": "w01/slides.html#remembering-why-it-matters",
    "title": "Week 1: Introduction to the Course",
    "section": "Remembering Why It Matters",
    "text": "Remembering Why It Matters"
  },
  {
    "objectID": "w01/slides.html#rules-of-thumb",
    "href": "w01/slides.html#rules-of-thumb",
    "title": "Week 1: Introduction to the Course",
    "section": "Rules of Thumb",
    "text": "Rules of Thumb\n\n\n\n\n\n\n\nAsk questions about power \\(\\leadsto\\) inequities, but especially about structures/processes that give rise to them!\n“Philosophers have hitherto only tried to understand the world; the point, however, is to change it.” (marx_thesen_1845?)\nDialectical implication: the more we understand it the better we’ll be at changing it\n\n\n\n\n\n\nRicardo Morales Art Studio / My office"
  },
  {
    "objectID": "w01/slides.html#axiomatics",
    "href": "w01/slides.html#axiomatics",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatics",
    "text": "Axiomatics\n\n\n\n\n\n\n\n\nPopular understanding of math: Deals with Facts, statements are true or false\n\nEx: \\(1 + 1 = 2\\) is “true”\n\nReality: No statements in math are absolutely true! Only conditional statements are possible to prove!\nWe cannot prove atomic statements \\(q\\), only implicational statements: \\(p \\implies q\\) for some axiom(s) \\(p\\).\n\n\\(1 + 1 = 2\\) is indeterminate without definitions of \\(1\\), \\(+\\), \\(=\\), and \\(2\\)!\n(Easy counterexample for math/CS majors: \\(1 + 1 = 0\\) in \\(\\mathbb{Z}_2\\))\n\n\n\n\n\n\n\n\n(steingart_axiomatics_2023?)"
  },
  {
    "objectID": "w01/slides.html#example-1-1-2",
    "href": "w01/slides.html#example-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: \\(1 + 1 = 2\\)",
    "text": "Example: \\(1 + 1 = 2\\)\n\n\n\n\n\n\n\nHow it’s taught: this is a rule, and if you don’t follow it you will be banished to eternal hellfire\nHow it’s proved: \\(ZFC \\implies [1 + 1 = 2]\\), where \\(ZFC\\) stands for the Zermelo-Fraenkel Axioms with the Axiom of Choice!\n\n\n\n\n\n\n(whitehead_principia_1910?), p. 83. See here for page in context"
  },
  {
    "objectID": "w01/slides.html#proving-1-1-2",
    "href": "w01/slides.html#proving-1-1-2",
    "title": "Week 1: Introduction to the Course",
    "section": "Proving \\(1 + 1 = 2\\)",
    "text": "Proving \\(1 + 1 = 2\\)\n(A non-formal proof that still captures the gist:)\n\nAxiom 1: There is a type of thing that can hold other things, which we’ll call a set. We’ll represent it like: \\(\\{ \\langle \\text{\\textit{stuff in the set}} \\rangle \\}\\).\nAxiom 2: Start with the set with nothing in it, \\(\\{\\}\\), and call it “\\(0\\)”.\nAxiom 3: If we put this set \\(0\\) inside of an empty set, we get a new set \\(\\{0\\} = \\{\\{\\}\\}\\), which we’ll call “\\(1\\)”.\nAxiom 4: If we put this set \\(1\\) inside of another set, we get another new set \\(\\{1\\} = \\{\\{\\{\\}\\}\\}\\), which we’ll call “\\(2\\)”.\nAxiom 5: This operation (creating a “next number” by placing a given number inside an empty set) we’ll call succession: \\(S(x) = \\{x\\}\\)\nAxiom 6: We’ll define addition, \\(a + b\\), as applying this succession operation \\(S\\) to \\(a\\), \\(b\\) times. Thus \\(a + b = \\underbrace{S(S(\\cdots (S(}_{b\\text{ times}}a))\\cdots ))\\)\nResult: (Axioms 1-6) \\(\\implies 1 + 1 = S(1) = S(\\{\\{\\}\\}) = \\{\\{\\{\\}\\}\\} = 2. \\; \\blacksquare\\)"
  },
  {
    "objectID": "w01/slides.html#how-is-this-relevant-to-ethics",
    "href": "w01/slides.html#how-is-this-relevant-to-ethics",
    "title": "Week 1: Introduction to the Course",
    "section": "How Is This Relevant to Ethics?",
    "text": "How Is This Relevant to Ethics?\n(Thank you for bearing with me on that 😅)\n\nJust as mathematicians slowly came to the realization that\n\n\\[\n\\textbf{mathematical results} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nI hope to help you see how\n\n\\[\n\\textbf{ethical conclusions} \\neq \\textbf{(non-implicational) truths}\n\\]\n\nWhen someone says \\(1 + 1 = 2\\), you are allowed to question them, and ask, “On what basis? Please explain…”.\n\nHere the only valid answer is a collection of axioms which entail \\(1 + 1 = 2\\)\n\nWhen someone says Israel has the right to defend itself, you are allowed to question them, and ask, “On what basis? Please explain…”\n\nHere the only valid answer is an ethical framework which entails that Israel has the right to defend itself."
  },
  {
    "objectID": "w01/slides.html#axiomatic-systems-statements-can-be-true-and-false",
    "href": "w01/slides.html#axiomatic-systems-statements-can-be-true-and-false",
    "title": "Week 1: Introduction to the Course",
    "section": "Axiomatic Systems: Statements Can Be True And False",
    "text": "Axiomatic Systems: Statements Can Be True And False\n\nLet \\(T\\) be the sum of the interior angles of a triangle. We’re taught \\(T = 180^\\circ\\) is a “rule”\nEuclid’s Fifth Postulate \\(P_5\\): Given a line and a point not on it, exactly one line parallel to the given line can be drawn through the point.\n\n\n\n\n\n\n\n\n\n\\(P_5 \\implies T = 180^\\circ\\)\n\n\n(Euclidean Geometry)\n\n\n\n\n\\(\\neg P_5 \\implies T \\neq 180^\\circ\\)\n\n\n(Non-Euclidean Geometry)"
  },
  {
    "objectID": "w01/slides.html#ethical-systems-promise-keeping",
    "href": "w01/slides.html#ethical-systems-promise-keeping",
    "title": "Week 1: Introduction to the Course",
    "section": "Ethical Systems: Promise-Keeping",
    "text": "Ethical Systems: Promise-Keeping\n\nScenario: You just baked a pie, and you promised your friend you’d give them the pie. You’re walking over to the friend’s house to give them the pie.\nSuddenly, you turn the corner to encounter a hostage situation: the hostage-taker is going to kill their hostage unless someone gives them a pie in the next 30 seconds\nDo you give the hostage-taker the pie?\n\n\n\n\n\n\n\n\nConsequentialist Ethics \\(\\implies\\) Yes\n\n\nTo be ethical is to weigh consequences of your actions\nThe positive consequences of giving the pie to the hostage-taker (saving a life) outweigh the negative consequences (breaking your promise to your friend)\n(Ex: Utilitarianism, associated with British philosopher Jeremy Bentham)\n\n\n\n\nDeontological Ethics \\(\\implies\\) No\n\n\nTo be ethical is to live by rules which you would want everyone to follow.\nAs a rule (a “categorical imperative”), you must not break promises. (Breaking this rule \\(\\implies\\) others can also “pick and choose” when to honor promises to you)\n(Ex: Kantian Ethics, associated with German philosopher Immanuel Kant)"
  },
  {
    "objectID": "w01/slides.html#descriptive-vs.-normative",
    "href": "w01/slides.html#descriptive-vs.-normative",
    "title": "Week 1: Introduction to the Course",
    "section": "Descriptive vs. Normative",
    "text": "Descriptive vs. Normative\n\n\n\n\n\n\n\n \n  \n \n\n\n\n\n\n\n(binladen_messages_2005?)\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptive Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years”\nNormative Statement: “Bin Laden attacked us because we had been bombing Iraq for 10 years, and that is a good justification”\n\n\nDescriptively True (empirically verifiable)\nNormatively True (entailed by axioms + descriptive facts) in some ethical systems, Normatively False (not entailed by axioms + descriptive facts) in others"
  },
  {
    "objectID": "w01/slides.html#the-is-ought-distinction",
    "href": "w01/slides.html#the-is-ought-distinction",
    "title": "Week 1: Introduction to the Course",
    "section": "The Is-Ought Distinction",
    "text": "The Is-Ought Distinction\n\n\n\n\nHume on Is vs. Ought (hume_treatise_1739?)\n\n\n\nthe author proceeds for some time in the ordinary way of reasoning\nsuddenly, instead of the usual copulations of propositions is and is not,\nI meet with no proposition that is not connected with an ought, or an ought not.\nThis change is imperceptible; but is, however, of the last consequence.\n\n\n\n\n\n\n\n\nDescriptive (Is)\nNormative (Ought)\n\n\n\n\nGrass is green (true)\nGrass ought to be green (?)\n\n\nGrass is blue (false)\nGrass ought to be blue (?)"
  },
  {
    "objectID": "w01/slides.html#what-happens-when-we-confuse-the-two",
    "href": "w01/slides.html#what-happens-when-we-confuse-the-two",
    "title": "Week 1: Introduction to the Course",
    "section": "What Happens When We Confuse The Two?",
    "text": "What Happens When We Confuse The Two?\n\n\n\n\n\n\n\nMakes it impossible to “cross the boundary” between your own and others’ beliefs\nCollective welfare: Bad on its own terms (see: wars, racism, etc.)\nSelf-interest: Prevents us from convincing other people of our arguments\n\n\n\n\n\n\n(geertz_interpretation_1973?)"
  },
  {
    "objectID": "w01/slides.html#collective-vs.-self-interest",
    "href": "w01/slides.html#collective-vs.-self-interest",
    "title": "Week 1: Introduction to the Course",
    "section": "Collective vs. Self-Interest",
    "text": "Collective vs. Self-Interest\n\n\n\n\n\n\n\nGood for collection of people \\(\\; \\nimplies\\) good for each individual person! (😰)\n\\(p\\) = Unions improve everyone’s workplace conditions, whether or not they pay dues\n\\(q\\) = Union dues are voluntary\n\\(p \\wedge q \\implies\\) I can obtain benefits of unions without paying\n\\(\\implies\\) Individually rational to not pay dues\n(Think also about how this applies to climate change policy) 🤔\n\n\n\n\n\n\n(olson_logic_1965?)"
  },
  {
    "objectID": "w01/slides.html#modeling-individual-vs.-societal-outcomes",
    "href": "w01/slides.html#modeling-individual-vs.-societal-outcomes",
    "title": "Week 1: Introduction to the Course",
    "section": "Modeling Individual vs. Societal Outcomes",
    "text": "Modeling Individual vs. Societal Outcomes\n\nIndividual Perspective: Individual \\(i\\) chooses whether or not to pay union dues\n\n\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: No Union\n\n\n\n\n\n\n\\(\\implies\\) Social Outcome: Union Possible\n\nKey reading: (schelling_micromotives_1978?), Micromotives and Macrobehavior"
  },
  {
    "objectID": "w01/slides.html#takeaway-for-policy-whitepapers",
    "href": "w01/slides.html#takeaway-for-policy-whitepapers",
    "title": "Week 1: Introduction to the Course",
    "section": "Takeaway for Policy Whitepapers",
    "text": "Takeaway for Policy Whitepapers\n\n\n\n\n\n\n\nYou cannot (just) say, “doing \\(x\\) will be better for society”\nYou must also justify benefits to individuals, or at minimum, the individual organization and its stakeholders!\n(Is this a normative or descriptive claim?)"
  },
  {
    "objectID": "w01/slides.html#data-science-for-who",
    "href": "w01/slides.html#data-science-for-who",
    "title": "Week 1: Introduction to the Course",
    "section": "Data Science for Who?",
    "text": "Data Science for Who?\n\nWhat are the processes by which data is (or is not) measured, recorded, and distributed?\nWho are the agents doing or not-doing these things?\n\n\nThe Library of Missing Datasets. From (dignazio_data_2020?)"
  },
  {
    "objectID": "w01/slides.html#example-measuring-freedom-and-human-rights",
    "href": "w01/slides.html#example-measuring-freedom-and-human-rights",
    "title": "Week 1: Introduction to the Course",
    "section": "Example: Measuring “Freedom” and “Human Rights”",
    "text": "Example: Measuring “Freedom” and “Human Rights”"
  },
  {
    "objectID": "w01/slides.html#methodological-individualism",
    "href": "w01/slides.html#methodological-individualism",
    "title": "Week 1: Introduction to the Course",
    "section": "Methodological Individualism",
    "text": "Methodological Individualism\n\nAtoms exhibit properties which are fruitful for understanding the physical world: we can study these properties as “building blocks” \\(\\leadsto\\) interactions among atoms with various properties give rise to higher-level physical “things” (molecules, chemicals, cells, organisms)\nIndividuals exhibit properties which are fruitful for understanding the social world: we can study these properties as “building blocks” \\(\\leadsto\\) interactions among individuals with various properties give rise to higher-level social processes (dyads, groups, institutions)\n\n\n\nFor overthinkers: quarks \\(\\leadsto\\) atoms as mental modules \\(\\leadsto\\) individuals 😉 (fodor_modularity_1983?)"
  },
  {
    "objectID": "w01/slides.html#structural-domination-the-grapes-of-wrath",
    "href": "w01/slides.html#structural-domination-the-grapes-of-wrath",
    "title": "Week 1: Introduction to the Course",
    "section": "Structural Domination: The Grapes of Wrath",
    "text": "Structural Domination: The Grapes of Wrath\n\nBut… I built it with my hands! Straightened old nails to put the sheathing on!\nIt’s not me. There’s nothing I can do. I’ll lose my job if I don’t do it. And look—suppose you kill me? They’ll hang you, and long before you’re hung there’ll be another guy here, he’ll bump the house down. You’re not killing the right guy.\nThat’s so… Who gave you orders? I’ll go after him. He’s the one to kill.\nYou’re wrong. He got his orders from the bank. ‘Clear those people out or it’s your job.’\nWell, there’s a president of the bank. A board of directors. I’ll fill up my rifle, head to the bank.\nThe bank gets orders from the East. ‘Make the land show profit or we’ll close you up.’ We’re sorry. It’s not us. It’s the monster. The bank isn’t like a man.\nYes, but the bank is only made of men!\nNo, you’re wrong there—quite wrong. The bank is something else than men. It happens nowadays that every man in a bank hates what the bank does, and yet the bank does it. The bank is something more than men, I tell you.\nI got to figure… We all got to figure. There’s some way to stop this. There’s got to be some way to stop this. It’s not like lightning or earthquakes. We’ve got a bad thing made by men, and by God, isn’t that something we should be able to change? (steinbeck_grapes_1939?)"
  },
  {
    "objectID": "w01/slides.html#ontology-individuals-and-structures",
    "href": "w01/slides.html#ontology-individuals-and-structures",
    "title": "Week 1: Introduction to the Course",
    "section": "Ontology: Individuals and Structures",
    "text": "Ontology: Individuals and Structures\nMethodological Individualism and Structural Domination!\n\n\n\nNo longer much preoccupied with such crudities as ‘conspiracy theory’, [progressives] have become quite monolithic in attributing all things negative to handy abstractions like ‘capitalism’, ‘the state’, ‘structural oppression’, and ‘hierarchy’. Hence they have been able to conjure what might be termed the ‘miracle of immaculate genocide’, a form of genocide, that is, in which there are no actual perpetrators and no one who might ‘really’ be deemed culpable […] The parallels between this ‘cutting edge’ conception and the defense mounted by postwar Germans are as eerie as they are obvious. (churchill_justice_2003?)\n\n\n\n\n\n(giddens_central_1979?)"
  },
  {
    "objectID": "w01/slides.html#operationalization",
    "href": "w01/slides.html#operationalization",
    "title": "Week 1: Introduction to the Course",
    "section": "Operationalization",
    "text": "Operationalization\n\n\n\nThink of claims commonly made based on “data”:\n\nMarkets create economic prosperity\nA glass of wine in the evening prevents cancer\nPolicing makes communities safer\n\nHow exactly are “prosperity”, “preventing cancer”, “policing”, “community safety” being measured? Who is measuring? Mechanisms for feedback \\(\\leadsto\\) updates?\n\n\n\n\n\n\n\n\n(stiglitz_mismeasuring_2010?)"
  },
  {
    "objectID": "w01/slides.html#what-is-being-compared",
    "href": "w01/slides.html#what-is-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "What Is Being Compared?",
    "text": "What Is Being Compared?\n\n\n\n\n\n\n\n\nApples\nOranges\nPears\n\n\n\n\nPolities w/250-500M people (US ~335M, UP ~250M, EU ~450M)\nPolities w/11M people in the Caribbean (Cuba, Haiti, Dominican Republic)\nPolities w/over 1 billion people (China ~1.4B, India ~1.4B, Africa ~1.4B, ⬆️+⬇️ America ~1B)\n\n\nDemocracies (US)\nDemocracies til they democratically elected someone US didn’t like (Iran, Guatemala, Chile)\nNon-democracies which brutally repress democratic movements w/US arms (Saudi Arabia)\n\n\nColonizing polities (US)\nPolities colonized by them (Philippines)\nNon-colonized polities (Ethiopia, Thailand)\n\n\nPolities w/infrastructure built up over 250+ yrs via slave labor (US 🇺🇸)\nPolities populated by former slaves (Liberia 🇱🇷)\nPolities that paid reparations to descendants of [certain] enslaved groups (Germany)\n\n\nPolities independent since 1776 (US)\nPolities independent since 1990 (Namibia)\nNon-self-governing polities (Puerto Rico, Palestine, New Caledonia)\n\n\nPolities enforcing a 60 yr embargo on Cuba (US)\nPolities with a 60 yr embargo imposed on them by US (Cuba)\nPolities without a 60 yr embargo imposed on them by US (…)"
  },
  {
    "objectID": "w01/slides.html#how-are-they-being-compared",
    "href": "w01/slides.html#how-are-they-being-compared",
    "title": "Week 1: Introduction to the Course",
    "section": "How Are They Being Compared?",
    "text": "How Are They Being Compared?\n\nWhat metric? Over what timespan?\nWhat unit of obs \\(\\leadsto\\) agg function \\(\\leadsto\\) level of aggregation?\n\n\n(dreze_china_1991?)"
  },
  {
    "objectID": "w01/slides.html#there-is-still-hope-i-promise",
    "href": "w01/slides.html#there-is-still-hope-i-promise",
    "title": "Week 1: Introduction to the Course",
    "section": "…There is Still Hope! I Promise!",
    "text": "…There is Still Hope! I Promise!\n\nFair Comparison through Statistical Matching:\n(lyall_divided_2020?): “Treating certain ethnic groups as second-class citizens […] leads victimized soldiers to subvert military authorities once war begins. The higher an army’s inequality, the greater its rates of desertion, side-switching, and casualties”\n\n\nMatching constructs pairs of belligerents that are similar across a wide range of traits thought to dictate battlefield performance but that vary in levels of prewar inequality. The more similar the belligerents, the better our estimate of inequality’s effects, as all other traits are shared and thus cannot explain observed differences in performance, helping assess how battlefield performance would have improved (declined) if the belligerent had a lower (higher) level of prewar inequality.\nSince [non-matched] cases are dropped […] selected cases are more representative of average belligerents/wars than outliers with few or no matches, [providing] surer ground for testing generalizability of the book’s claims than focusing solely on canonical but unrepresentative usual suspects (Germany, the United States, Israel)"
  },
  {
    "objectID": "w01/slides.html#does-inequality-cause-poor-military-performance",
    "href": "w01/slides.html#does-inequality-cause-poor-military-performance",
    "title": "Week 1: Introduction to the Course",
    "section": "Does Inequality Cause Poor Military Performance?",
    "text": "Does Inequality Cause Poor Military Performance?\n\n\n\n\n\n\n\n\nCovariates\nSultanate of Morocco Spanish-Moroccan War, 1859-60\nKhanate of Kokand War with Russia, 1864-65\n\n\n\n\n\\(X\\): Military Inequality\nLow (0.01)\nExtreme (0.70)\n\n\n\\(\\mathbf{Z}\\): Matched Covariates:\n\n\n\n\nInitial relative power\n66%\n66%\n\n\nTotal fielded force\n55,000\n50,000\n\n\nRegime type\nAbsolutist Monarchy (−6)\nAbsolute Monarchy (−7)\n\n\nDistance from capital\n208km\n265km\n\n\nStanding army\nYes\nYes\n\n\nComposite military\nYes\nYes\n\n\nInitiator\nNo\nNo\n\n\nJoiner\nNo\nNo\n\n\nDemocratic opponent\nNo\nNo\n\n\nGreat Power\nNo\nNo\n\n\nCivil war\nNo\nNo\n\n\nCombined arms\nYes\nYes\n\n\nDoctrine\nOffensive\nOffensive\n\n\nSuperior weapons\nNo\nNo\n\n\nFortifications\nYes\nYes\n\n\nForeign advisors\nYes\nYes\n\n\nTerrain\nSemiarid coastal plain\nSemiarid grassland plain\n\n\nTopography\nRugged\nRugged\n\n\nWar duration\n126 days\n378 days\n\n\nRecent war history w/opp\nYes\nYes\n\n\nFacing colonizer\nYes\nYes\n\n\nIdentity dimension\nSunni Islam/Christian\nSunni Islam/Christian\n\n\nNew leader\nYes\nYes\n\n\nPopulation\n8–8.5 million\n5–6 million\n\n\nEthnoling fractionalization (ELF)\nHigh\nHigh\n\n\nCiv-mil relations\nRuler as commander\nRuler as commander\n\n\n\\(Y\\): Battlefield Performance:\n\n\n\n\nLoss-exchange ratio\n0.43\n0.02\n\n\nMass desertion\nNo\nYes\n\n\nMass defection\nNo\nNo\n\n\nFratricidal violence\nNo\nYes"
  },
  {
    "objectID": "w01/slides.html#bro-snapped",
    "href": "w01/slides.html#bro-snapped",
    "title": "Week 1: Introduction to the Course",
    "section": "Bro Snapped",
    "text": "Bro Snapped\n(I have no dog in this fight, I’m not trying to improve military performance of an army, but got damn)"
  },
  {
    "objectID": "w01/slides.html#implementation",
    "href": "w01/slides.html#implementation",
    "title": "Week 1: Introduction to the Course",
    "section": "Implementation",
    "text": "Implementation\n\n\n\n\n\n\n\n\n\nFrom (dignazio_data_2020?), Ch. 6 (see also)\n\n\n\n\n\n\n\n\n\n\n\n\nFrom (lerman_arresting_2014?) (see also)"
  },
  {
    "objectID": "w01/slides.html#fairness",
    "href": "w01/slides.html#fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "Fairness… 🧐",
    "text": "Fairness… 🧐\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: From Lily Hu, Direct Effects: How Should We Measure Racial Discrimination?, Phenomenal World, 25 September 2020\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: From (kasy_fairness_2021?)"
  },
  {
    "objectID": "w01/slides.html#and-inverse-fairness",
    "href": "w01/slides.html#and-inverse-fairness",
    "title": "Week 1: Introduction to the Course",
    "section": "…And INVERSE Fairness 🤯",
    "text": "…And INVERSE Fairness 🤯\n\nFrom Machine Learning What Policymakers Value (bjorkegren_machine_2022?)"
  },
  {
    "objectID": "w01/slides.html#facial-recognition-algorithms",
    "href": "w01/slides.html#facial-recognition-algorithms",
    "title": "Week 1: Introduction to the Course",
    "section": "Facial Recognition Algorithms",
    "text": "Facial Recognition Algorithms\n\n\n\n\n\n\n\n\n\n(facia.ai_facial_2023?)\n\n\n\n\n\n\n\n(wellcomecollection_composite_1890?)\n\n\n\n\n\n\n\n\n\n(ouz_google_2023?)\n\n\n\n\n\n\n\n(wang_deep_2018?)"
  },
  {
    "objectID": "w01/slides.html#large-language-models",
    "href": "w01/slides.html#large-language-models",
    "title": "Week 1: Introduction to the Course",
    "section": "Large Language Models",
    "text": "Large Language Models\n\n\n\nWhen to retain biases…\n\n\n\n…and when to debias\n\n\n\n\n\n\n\n\n\n\nFigure 4: From (schiebinger_machine_2020?)\n\n\n\n\n\n\n\n\n\n\nFigure 5: From DeepLearning.AI’s Deep Learning course"
  },
  {
    "objectID": "w01/slides.html#military-and-police-applications-of-ai",
    "href": "w01/slides.html#military-and-police-applications-of-ai",
    "title": "Week 1: Introduction to the Course",
    "section": "Military and Police Applications of AI",
    "text": "Military and Police Applications of AI\n\n\n\n\n\n\n\n\n\n(ayyub_app_2019?)\n\n\n\n\n\n\n\n(mcneil_israel_2022?)"
  },
  {
    "objectID": "w01/slides.html#from-week-7-onwards-you-work-at-a-think-tank",
    "href": "w01/slides.html#from-week-7-onwards-you-work-at-a-think-tank",
    "title": "Week 1: Introduction to the Course",
    "section": "From Week 7 Onwards, You Work At A Think Tank",
    "text": "From Week 7 Onwards, You Work At A Think Tank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(morozov_socialize_2015?)\n\n\n\n\n\n\n\nFrom (ames_techtopus_2014?)"
  },
  {
    "objectID": "w01/slides.html#references",
    "href": "w01/slides.html#references",
    "title": "Week 1: Introduction to the Course",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Welcome to DSAN 5650: Causal Inference for Computational Social Science at Georgetown University!\nThe course meets on Wednesdays from 6:30-9pm online via Zoom",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-staff",
    "href": "syllabus.html#course-staff",
    "title": "Syllabus",
    "section": "Course Staff",
    "text": "Course Staff\n\nProf. Jeff Jacobs, jj1088@georgetown.edu\n\nOffice hours (Click to schedule): Tuesdays, 3:30-6:30pm\n\nTAs: TBD",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis course provides students with the opportunity to take the analytical skills, machine learning algorithms, and statistical methods learned throughout their first year in the program and explore how they can be employed towards carrying out rigorous, original research in the behavioral and social sciences. With a particular emphasis on tackling the additional challenges which arise when moving from associational to causal inference, particularly when only observational (as opposed to experimental) data is available, students will become proficient in cutting-edge causal Machine Learning techniques such as propensity score matching, synthetic controls, causal program evaluation, inverse social welfare function estimation from panel data, and Double-Debiased Machine Learning.\nIn-class examples will cover continuous, discrete-choice, and textual data from a wide swath of social and behavioral sciences: economics, political science, sociology, anthropology, quantitative history, and digital humanities. After gaining experience through in-class labs and homework assignments focused on reproducing key findings from recent journal articles in each of these disciplines, students will spend the final weeks of the course on a final project demonstrating their ability to develop, evaluate, and test the robustness of a causal hypothesis.\nPrerequisites: DSAN 5000, DSAN 5100 (DSAN 5300 recommended but not required)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-overview",
    "href": "syllabus.html#course-overview",
    "title": "Syllabus",
    "section": "Course Overview",
    "text": "Course Overview\nThe course revolves around three “pillars”, which we’ll examine individually before bringing them together for your final projects at the end of the class: high-level ethical issues in data science, general ethical frameworks, and public policy applications.\n\nData Science\nA portion of the course will focus on introductions to cutting-edge technologies like self-driving cars, ChatGPT, facial detection algorithms, and various applications of AI to police and military technologies. For this portion, we’ll draw fairly often from the contents of the following books:\n\n(perez_invisible_2019?): Invisible Women: Data Bias in a World Designed for Men.\nCatherine D’Ignazio and Lauren F. Klein (2020). Data Feminism. Cambridge, MA: MIT Press. [Free, open-source!]\nCathy O’Neil (2016). Weapons of Math Destruction. New York, NY: Crown Books.\n\nSince there are plenty of in-depth resources available to you (e.g., other Georgetown courses!) for learning the technical details of these technologies, our goal in this course will be to learn just the particular aspects of each technology which are most relevant to the ethical and policy issues they present.\nFor example, we will look at Neural Netwok-based Machine Learning algorithms, but we will focus specifically on how the performance of these algorithms on a given task depends crucially on the existence of effective training data for that task. The breakthroughs in Artificial Intelligence which have had an immense impact on society over the past few decades, for example, have not come about because of new algorithms (neural networks, for example, have been around since the 1950s). Rather, they have come about because of the massive, exponential increase in the amount of data available to train these already-existing algorithms: for example, data scraped from across the entire web, or from millions of scanned books, or from Wikipedia’s massive collection of articles. This means, therefore, that these algorithms simply encode pre-existing human biases into algorithmically-derived “rules”, thus motivating the next pillar of the course: Ethics!\n\n\nEthics\nFor the ethics-focused portion of the course, we’ll be reading selections from the following textbook:\n\nLewis Vaughn and Louis P. Pojman (2021). The Moral Life: An Introductory Reader in Ethics and Literature. Oxford, UK: Oxford University Press. [PDF]\n\nFrom the vast array of readings contained in this collection, we’ll look at both “standard” ethical readings from e.g. Jeremy Bentham and Immanuel Kant plus readings from literary sources like Ursula Le Guin and Ambrose Bierce.\n\n\nPublic Policy\nFor the final piece of the course we will take the technological developments discussed the first portion, analyze them using the ethical frameworks discussed in the second portion, and come to conclusions as to what types of things lawmakers, governments, and civil society organizations (NGOs, for example, and Think Tanks) can do in practice to address the ethical issues raised by these technologies. This means that, specifically, the recommended final project for the course will be a Policy Whitepaper, where you will choose a particular institution and make a recommendation to them in terms of how they can use their power (for example, the power to pass laws) to most effectively address an ethical issue that you believe is important.\nFor this portion of the class we’ll have to draw on a wide range of different readings, depending on what particular subdomains of public policy are most interesting to you all, but as a general textbook on ethics in data science which does focus a good amount on policy specifically, we will look at:\n\nAnne L. Washington (2023). Ethical Data Science: Prediction in the Public Interest. New York, NY: Oxford University Press.\n\nNow that you have an overview of the trajectory of the course, the following section contains the particulars of what we’ll be reading and working on each week!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "Syllabus",
    "section": "Schedule",
    "text": "Schedule\nThe following is a rough map of what we will work through together throughout the semester; given that everyone learns at a different pace, my aim is to leave us with a good amount of flexibility in terms of how much time we spend on each topic: if I find that it takes me longer than a week to convey a certain topic in sufficient depth, for example, then I view it as a strength rather than a weakness of the course that we can then rearrange the calendar below by adding an extra week on that particular topic! Similarly, if it seems like I am spending too much time on a topic, to the point that students seem bored or impatient to move onto the next topic, we can move a topic intended for the next week to the current week!\n\n\n\nUnit\nWeek\nDate\nTopic\n\n\n\n\nUnit 1: Ethical Frameworks\n1\nJan 15\nIntroduction to the Course\n\n\n\n2\nJan 22\nMachine Learning, Training Data, and Bias\n\n\nUnit 2: Fairness in AI\n3\nJan 29\nEthical Frameworks: Rights, Discrimination, and Fairness\n\n\n\n\nJan 31 (Friday), 5:59pm EST\n[Deliverable] HW1: Nuts and Bolts for Fairness in AI\n\n\n\n4\nFeb 5\n(Descriptive) Fairness in AI\n\n\n\n5\nFeb 12\nContext-Sensitive Fairness\n\n\n\n6\nFeb 19\nCausality in Ethics and Policy\n\n\n\n\nFeb 21 (Friday), 5:59pm EST\n[Deliverable] HW2: Context-Sensitive Fairness\n\n\nMidterm\n7\nFeb 26\nIn-Class Midterm: Data Ethics, Fairness, Privacy, Causality\n\n\n\n\nMar 6\nNo Class (Spring Break)\n\n\nUnit 3: Policy Frameworks\n8\nMar 12\nPrivacy Policies, Incomplete Contracts, and Power\n\n\n\n9\nMar 19\nFrom Data Ethics to Data Policy\n\n\n\n10\nMar 26\nEconometric Policy Evaluation and Inverse Fairness\n\n\n\n11\nApr 2\nFairness vs. Social Welfare\n\n\nUnit 4: Applications\n12\nApr 9\nProject Talk, Causality and Identity Formation\n\n\n\n13\nApr 16\nApplications: Race, Class, Gender, Sexuality, and Disability (Data Feminism)\n\n\n\n14\nApr 23\nRepublican Liberty and the Kindly Slavemaster\n\n\n\n\nMay 10 (Friday)\n[Deliverable] Policy Whitepaper",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assignments-and-grading",
    "href": "syllabus.html#assignments-and-grading",
    "title": "Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThe main assignment in the course will be your policy whitepaper, submitted at the end of the semester. However, there will also be a midterm exam and a series of assignments which exist to let you explore each of the modules of the course, in turn.\n\n\n\n\n\n\n\n\nAssignment\nDue Date\n% of Grade\n\n\n\n\nHW1: Nuts and Bolts for Fairness in AI \nFriday, February 9\n10%\n\n\nHW2: Context-Sensitive Fairness \nFriday, February 21\n10%\n\n\nMidterm\nWednesday, February 28\n30%\n\n\nHW3: Privacy Policies as Incomplete Contracts \nFriday, April 12\n10%\n\n\nHW4: Policy Evaluation\nFriday, April 26\n10%\n\n\nPolicy Whitepaper\nFriday, May 10\n30%\n\n\n\n\nHomework Lateness Policy\nAfter the due date, for each homework assignment, you will have a grace period of 24 hours to submit the assignment without a lateness penalty. After this 24-hour grace period, late penalties will be applied based on the following scale (unless you obtain an excused lateness from one of the instructional staff!):\n\n0 to 24 hours late: no penalty\n24 to 30 hours late: 2.5% penalty\n30 to 42 hours late: 5% penalty\n42 to 54 hours late: 10% penalty\n54 to 66 hours late: 20% penalty\nMore than 66 hours late: Assignment submissions no longer accepted (without instructor approval)",
    "crumbs": [
      "Syllabus"
    ]
  }
]