[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "As mentioned on the syllabus, the field of causal inference in general (and causal inference for computational social science in particular) moves excitingly-fast, such that the material has yet to ‚Äúcongeal‚Äù into a single, all-encompassing textbook. Nonetheless, the following three books cover a substantial amount of ground (described in more detail below each citation), so that together they form a coherent ‚Äúthree-volume textbook‚Äù for this class! If you can only read three books this summer, read these :)\n\n\n\n\n\n\n Morgan and Winship (2015)\n\n\n\nMorgan and Winship, Counterfactuals and Causal Inference: Methods and Principles for Social Research [PDF]\n\n\n\nThis is the book which comes closest to being an all-encompassing, single textbook for the class! It brings together different ‚Äústrands‚Äù of causal modeling research (since each field‚Äîeconomics, bioinformatics, sociology, etc.‚Äîtends to use its own notation and vocabulary), unifying them into a single approach. The only reason we can‚Äôt use it as the main textbook is because it hasn‚Äôt been updated since 2015, and most of the assignments in this class use computational tools from 2018 onwards!\n\n\n\n\n\n\n\n\n Angrist and Pischke (2014)\n\n\n\nAngrist and Pischke, Mastering ‚ÄôMetrics: The Path from Cause to Effect (Angrist and Pischke 2014) [PDF]\n\n\n\nThis book is included as the second of the three ‚Äúcore‚Äù texts mainly because, it uses the language of causality specific to Econometrics, the language that is most familiar to me from my PhD training in Political Economy. However, if you tend to learn better by example, it also does a good job of foregrounding specific examples (like evaluating charter schools and community policing policies), so that the methods emerging naturally from attempts to solve these puzzles when association methods like linear regression fail to capture their causal linkages.\n\n\n\n\n\n\n\n\n Pearl and Mackenzie (2018)\n\n\n\nPearl and Mackenzie, The Book of Why: The New Science of Cause and Effect [EPUB]\n\n\n\nThis book contrasts with the Angrist and Pischke book in using the language of causality formed within Computer Science rather than Economics. It can be a good starting point especially if you‚Äôre unfamiliar with the heavy use of diagrams for scientific modeling‚Äîbasically, whereas Angrist and Pischke‚Äôs first instinct is to use (sometimes informal) equations like \\(y = mx + b\\) to explain steps in the procedures, Pearl and Mackenzie‚Äôs instinct would be to instead use something like \\(\\require{enclose}\\enclose{circle}{\\kern .01em ~x~\\kern .01em} \\overset{\\small m, b}{\\longrightarrow} \\enclose{circle}{\\kern.01em y~\\kern .01em}\\) to represent the same concept (in this case, a line with slope \\(m\\) and intercept \\(b\\)!).",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#core-textbooks",
    "href": "resources.html#core-textbooks",
    "title": "Resources",
    "section": "",
    "text": "As mentioned on the syllabus, the field of causal inference in general (and causal inference for computational social science in particular) moves excitingly-fast, such that the material has yet to ‚Äúcongeal‚Äù into a single, all-encompassing textbook. Nonetheless, the following three books cover a substantial amount of ground (described in more detail below each citation), so that together they form a coherent ‚Äúthree-volume textbook‚Äù for this class! If you can only read three books this summer, read these :)\n\n\n\n\n\n\n Morgan and Winship (2015)\n\n\n\nMorgan and Winship, Counterfactuals and Causal Inference: Methods and Principles for Social Research [PDF]\n\n\n\nThis is the book which comes closest to being an all-encompassing, single textbook for the class! It brings together different ‚Äústrands‚Äù of causal modeling research (since each field‚Äîeconomics, bioinformatics, sociology, etc.‚Äîtends to use its own notation and vocabulary), unifying them into a single approach. The only reason we can‚Äôt use it as the main textbook is because it hasn‚Äôt been updated since 2015, and most of the assignments in this class use computational tools from 2018 onwards!\n\n\n\n\n\n\n\n\n Angrist and Pischke (2014)\n\n\n\nAngrist and Pischke, Mastering ‚ÄôMetrics: The Path from Cause to Effect (Angrist and Pischke 2014) [PDF]\n\n\n\nThis book is included as the second of the three ‚Äúcore‚Äù texts mainly because, it uses the language of causality specific to Econometrics, the language that is most familiar to me from my PhD training in Political Economy. However, if you tend to learn better by example, it also does a good job of foregrounding specific examples (like evaluating charter schools and community policing policies), so that the methods emerging naturally from attempts to solve these puzzles when association methods like linear regression fail to capture their causal linkages.\n\n\n\n\n\n\n\n\n Pearl and Mackenzie (2018)\n\n\n\nPearl and Mackenzie, The Book of Why: The New Science of Cause and Effect [EPUB]\n\n\n\nThis book contrasts with the Angrist and Pischke book in using the language of causality formed within Computer Science rather than Economics. It can be a good starting point especially if you‚Äôre unfamiliar with the heavy use of diagrams for scientific modeling‚Äîbasically, whereas Angrist and Pischke‚Äôs first instinct is to use (sometimes informal) equations like \\(y = mx + b\\) to explain steps in the procedures, Pearl and Mackenzie‚Äôs instinct would be to instead use something like \\(\\require{enclose}\\enclose{circle}{\\kern .01em ~x~\\kern .01em} \\overset{\\small m, b}{\\longrightarrow} \\enclose{circle}{\\kern.01em y~\\kern .01em}\\) to represent the same concept (in this case, a line with slope \\(m\\) and intercept \\(b\\)!).",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#core-reference-texts",
    "href": "resources.html#core-reference-texts",
    "title": "Resources",
    "section": "Core Reference Texts",
    "text": "Core Reference Texts\nIn contrast to the books in the previous section, these books are not ‚Äúthe‚Äù textbooks for the class! These are here instead as reference books, to keep on hand (a) for when the lectures or the above books are unclear on some topic, and/or (b) for deeper dives into certain topics (where the latter may become a more relevant mission for you as we move towards the final project üòâ)\nJudea Pearl (2002). Causality",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#econometric-policy-evaluation",
    "href": "resources.html#econometric-policy-evaluation",
    "title": "Resources",
    "section": "Econometric Policy Evaluation",
    "text": "Econometric Policy Evaluation\n\n(bjorkegren_machine_2022?), ‚Äú(Machine) Learning what Policymakers Value‚Äù, EAAMO (Equity and Access in Algorithms, Mechanisms, and Optimization) [PDF]",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#video-resources",
    "href": "resources.html#video-resources",
    "title": "Resources",
    "section": "Video Resources",
    "text": "Video Resources\nTo me (as in, given how my brain works), there are certain topics which I‚Äôve spent hours trying to understand via reading, only to realize that there‚Äôs some simple diagram or animation out there which ‚Äúclicks‚Äù it in my mind 10000 times more effectively than the reading ever would.\nSo, to that end, these video resources are just as important as (for some topics far more important than) the resources above!1",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#footnotes",
    "href": "resources.html#footnotes",
    "title": "Resources",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor similar reasons, audiobooks may provide more effective ways to digest some topics in the course!‚Ü©Ô∏é",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "midterm.html",
    "href": "midterm.html",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "",
    "text": "The DSAN 5450 in-class midterm will start at 3:30pm on Wednesday, February 26th. It is intended to take only 1.5 hours, but you will have 3 hours to take it just in case, so that it will be due by 6:30pm.\nWe‚Äôve covered a lot of‚Ä¶ sometimes-disjointed topics thus far, so our goal for the midterm is to emphasize the most important takeaways from across the first six weeks of the class, by putting them in your brain‚Äôs short-term memory one more time before we dive into the second, policy-focused half of the course when you come back from spring break! As a reminder, there is a very good reason to continually try and re-remember the same course topics, coming from studies of long-term memory retention:"
  },
  {
    "objectID": "midterm.html#overview",
    "href": "midterm.html#overview",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "",
    "text": "The DSAN 5450 in-class midterm will start at 3:30pm on Wednesday, February 26th. It is intended to take only 1.5 hours, but you will have 3 hours to take it just in case, so that it will be due by 6:30pm.\nWe‚Äôve covered a lot of‚Ä¶ sometimes-disjointed topics thus far, so our goal for the midterm is to emphasize the most important takeaways from across the first six weeks of the class, by putting them in your brain‚Äôs short-term memory one more time before we dive into the second, policy-focused half of the course when you come back from spring break! As a reminder, there is a very good reason to continually try and re-remember the same course topics, coming from studies of long-term memory retention:"
  },
  {
    "objectID": "midterm.html#part-1-high-level-data-ethics-considerations",
    "href": "midterm.html#part-1-high-level-data-ethics-considerations",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 1: High-Level Data Ethics Considerations",
    "text": "Part 1: High-Level Data Ethics Considerations\nThis part corresponds roughly to the first two sessions of the course, where we talked about key ‚Äúhigh-level‚Äù questions in data ethics.\n\n(1.1) The Library of Missing Datasets\nWhy does some information already exist in the form of nicely-formatted, easily-accessible datasets, while other information does not?\n\nHere the specific reference in class was to the Library of Missing Datasets, so you can check out the photos at that link for examples of missing datasets.\nThe midterm question here could, therefore, ask you to think through the process by which a certain dataset came into existence as (e.g.) a clean, easily-available .csv file, and/or why another set of data might not exist in this form.\n\n\n\n(1.2) Operationalization\nWhat types of data-ethical issues arise because of the ‚Äúgap‚Äù between conceptual variables and operationalized variables?\n\nHere the main reference for you is this slide from Week 2\nFor the possible midterm question here, specifically, you should focus on the idea behind the book on the right side of that slide: ‚ÄúMis-Measuring Our Lives‚Äù. That book points out the gap between the conceptual variable [economic well-being] and its operationalization as [GDP].\n\nSo, for the midterm, we might ask you to consider a conceptual variable like ‚Äúfairness‚Äù or ‚Äúprivacy‚Äù, and think through different ways they could be operationalized as measurable quantities."
  },
  {
    "objectID": "midterm.html#part-2-ethical-frameworks",
    "href": "midterm.html#part-2-ethical-frameworks",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 2: Ethical Frameworks",
    "text": "Part 2: Ethical Frameworks\n\n(2.1) Descriptive vs.¬†Normative\nI think you all did a great job of demonstrating that you understand this distinction, through homeworks and discussions (in class and in office hours)! So, on this topic I think you can just review the basic ‚Äúgist‚Äù of how this works:\nTwo types of Descriptive statements:\n\nNon-implicational statements that describe facts, like \\(1 + 1 = 2\\), are descriptive but indeterminate without a set of axioms (definitions for the symbols, in this case)\nImplicational statements that describe facts, like \\(ZFC \\implies 1 + 1 = 2\\), are descriptive and also determinate (in this case, determinately true)\n\nTwo types of Normative statements:\n\nWhen the statements are not descriptions of empirically/observationally (and intersubjectively) verifiable predicates about how things are (‚ÄúGrass is green‚Äù), but are instead prescriptions of how things ought to be (‚ÄúGrass ought to be green‚Äù/‚ÄúIt is good for grass to be green and bad for grass to be blue‚Äù), they have additional normative dimensions\nHowever, in the same way that the descriptive statement \\(1 + 1 = 2\\) goes from indeterminate to determine when we provide a set of axioms, normative statements are also transformed from indeterminate to determinate when we provide an ethical framework within which the normative statement can be evaluated.\n\n\n\n(2.2) Consequentialism vs.¬†Deontological Ethics\nThis portion would also very much involve the two most common concrete versions of these two ethical frameworks:\n\nUtilitarianism as the most common consequentialist framework\nKantian Ethics as the most common deontological-ethical framework\n\nOn the latter two points specifically, I didn‚Äôt make the distinction as clearly as I should have in class, so I‚Äôm making it here!\nQuestion 2.5 from Homework 1 provided the following statement:\n\n¬´Lying is bad, since you wouldn‚Äôt want others to lie to you.¬ª\n\nAnd then, between Consequentialism and Deontological Ethics, the correct answer was that this statement is more straightforwardly implied by Deontological Ethics. I know this one is particularly difficult to think through, but I wanted to highlight it here because this is the question that really reveals the subtle-but-important distinction between these two systems:\n\nA consequentialist approach to ‚Äúresolving‚Äù a dilemma around lying would, crucially, be based on a prediction of the actual consequences that would result from a possible choice, whereas\nA deontological approach differs from this in considering what makes a possible choice good or bad in-and-of-itself, without reference to the predicted consequences.\n\nThe reason I phrase the distinction in this way is because, in the above statement, you can focus on the portion after the word ‚Äúsince‚Äù (‚Äúsince you wouldn‚Äôt want others to lie to you‚Äù):\n\nWithin a consequentialist framework, this reasoning would not itself constitute a justification for not lying, since it would have to be paired with a statement like ‚ÄúIf I lie, then it is likely that others will lie to me‚Äù, which is not true in general! The idiom of a ‚Äúwhite lie‚Äù, for example, comes precisely from the fact that there are often times when we feel like we should lie to people to avoid the consequence of hurting them.\nWithin a deontological framework, on the other hand, this reasoning would constitute a justification for not lying, since it corresponds precisely to the rule that was mentioned in the prior two questions: Kant‚Äôs Categorical Imperative.\nThis Categorical Imperative rule is of special interest, relative to the full set of ‚Äúethical rules‚Äù you could imagine using, because it is a rule for making ethical decisions without reference to the consequences of a particular choice:\n\nInstead of predicting what might happen if I make this choice, and judging whether it is an ethical choice on that basis‚Ä¶\nI now imagine what would happen hypothetically if everyone else in the world made the choice, whether or not my action would in fact make everyone else in the world make the same choice!\n\n\nI hope that explanation, and the reference to ‚Äúwhite lies‚Äù as an example, can help make it more clear why the answer to Question 2.5 was ‚ÄúDeontological Ethics‚Äù. As one final point, to make it super concrete:\n\nThe reason why the answer is not Consequentialism here is because, a Consequentialist might agree that ‚ÄúI wouldn‚Äôt want others to lie to me‚Äù, and yet also think ‚ÄúBut that‚Äôs not a good reason to not lie, since I could lie here without it causing others to lie to me.‚Äù\nThat is what would enable ‚Äúwhite lies‚Äù to be acceptable under consequentialism: since you only consider the predicted consequences of your action in the ‚Äúreal world‚Äù, rather than in a hypothetical world where everyone does the same action, you are then able to move to a comparison of whether the benefits of lying outweigh the costs of lying, as one way to make the decision (by ‚Äúcalculating‚Äù the consequences!)."
  },
  {
    "objectID": "midterm.html#part-3-context-free-fairness-and-proxy-variables",
    "href": "midterm.html#part-3-context-free-fairness-and-proxy-variables",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 3: Context-Free Fairness and Proxy Variables",
    "text": "Part 3: Context-Free Fairness and Proxy Variables\nHere the main idea will be to think through the fairness definitions introduced in this part:\n\nFairness Through Unawareness (Removing ‚Äúsensitive‚Äù variables from the dataset)\nFairness as Equalized Positive Rate\nFairness as Equalized False Positive Rate\nFairness as Equalized False Negative Rate\nFairness as Calibration\n\nAnd especially to be able to understand the ‚Äúsimple‚Äù cases when these might work, but also the non-simple cases where these fail to capture what we‚Äôd like a robust / actually-usable fairness measure to capture. Some straightforward questions to guide you in this thinking for this part would be, e.g.:\n\nCan we have all of these measures at once?\n\nShort answer: No.¬†But, you should also have some degree of intuition from class about why we can‚Äôt (the impossibility results)\n\nThe first four are probably more straightforward, as things we can achieve by dropping variables (Unawarness) or by reading the entries in a confusion matrix. Calibration, however, requires a bit more thought:\n\nHow is calibration defined? The most succinct definition would just be: the requirement that the value of the risk score \\(r(X)\\) that ‚Äúunderlies‚Äù the decision-making algorithm (in that it is used to produce our predictions \\(\\widehat{Y}\\)) is itself a probability value‚Äînamely, the probability that a person with attributes \\(X\\) has associated outcome \\(Y\\).\nWhy is calibration desirable? Why does it help us in terms of assessing fairness? The definition in the previous bullet point is not very easy-to-understand (to me, at least), so that I interpret it as just a requirement that the risk score ‚Äútracks‚Äù the relationship between \\(X\\) and \\(Y\\) in a direct way: for example, high values of \\(\\Pr(Y \\mid X)\\) mean high values of the underlying representation \\(r(X)\\) that is used to generate \\(\\widehat{Y}\\) as a prediction of \\(Y\\).\nViewed in this way, then, I hope it makes sense that this property would be desirable in terms of interpretability: it means that, if we wanted to know why our prediction algorithm was producing some specific prediction \\(\\widehat{Y}_i\\) for a person with attributes \\(X_i\\), we could ‚Äúopen up the black box‚Äù of the algorithm and look directly at the risk score \\(r(X_i)\\) with respect to the risk score function \\(r(\\cdot)\\) in general, to see why it produced such a high/low value of \\(\\widehat{Y}_i\\).\nI know even that last point can still be confusing, so to me the final ‚Äúpiece‚Äù for understanding is to think about how: if we didn‚Äôt have calibration, then we would have no natural way of interpreting the risk function \\(r(\\cdot)\\). Since without calibration it is not constrained to represent a probability, it could take on any value‚Äî\\(\\pi\\), \\(-1000\\), \\(\\sqrt{2^{100}}\\)‚Äîand we would have no way of knowing the relationship between these values and the resulting predictions \\(\\widehat{Y}\\); no way of knowing, for example, why plugging in a person with characteristics \\(X_i\\) produced \\(r(X_i) = \\pi\\) which then led to the prediction \\(\\widehat{Y}_i = 1\\), to detain this person until trial!"
  },
  {
    "objectID": "midterm.html#part-4-context-sensitive-fairness",
    "href": "midterm.html#part-4-context-sensitive-fairness",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 4: Context-Sensitive Fairness",
    "text": "Part 4: Context-Sensitive Fairness\nWe spent some amount of time critiquing the fairness definitions mentioned in the previous section. This was not for the sake of judging whether they‚Äôre ‚Äúgood‚Äù or ‚Äúbad‚Äù as such, but rather, for the sake of understanding specifically what they‚Äôre missing. Two different characterizations of what they‚Äôre missing give us our two key context-sensitive approaches to fairness, discussed in the next two sections:\n\n(4.1) Individual-Similarity-Based Fairness\n\nThe Context-Free measures fail to consider how satisfying a criterion (e.g., Equalized False Positive Rate) at a group level could trample over the rights of individuals.\n\nThe illustration of this failure that I mentioned in class boiled down to:\n\nLet \\(A_i\\) represent a sensitive attribute of individuals, such that \\(A_i = 0\\) if person \\(i\\) is white, and \\(A_i = 1\\) if person \\(i\\) is black.\nIf a police department finds itself failing to satisfy a fairness criterion like Equality of Positive Rates, in the sense that their arrest rate \\(r_1\\) for individuals with \\(A_i = 1\\) is higher than their arrest rate \\(r_0\\) for individuals with \\(A_i = 0\\), then‚Ä¶\nThey can quickly ‚Äúresolve‚Äù this failure and satisfy the criterion by running outside and arresting the first \\(N\\) white people they see, where \\(N\\) is the number of additional white arrestees that would be necessary to make \\(r_0 = r_1\\).\n\nHowever, as this illustration hopefully makes clear, this procedure would allow satisfaction of the group-level fairness criterion, but only at the expense of violating our intuitive notions of fairness towards individuals.\nAlthough there are lots and lots of ways that this notion of individual-level fairness could be incorporated into the Context-Free fairness measures to make them Context-Sensitive, one of the most popular and straightforward ways is by constructing an indiviudal-similarity-based fairness measure, and then using it to constrain the space of possible decisions by enforcing the rule that:\n\n\n\n\n\n\nFairness Through Awareness (dwork_fairness_2011?)\n\n\n\nIndividuals who are similar with respect to a task should be classified similarly.\n\n\nThe first thing I want you to note about this approach is that it specifically aims to resolve the issue we‚Äôve already seen with utilitarianism, namely, that * Optimizing society-level desiderata (like ‚Äúoverall happiness‚Äù) may lead to * individuals being brutally mistreated (e.g., having their rights violated)\nYou can also hopefully see how this notion (Fairness Through Awarness) could provide a Rawls-style ordering: individual fairness lexically prior to group-level fairness (optimize group-level fairness once individual-level is satisfied).\nThen lastly, as you saw on HW2, this general notion of Fairness Through Awareness can be operationalized as a measurable quantity by, for example, implementing what is generally called metric fairness: Given a similarity metric \\(m: \\mathcal{I} \\times \\mathcal{I} \\rightarrow \\mathbb{R}\\), where \\(\\mathcal{I}\\) is the set of all individuals,\n\\[\n|D_i - D_j| \\leq m(i, j)\n\\]\nfor all pairs of individuals \\((i, j)\\). Or in other words, that the difference between the decisions \\(D_i\\) and \\(D_j\\) should be bounded above by the similarity \\(m(i,j)\\) between \\(i\\) and \\(j\\).\nThis, to me, is already slightly more than you need to know for the midterm, but if you want to dive into this Context-Sensitive approach specifically, Section 5.1 of (mitchell_algorithmic_2021?) has a really great discussion of Metric Fairness specifically.\n\n\n(4.2) Causal Fairness\nThis is the capital-B capital-D Big Deal approach to fairness, in my view, but you‚Äôve already heard enough about that in class and on HW2!\nSo, for the midterm, instead I will just say that the key thing I want you to be comfortable with for now is drawing and interpreting Causal Diagrams like the ones I‚Äôve shown in the slides and drawn on the board in class.\nFirst and foremost, if you absorb the Quick Intro to Probabilistic Graphical Models writeup, you are most of the way there to understanding Causal Diagrams in general, since (sweeping some details under the rug) these Causal Diagrams are primarily just PGMs where we interpret the edges (the arrows in the PGMs) as hypothesized causal effects.\nThus, for the midterm, my first goal is to test your ability to read these PGMs and understand what they‚Äôre positing (‚Äúsaying‚Äù) about the world. For example, if I give you a hypothesis like\n\n\\(H_1\\): Individual \\(i\\) was arrested because they are black\n\nYou should be able to ‚Äútranslate‚Äù this into a causal diagram based on:\n\nA random variable \\(Y_i\\) representing whether or not an individual \\(i\\) was arrested (where we use the letter \\(Y\\) here speicifcally because we‚Äôre representing an outcome that we‚Äôre hoping to explain)\nA random variable \\(A_i\\) representing the race of individual \\(i\\), and\nAn edge \\(A_i \\rightarrow Y_i\\), representing the hypothesis that individual \\(i\\)‚Äôs specific \\(A_i\\) value (\\(A_i = a_i\\)) is what caused \\(Y_i\\) to take on individual \\(i\\)‚Äôs specific \\(Y_i\\) value (\\(Y_i = y_i = 1\\), in this case).\n\nThen, once you‚Äôre comfortable with this process of ‚Äúimplementing‚Äù hypotheses by constructing causal diagrams, the only other thing I think will be important for the midterm is your ability to adjudicate between two or more such diagrams on the basis of their plausibility.\nWhat I mean by that is‚Ä¶ keep in mind the definition of causality that was given in a slide in class:\n\n\n\n\n\n\nDefining Causality (hume_treatise_1739?)\n\n\n\n\\(X\\) causes \\(Y\\) if and only if:\n\n\\(X\\) temporally precedes \\(Y\\) and\n\nIn two worlds \\(W_0\\) and \\(W_1\\) where\neverything is exactly the same except that \\(X = 0\\) in \\(W_0\\) and \\(X = 1\\) in \\(W_1\\),\n\\(Y = 0\\) in \\(W_0\\) and \\(Y = 1\\) in \\(W_1\\).\n\n\n\n\nYou should be able to use this definition to (for example) eliminate implausible causal diagrams, namely, causal diagrams which violate the basic predicates within this definition. So, for example, say I gave you the following causal diagram as a causal hypothesis regarding how toasters toast a piece of bread \\(i\\):\n\n\\(T_i\\) is a Random Variable which is \\(0\\) if the bread has not yet been placed in the toaster and \\(1\\) if has been placed in the toaster,\n\\(C_i\\) is a Random Variable which is \\(0\\) if the bread is not cooked, and \\(1\\) if the bread is cooked, and\nThere is an arrow \\(C_i \\rightarrow T_i\\)\n\nYou should be able to identify this as an implausible causal diagram‚Äîmeaning, a causal diagram representing an implausible hypothesis about how toasters work, relative to the Humean notion of causality‚Äîsince in our observations of how toasters work, the bread being placed in the toaster (\\(\\text{do}(T_i = 1)\\)) occurs before the bread being cooked \\(C_i = 1\\), temporally."
  },
  {
    "objectID": "midterm.html#part-5-doin-thangs-causality-continued",
    "href": "midterm.html#part-5-doin-thangs-causality-continued",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Part 5: Doin Thangs (Causality Continued)",
    "text": "Part 5: Doin Thangs (Causality Continued)\nShort story short, the example from the end of our most recent meeting, where we showed how it‚Äôs possible to have:\n\n\\(\\Pr(Y = 1) = p_y\\), and\n\\(\\Pr(Y = 1 \\mid X = 1) \\neq p_y\\), and yet\n\\(\\Pr(Y = 1 \\mid \\text{do}(X = 1)) = p_y\\),\n\nThus revealing the fact that \\(\\Pr(Y = 1 \\mid X = 1)\\) does not capture the causal effect of \\(X\\) on \\(Y\\) in this case, which is just one specific instance of the general maxim you already know, that correlation does not imply causation.\nAnd yet, with this \\(\\text{do}(E)\\) operator (where \\(E\\) is some probabilistic event), we have something concrete that we can use to start figuring out when observing a correlation does allow us to infer a causal effect!\nThe actual figuring-out will have to wait until after the midterm. But I want you to have that notion in your head when you see the \\(\\text{do}(\\cdot)\\) operator and/or a causal diagram: that these are the tools that are going to allow us to bridge this gap between correlation and causation, something that probability theory alone (i.e., the stuff you may have learned in DSAN 5100) cannot do!\nAs a preview, which I mentioned at the very very end of the ‚Äúdo-calculus‚Äù example I went through on the board: Pearl (2000) is literally a gigantic book that meticulously works through all possible causal diagrams1 and proves a massively important theorem that we‚Äôll see after the midterm, which tells us precisely what conditions need to be met (in a given causal system) for us to be able to infer causal effects from conditional probabilities."
  },
  {
    "objectID": "midterm.html#references",
    "href": "midterm.html#references",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "References",
    "text": "References\n\n\nPearl, Judea. 2000. Causality: Models, Reasoning, and Inference. Cambridge University Press."
  },
  {
    "objectID": "midterm.html#footnotes",
    "href": "midterm.html#footnotes",
    "title": "DSAN 5450 Midterm Study Guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNot like, one-by-one, but by mathematically characterizing all of the possibilities, like how we can say that ¬´Assuming Euclid‚Äôs 5th Postulate, the interior angles of a triangle sum to 180¬∞¬ª, despite not having gone one-by-one through every triangle.‚Ü©Ô∏é"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSAN 5650: Causal Inference for Computational Social Science",
    "section": "",
    "text": "Welcome to the homepage for DSAN 5650: Causal Inference for Computational Social Science at Georgetown University, for the Summer 2025 session!\nThe course meets on Wednesdays from 6:30pm to 9:00pm online, via the Zoom Link provided in the sidebar.\nCheck out the syllabus (or any other link in the sidebar) for more info! Or, use the following links to view notes for individual weeks:\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1: From a Science of Particles to a Science of People\n\n\nMay 21\n\n\n\n\n\nNo matching items\n\n\nCourse Description:\nThis course provides students with the opportunity to take the analytical skills, machine learning algorithms, and statistical methods learned throughout their first year in the program and explore how they can be employed towards carrying out rigorous, original research in the behavioral and social sciences. With a particular emphasis on tackling the additional challenges which arise when moving from associational to causal inference, particularly when only observational (as opposed to experimental) data is available, students will become proficient in cutting-edge causal Machine Learning techniques such as propensity score matching, synthetic controls, causal program evaluation, inverse social welfare function estimation from panel data, and Double-Debiased Machine Learning.\nIn-class examples will cover continuous, discrete-choice, and textual data from a wide swath of social and behavioral sciences: economics, political science, sociology, anthropology, quantitative history, and digital humanities. After gaining experience through in-class labs and homework assignments focused on reproducing key findings from recent journal articles in each of these disciplines, students will spend the final weeks of the course on a final project demonstrating their ability to develop, evaluate, and test the robustness of a causal hypothesis.\nPrerequisites: DSAN 5000, DSAN 5100 (DSAN 5300 recommended but not required)",
    "crumbs": [
      "<i class='bi bi-house pe-1'></i> Home"
    ]
  },
  {
    "objectID": "writeups/pgm-intro/index.html",
    "href": "writeups/pgm-intro/index.html",
    "title": "A Quick Introduction to Probabilistic Graphical Models",
    "section": "",
    "text": "A Probabilistic Graphical Model (PGM) is just a formal mathematical representation of a data-generating process. So, if we wanted to model the relationship between weather and a person‚Äôs choice of whether to go out and party or stay in and watch a movie on a given Saturday evening, we could begin by proposing the following data-generating process:\nNow, given the description of a PGM given above (nodes as variables, edges as relationships between variables), we can perform the move alluded to in the previous section: we can convert our data-generating process into a PGM, by defining nodes (variables) and edges (relationships) as follows:\nThe resulting PGM, in graphical form1, is presented below, followed by the Conditional Probability Table describing the edge from the \\(W\\) node to the \\(Y\\) node.\nPGMs can help us make inferences about the world in the face of incomplete information, which is the situation in nearly every real-world problem. The key tool here is the separation of nodes into two categories: observed (represented graphically as a shaded node) and latent (represented graphically as an unshaded node).\nThus we can now use our model as a weather-inference machine: if we observe that the person we‚Äôre modeling is out at a party with us, what can we infer from this information about the weather outside? We can draw this situation as a PGM with shaded and unshaded nodes, as in the figure below, and then use Bayes‚Äô Rule to perform calculations over the network, to see how the observed information about the person at the party ‚Äúflows‚Äù back into the node representing the weather.\nKeeping in mind that Bayes‚Äô Rule tells us, for any two events \\(A\\) and \\(B\\), how to use information about \\(\\Pr(B \\mid A)\\) to obtain information about \\(\\Pr(A \\mid B)\\):\n\\[\n\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)},\n\\]\nWe can now apply this rule to obtain our new probability distribution over the weather, taking into account the new information that the person has chosen to go out:\n\\[\n\\begin{align*}\n&\\Pr(W = \\textsf{Sunny} \\mid Y = \\textsf{Go Out})\n= \\frac{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny})}{\\Pr(Y = \\textsf{Go Out})} \\\\\n= &\\frac{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny})}{\\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Sunny}) + \\Pr(Y = \\textsf{Go Out} \\mid W = \\textsf{Rainy})}\n\\end{align*}\n\\]\nAnd now we simply plug in the information we already have from our conditional probability table to obtain our new (conditional) probability of interest:\n\\[\n\\begin{align*}\n\\Pr(W = \\textsf{Sunny} \\mid Y = \\textsf{Go Out}) &= \\frac{(0.8)(0.5)}{(0.8)(0.5) + (0.1)(0.5)} \\\\\n&= \\frac{0.4}{0.4 + 0.05} = \\frac{0.4}{0.45} \\approx 0.89.\n\\end{align*}\n\\]\nWe have learned something interesting: now that we‚Äôve observed the person out at a party, the probability that it is sunny out jumps from \\(0.5\\) (called the ‚Äúprior‚Äù estimate of \\(W\\), i.e., our best guess without any other relevant information) to \\(0.89\\) (called the ‚Äúposterior‚Äù estimate of \\(W\\), i.e., our best guess after incorporating relevant information)."
  },
  {
    "objectID": "writeups/pgm-intro/index.html#footnotes",
    "href": "writeups/pgm-intro/index.html#footnotes",
    "title": "A Quick Introduction to Probabilistic Graphical Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe term ‚ÄúGraphical‚Äù in Probabilistic Graphical Model is not used in the same sense as the ‚Äúgraphical‚Äù we‚Äôre used to from vernacular English. Capital-G Graphical denotes that the Probabilistic Model is represented as a Graph, a well-defined mathematical object consisting of nodes and edges, which does not have to be represented graphically (though it could be, like in our example here with circles and arrows). In fact, when a computer program is estimating a PGM, it is by definition not in a graphical form‚Äîit‚Äôs in the form of 0s and 1s, stored in the computer‚Äôs memory.‚Ü©Ô∏é"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignment Point Distributions",
    "section": "",
    "text": "Use the tabs below to view the point distributions for different assignments.\nThe distributions are imported from Google Sheets mainly for transparency: so that you can see exactly how totals are computed as a sum of the individual points allocated for each test!\n\nHW1HW2\n\n\n\n\n\n\n\n\n\npart\nqid\ntest_type\npoints\npart_total\n\n\n\n\n1\nQ1.1\npublic\n0\n12\n\n\n\nQ1.1\nhidden\n1\n\n\n\n\nQ1.2\npublic\n0\n\n\n\n\nQ1.2\nhidden\n1\n\n\n\n\nQ1.3\npublic\n0\n\n\n\n\nQ1.3\nhidden\n1\n\n\n\n\nQ1.4\npublic\n0\n\n\n\n\nQ1.4\nhidden\n1\n\n\n\n\nQ1.5\npublic\n0\n\n\n\n\nQ1.5\nhidden\n1\n\n\n\n\nQ1.6\npublic\n0\n\n\n\n\nQ1.6\nhidden\n1\n\n\n\n\nQ1.7\npublic\n0\n\n\n\n\nQ1.7\nhidden\n1\n\n\n\n\nQ1.8\npublic\n0\n\n\n\n\nQ1.8\nhidden\n1\n\n\n\n\nQ1.9\npublic\n0\n\n\n\n\nQ1.9\nhidden\n1\n\n\n\n\nQ1.10\npublic\n0\n\n\n\n\nQ1.10\nhidden\n1\n\n\n\n\nQ1.11\npublic\n0\n\n\n\n\nQ1.11\nhidden\n1\n\n\n\n\nQ1.12\npublic\n0\n\n\n\n\nQ1.12\nhidden\n1\n\n\n\n2\nQ2.1\npublic\n0\n7\n\n\n\nQ2.1\nhidden\n1\n\n\n\n\nQ2.2\npublic\n0\n\n\n\n\nQ2.2\nhidden\n1\n\n\n\n\nQ2.3\npublic\n0\n\n\n\n\nQ2.3\nhidden\n1\n\n\n\n\nQ2.4\npublic\n0\n\n\n\n\nQ2.4\nhidden\n1\n\n\n\n\nQ2.5\npublic\n0\n\n\n\n\nQ2.5\nhidden\n1\n\n\n\n\nQ2.6\npublic\n0\n\n\n\n\nQ2.6\nhidden\n2\n\n\n\n3\nQ3.1\npublic\n0\n5\n\n\n\nQ3.1\nhidden\n1\n\n\n\n\nQ3.2\npublic\n0\n\n\n\n\nQ3.2\nhidden\n1\n\n\n\n\nQ3.3a\npublic\n0\n\n\n\n\nQ3.3a\nhidden\n1\n\n\n\n\nQ3.3b\npublic\n0\n\n\n\n\nQ3.3b\nhidden\n1\n\n\n\n\nQ3.3c\npublic\n0\n\n\n\n\nQ3.3c\nhidden\n1\n\n\n\n4.1\nQ4.1.1\npublic\n1\n13\n\n\n\nQ4.1.1\nhidden\n2\n\n\n\n\nQ4.1.2\npublic\n1\n\n\n\n\nQ4.1.2\nhidden\n2\n\n\n\n\nQ4.1.3\npublic\n1\n\n\n\n\nQ4.1.3\nhidden\n1\n\n\n\n\nQ4.1.4\npublic\n1\n\n\n\n\nQ4.1.4\nhidden\n2\n\n\n\n\nQ4.1.5\npublic\n1\n\n\n\n\nQ4.1.5\nhidden\n1\n\n\n\n4.2\nQ4.2.1\npublic\n1\n4\n\n\n\nQ4.2.1\nhidden\n1\n\n\n\n\nQ4.2.2\npublic\n1\n\n\n\n\nQ4.2.2\nhidden\n1\n\n\n\n4.3\nQ4.3.1\npublic\n1\n4\n\n\n\nQ4.3.1\nhidden\n1\n\n\n\n\nQ4.3.2\npublic\n1\n\n\n\n\nQ4.3.2\nhidden\n1\n\n\n\n4.4\nQ4.4.1\npublic\n1\n3\n\n\n\nQ4.4.1\nhidden\n2\n\n\n\n4.5\nQ4.5.1\npublic\n1\n4\n\n\n\nQ4.5.1\nhidden\n2\n\n\n\n\nQ4.5.2\npublic\n0\n\n\n\n\nQ4.5.2\nhidden\n1\n\n\n\n4.6\nQ4.6.1\npublic\n1\n3\n\n\n\nQ4.6.1\nhidden\n2\n\n\n\n4.7\nQ4.7.1\npublic\n1\n5\n\n\n\nQ4.7.1\nhidden\n2\n\n\n\n\nQ4.7.2\npublic\n1\n\n\n\n\nQ4.7.2\nhidden\n1\n\n\n\n4.8\nQ4.8.1\npublic\n1\n11\n\n\n\nQ4.8.1\nhidden\n2\n\n\n\n\nQ4.8.2\npublic\n0\n\n\n\n\nQ4.8.2\nhidden\n1\n\n\n\n\nQ4.8.3\npublic\n0\n\n\n\n\nQ4.8.3\nhidden\n1\n\n\n\n\nQ4.8.4\npublic\n1\n\n\n\n\nQ4.8.4\nhidden\n2\n\n\n\n\nQ4.8.5\npublic\n1\n\n\n\n\nQ4.8.5\nhidden\n2\n\n\n\n4.9\nQ4.9.1\npublic\n0\n2\n\n\n\nQ4.9.1\nhidden\n1\n\n\n\n\nQ4.9.2\npublic\n0\n\n\n\n\nQ4.9.2\nhidden\n1\n\n\n\n4.10\nQ4.10.1\npublic\n0\n8\n\n\n\nQ4.10.1\nhidden\n1\n\n\n\n\nQ4.10.2\npublic\n0\n\n\n\n\nQ4.10.2\nhidden\n1\n\n\n\n\nQ4.10.3\npublic\n1\n\n\n\n\nQ4.10.3\nhidden\n2\n\n\n\n\nQ4.10.4\npublic\n1\n\n\n\n\nQ4.10.4\nhidden\n2\n\n\n\n4.11\nQ4.11.1\npublic\n1\n6\n\n\n\nQ4.11.1\nhidden\n2\n\n\n\n\nQ4.11.2\npublic\n1\n\n\n\n\nQ4.11.2\nhidden\n2\n\n\n\n4.12\nQ4.12\npublic\n1\n5\n\n\n\nQ4.12\nhidden\n4\n\n\n\n5\nQ5.1\npublic\n0\n8\n\n\n\nQ5.1\nhidden\n2\n\n\n\n\nQ5.2\npublic\n0\n\n\n\n\nQ5.2\nhidden\n2\n\n\n\n\nQ5.3\npublic\n0\n\n\n\n\nQ5.3\nhidden\n2\n\n\n\n\nQ5.4\npublic\n0\n\n\n\n\nQ5.4\nhidden\n2\n\n\n\nTotal\n\n\n100\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npart\nqid\ntest_type\npoints\npart_total\n\n\n\n\n1\nQ1.1\npublic\n0\n\n\n\n\nQ1.1\nhidden\n2\n\n\n\n\nQ1.2\npublic\n0\n\n\n\n\nQ1.2\nhidden\n2\n\n\n\n\nQ1.3a\npublic\n0\n\n\n\n\nQ1.3a\nhidden\n2\n\n\n\n\nQ1.3b\npublic\n0\n\n\n\n\nQ1.3b\nhidden\n2\n\n\n\n\nQ1.4a\npublic\n0\n\n\n\n\nQ1.4a\nhidden\n2\n\n\n\n\nQ1.4b\npublic\n0\n\n\n\n\nQ1.4b\nhidden\n2\n\n\n\n\nQ1.5\npublic\n0\n\n\n\n\nQ1.5\nhidden\n2\n\n\n\n\nQ1.6\npublic\n0\n\n\n\n\nQ1.6\nhidden\n2\n\n\n\n\nQ1.7\npublic\n0\n\n\n\n\nQ1.7\nhidden\n2\n\n\n\n\nQ1.8\npublic\n0\n\n\n\n\nQ1.8\nhidden\n2\n20\n\n\n2\nQ2.1\npublic\n0\n\n\n\n\nQ2.1\nhidden\n5\n\n\n\n\nQ2.2\npublic\n0\n\n\n\n\nQ2.2\nhidden\n5\n10\n\n\n3\nQ3.1a\npublic\n0\n\n\n\n\nQ3.1a\nhidden\n2\n\n\n\n\nQ3.1b\npublic\n0\n\n\n\n\nQ3.1b\nhidden\n2\n\n\n\n\nQ3.2a\npublic\n0\n\n\n\n\nQ3.2a\nhidden\n2\n\n\n\n\nQ3.2b\npublic\n0\n\n\n\n\nQ3.2b\nhidden\n2\n\n\n\n\nQ3.3a\npublic\n0\n\n\n\n\nQ3.3a\nhidden\n2\n\n\n\n\nQ3.3b\npublic\n0\n\n\n\n\nQ3.3b\nhidden\n2\n12\n\n\n4\nQ4.1a\npublic\n0\n\n\n\n\nQ4.1a\nhidden\n2\n\n\n\n\nQ4.1b\npublic\n0\n\n\n\n\nQ4.1b\nhidden\n2\n\n\n\n\nQ4.2a\npublic\n0\n\n\n\n\nQ4.2a\nhidden\n2\n\n\n\n\nQ4.2b\npublic\n0\n\n\n\n\nQ4.2b\nhidden\n2\n\n\n\n\nQ4.3a\npublic\n0\n\n\n\n\nQ4.3a\nhidden\n2\n\n\n\n\nQ4.3b\npublic\n0\n\n\n\n\nQ4.3b\nhidden\n2\n12\n\n\n5\nQ5.1\npublic\n0\n\n\n\n\nQ5.1\nhidden\n4\n\n\n\n\nQ5.2\npublic\n0\n\n\n\n\nQ5.2\nhidden\n4\n\n\n\n\nQ5.3\npublic\n0\n\n\n\n\nQ5.3\nhidden\n4\n12\n\n\n6\nQ6.1\npublic\n0\n\n\n\n\nQ6.1\nhidden\n7\n\n\n\n\nQ6.2\npublic\n0\n\n\n\n\nQ6.2\nhidden\n7\n14\n\n\n7\nQ7.1\npublic\n0\n\n\n\n\nQ7.1\nhidden\n5\n\n\n\n\nQ7.2\npublic\n0\n\n\n\n\nQ7.2\nhidden\n5\n\n\n\n\nQ7.3\npublic\n0\n\n\n\n\nQ7.3\nhidden\n5\n\n\n\n\nQ7.4\npublic\n0\n\n\n\n\nQ7.4\nhidden\n5\n20\n\n\nTotal\n\n\n100\n100"
  },
  {
    "objectID": "writeups/index.html",
    "href": "writeups/index.html",
    "title": "Extra Writeups",
    "section": "",
    "text": "Order By\n       Default\n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nLast Updated\n\n\nRelevant To\n\n\nCategory\n\n\n\n\n\n\nHigher-Order DAGs via Block Models\n\n\nThursday, May 1, 2025\n\n\nWeeks 5-7 (Causality)\n\n\nExtra Writeups\n\n\n\n\nA Quick Introduction to Probabilistic Graphical Models\n\n\nSunday, February 18, 2024\n\n\nWeeks 5-7 (Causality)\n\n\nExtra Writeups\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "final.html",
    "href": "final.html",
    "title": "Final Project Specifications",
    "section": "",
    "text": "Our goal is to make the final project as open-ended as possible, to give you the space to explore any particular topic that may have piqued your interest throughout the semester! At the same time, we hope to provide you with guidance and mentorship so that you don‚Äôt feel lost as to how to start, how to proceed, and/or what to submit for the final deliverable!1"
  },
  {
    "objectID": "final.html#overview",
    "href": "final.html#overview",
    "title": "Final Project Specifications",
    "section": "",
    "text": "Our goal is to make the final project as open-ended as possible, to give you the space to explore any particular topic that may have piqued your interest throughout the semester! At the same time, we hope to provide you with guidance and mentorship so that you don‚Äôt feel lost as to how to start, how to proceed, and/or what to submit for the final deliverable!1"
  },
  {
    "objectID": "final.html#references",
    "href": "final.html#references",
    "title": "Final Project Specifications",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "final.html#footnotes",
    "href": "final.html#footnotes",
    "title": "Final Project Specifications",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you can‚Äôt tell, my whole educational philosophy here is just the Montessori system‚Äîthis approach was originally developed for younger (primary school) children, but lots and lots of recent educational research indicates that it‚Äôs an actually an extremely effective way to learn, and to motivate self-learning, for people of any age üòé‚Ü©Ô∏é"
  },
  {
    "objectID": "w01/index.html",
    "href": "w01/index.html",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "",
    "text": "Open slides in new window ‚Üí",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#prof.-jeff-introduction",
    "href": "w01/index.html#prof.-jeff-introduction",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Prof.¬†Jeff Introduction!",
    "text": "Prof.¬†Jeff Introduction!\n\nBorn in NW DC ‚Üí high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Econ",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#the-world-outside-of-dc",
    "href": "w01/index.html#the-world-outside-of-dc",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "The World Outside of DC",
    "text": "The World Outside of DC\n Studied abroad in Beijing (Peking University/ÂåóÂ§ß) ‚Üí internship with Huawei in Hong Kong (HKUST)\n\n\n\n Stanford, MS in Computer Science\n Research Economist, UC Berkeley\n Columbia, PhD in Political Economy",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#why-is-georgetown-having-me-teach-this",
    "href": "w01/index.html#why-is-georgetown-having-me-teach-this",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Why Is Georgetown Having Me Teach This?",
    "text": "Why Is Georgetown Having Me Teach This?\n\n\n\n\n\n\n\nQuanty things \\(\\leadsto\\) PhD in Political Economy\nPhD exam major: Political Philosophy\nPhD exam minor: International Relations\nPhD exam paper: ‚ÄúHow to Do Things with Translations‚Äù\nGame-changing Research Fellowships at‚Ä¶ (Nothing was the same -drake a. graham):\nSanta Fe Institute: dedicated to the multidisciplinary study of complex adaptive systems: physical, computational, biological, and social systems\n\n\n\n\n\n\n\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\nimport pandas as pd\nyear_df = pd.DataFrame({\n  'field': ['Math&lt;br&gt;(BS)','CS&lt;br&gt;(BS,MS)','Pol Phil&lt;br&gt;(PhD Pt 1)','Econ&lt;br&gt;(BS+Job)','Pol Econ&lt;br&gt;(PhD Pt 2)'],\n  'cat': ['Quant','Quant','Humanities','Social Sci','Social Sci'],\n  'yrs': [4, 6, 3, 6, 5]\n})\nfig = px.sunburst(\n    year_df, path=['cat','field'], values='yrs',\n    width=450, height=400, color='cat',\n    color_discrete_map={'Quant': cb_palette[0], 'Humanities': cb_palette[1], 'Social Sci': cb_palette[2]},\n    hover_data=[]\n)\nfig.update_traces(\n   hovertemplate=None,\n   hoverinfo='skip'\n)\n# Update layout for tight margin\n# See https://plotly.com/python/creating-and-updating-figures/\nfig.update_layout(margin = dict(t=0, l=0, r=0, b=0))\nfig.show()\n\n                                                \n\n\n\n\n\nFigure¬†1: Years spent questing in dungeons of academia\n\n\n\n\n\n\n\nCentre for the Study of the History of Political Thought, Queen Mary University of London (QMUL): New approaches to the history of political thought [Quentin Skinner, ‚ÄúCambridge School‚Äù] have changed how we study ideas from the past and their relevance to contemporary politics. The focus of the Centre is to explore [ts].",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#dissertation-nlp-x-history",
    "href": "w01/index.html#dissertation-nlp-x-history",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Dissertation (NLP x History)",
    "text": "Dissertation (NLP x History)\n‚ÄúOur Word is Our Weapon‚Äù: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#the-ir-part-wars-of-ideas-i-cold-war",
    "href": "w01/index.html#the-ir-part-wars-of-ideas-i-cold-war",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "(The IR Part) Wars of Ideas I: Cold War",
    "text": "(The IR Part) Wars of Ideas I: Cold War\n\nCold War arms shipments (SIPRI) vs.¬†propaganda (–ü–µ—á–∞—Ç—å –°–°–°–†): here, to üá™üáπ",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#the-middle-east-part-wars-of-ideas-ii-first-intifada",
    "href": "w01/index.html#the-middle-east-part-wars-of-ideas-ii-first-intifada",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "(The Middle East Part) Wars of Ideas II: First Intifada",
    "text": "(The Middle East Part) Wars of Ideas II: First Intifada",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#researching-things",
    "href": "w01/index.html#researching-things",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Researching Things",
    "text": "Researching Things\n\nMost cited paper: ‚ÄúMonopsony in Online Labor Markets‚Äù (Uses Double-Debiased ML for Causal Inference!)\nMost recent paper: ‚ÄúOperationalizing Freedom as Non-Domination in the Labor Market‚Äù (Cambridge U Press)\nRarely cited paper but often-thought-about obsession: ‚ÄúHow To Do Things With Translations‚Äù\nRelated thing you can buy in a bookstore: [Editorial board for new translation of] Capital, Vol. 1 by Karl Marx (Princeton U Press)",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#coarse-graining-units-of-observation",
    "href": "w01/index.html#coarse-graining-units-of-observation",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Coarse-Graining Units of Observation",
    "text": "Coarse-Graining Units of Observation\n\n\n\nField\nExample Unit of Observation\n\n\n\n\nPhysics\nParticle\n[Particle = Fine-Graining of Molecules]\n\n\nChemistry\nMolecule = \\(\\cup\\)(Particles)\n[Molecule = Coarse-Graining of Particles]\n\n\nBiology\nCell = \\(\\cup\\)(Molecules)\n\n\nNeuro/Cognitive Science\nBrain = \\(\\cup\\)(Cells)\n\n\nHuman Physiology\nBody = Brain \\(\\cup\\) Other Organs\n\n\nüßê something happens here‚Ä¶ ü§î\n\n\nAnthropology\nHuman-Relational System (e.g., Kinship) = \\(\\cup\\)(Brains) \\(\\times\\) Natural Environment\n\n\nEconomics\nEconomy = Specific relational system of exchange w.r.t. scarce resources\n\n\nPolitical Economy\nEconomy-Context = Economic Exchange \\(\\cap\\) Relational Power\n\n\nSociology\nSociety = \\(\\cup\\)(Relational Systems: Kinship, Friendship, Authority, Power, Violence)\n\n\nHistory\nLongue-Dur√©e = Evolution of Societies over Time and Space",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#particularly-fun-non-standard-examples",
    "href": "w01/index.html#particularly-fun-non-standard-examples",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Particularly Fun Non-‚ÄúStandard‚Äù Examples",
    "text": "Particularly Fun Non-‚ÄúStandard‚Äù Examples\n\nDeDeo, French Revolution\nGrimmer, Mirrors for Sultans and Princes",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#data-generating-processes-dgps",
    "href": "w01/index.html#data-generating-processes-dgps",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Data-Generating Processes (DGPs)",
    "text": "Data-Generating Processes (DGPs)\nThe fundamental building block for the course is the idea of a Data-Generating Process (DGP). You may have encountered this concept in passing during other DSAN courses (for example, in DSAN 5100, a phrase like ‚ÄúAssume \\(X\\) is drawn i.i.d. from a Normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\)‚Äù is a statement characterizing the DGP of a Random Variable \\(X\\)), but in this course we will ‚Äúzoom in‚Äù on this concept rather than treating it like a black box or a footnote to e.g.¬†a theorem like the Law of Large Numbers.\nThis deep dive into DGPs is necessary for us here, since our goal in the course is to move from associational statements like ‚Äúan increase of \\(X\\) by one unit is associated with an increase of \\(Y\\) by \\(\\beta\\) units‚Äù to causal statements like ‚Äúincreasing \\(X\\) by one unit causes \\(Y\\) to increase by \\(\\beta\\) units‚Äù. As you‚Äôll see in Week 1, the tools from probability theory and statistics that you learned in DSAN 5100‚ÄîRandom Variables, Cumulative Distribution Functions, Conditional Probability, and so on‚Äîare necessary but not sufficient to analyze data from a causal perspective.\nFor example, if we use our tools from DSAN 5000 and DSAN 5100 on some dataset to discover that:\n\nThe probability that some event \\(E_1\\) occurs is \\(\\Pr(E_1) = 0.5\\), and\nThe probability that \\(E_1\\) occurs conditional on another event \\(E_0\\) occurring is \\(\\Pr(E_1 \\mid E_0) = 0.75\\),\n\nwe unfortunately cannot infer from these two pieces of information that the occurrence of \\(E_0\\) causes an increase in the likelihood of \\(E_1\\) occurring.\nThis issue (that conditional probabilities could not be interpreted causally) at first represented a kind of dead end for scientists interested in employing probability theory to study causal relationships‚Ä¶ In recent decades, however, researchers have built up what amounts to an additional ‚Äúlayer‚Äù of modeling tools which augment the existing machinery of probability theory to address causality head-on!1\nFor instance, a modeling approach called ‚Äú\\(\\textsf{do}\\)-Calculus‚Äù, that we will learn in this class, extends the core operations and definitions of probability theory to allow such an move to deriving causality! It does this by introducing a \\(\\textsf{do}(\\cdot)\\) operator that can be applied to Random Variables like \\(X\\), with e.g.¬†\\(\\textsf{do}(X = 5)\\) representing the event wherein someone has intervened in a Data-Generating Process to force the value of \\(X\\) to be 5.\nWith this operator in hand (that is, used alongside an explicit model of a DGP satisfying a set of underlying axioms which are slightly more strict than the axioms of probability theory), it turns out that we can make causal inferences using a very similar pair of facts! If we know that:\n\nThe probability that some event \\(E_1\\) occurs is \\(\\Pr(E_1) = 0.5\\), and\nThe probability that \\(E_1\\) occurs conditional on the event \\(\\textsf{do}(E_0)\\) occurring is \\(\\Pr(E_1 \\mid \\textsf{do}(E_0)) = 0.75\\),\n\nnow we can actually draw the inference that the occurrence of \\(E_0\\) caused an increase in the likelihood of \\(E_1\\) occurring!\nThis stylized comparison (between what‚Äôs possible using ‚Äúcore‚Äù probability theory and what‚Äôs possible when we augment it with additional causal modeling tools) serves as our basic motivation for the course, so that from Week 2 onwards we build upon this foundation to reach the three learning goals described in the next section!",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#meta-logistics-spaced-repetition",
    "href": "w01/index.html#meta-logistics-spaced-repetition",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Meta-Logistics: Spaced Repetition",
    "text": "Meta-Logistics: Spaced Repetition",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#meta-logistics-maria-montessori-and-your-final-projects",
    "href": "w01/index.html#meta-logistics-maria-montessori-and-your-final-projects",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Meta-Logistics: Maria Montessori and Your Final Projects",
    "text": "Meta-Logistics: Maria Montessori and Your Final Projects",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#your-final-projects",
    "href": "w01/index.html#your-final-projects",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Your Final Projects",
    "text": "Your Final Projects",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#jupyterhub",
    "href": "w01/index.html#jupyterhub",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "JupyterHub",
    "text": "JupyterHub\nhttps://guhub.io",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#assignments-midterm",
    "href": "w01/index.html#assignments-midterm",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Assignments / Midterm",
    "text": "Assignments / Midterm",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#references",
    "href": "w01/index.html#references",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "References",
    "text": "References\n\n\nPearl, Judea. 2000. Causality: Models, Reasoning, and Inference. Cambridge University Press.",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/index.html#footnotes",
    "href": "w01/index.html#footnotes",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPearl (2000) represents a key work in this field of research, as it essentially brought together different pieces of causal models into one unified, rigorous framework.‚Ü©Ô∏é",
    "crumbs": [
      "Week 1: {{< var w01.date-md >}}"
    ]
  },
  {
    "objectID": "w01/slides.html#prof.-jeff-introduction",
    "href": "w01/slides.html#prof.-jeff-introduction",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Prof.¬†Jeff Introduction!",
    "text": "Prof.¬†Jeff Introduction!\n\nBorn in NW DC ‚Üí high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Econ"
  },
  {
    "objectID": "w01/slides.html#the-world-outside-of-dc",
    "href": "w01/slides.html#the-world-outside-of-dc",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "The World Outside of DC",
    "text": "The World Outside of DC\n Studied abroad in Beijing (Peking University/ÂåóÂ§ß) ‚Üí internship with Huawei in Hong Kong (HKUST)\n\n\n\n Stanford, MS in Computer Science\n Research Economist, UC Berkeley\n Columbia, PhD in Political Economy"
  },
  {
    "objectID": "w01/slides.html#why-is-georgetown-having-me-teach-this",
    "href": "w01/slides.html#why-is-georgetown-having-me-teach-this",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Why Is Georgetown Having Me Teach This?",
    "text": "Why Is Georgetown Having Me Teach This?\n\n\n\n\n\n\n\nQuanty things \\(\\leadsto\\) PhD in Political Economy\nPhD exam major: Political Philosophy\nPhD exam minor: International Relations\nPhD exam paper: ‚ÄúHow to Do Things with Translations‚Äù\nGame-changing Research Fellowships at‚Ä¶ (Nothing was the same -drake a. graham):\nSanta Fe Institute: dedicated to the multidisciplinary study of complex adaptive systems: physical, computational, biological, and social systems\n\n\n\n\n\n\n\n\n\n                                                \n\n\n\n\n\nFigure¬†1: Years spent questing in dungeons of academia\n\n\n\n\n\n\n\nCentre for the Study of the History of Political Thought, Queen Mary University of London (QMUL): New approaches to the history of political thought [Quentin Skinner, ‚ÄúCambridge School‚Äù] have changed how we study ideas from the past and their relevance to contemporary politics. The focus of the Centre is to explore [ts]."
  },
  {
    "objectID": "w01/slides.html#dissertation-nlp-x-history",
    "href": "w01/slides.html#dissertation-nlp-x-history",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Dissertation (NLP x History)",
    "text": "Dissertation (NLP x History)\n‚ÄúOur Word is Our Weapon‚Äù: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada"
  },
  {
    "objectID": "w01/slides.html#the-ir-part-wars-of-ideas-i-cold-war",
    "href": "w01/slides.html#the-ir-part-wars-of-ideas-i-cold-war",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "(The IR Part) Wars of Ideas I: Cold War",
    "text": "(The IR Part) Wars of Ideas I: Cold War\n\nCold War arms shipments (SIPRI) vs.¬†propaganda (–ü–µ—á–∞—Ç—å –°–°–°–†): here, to üá™üáπ"
  },
  {
    "objectID": "w01/slides.html#the-middle-east-part-wars-of-ideas-ii-first-intifada",
    "href": "w01/slides.html#the-middle-east-part-wars-of-ideas-ii-first-intifada",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "(The Middle East Part) Wars of Ideas II: First Intifada",
    "text": "(The Middle East Part) Wars of Ideas II: First Intifada"
  },
  {
    "objectID": "w01/slides.html#researching-things",
    "href": "w01/slides.html#researching-things",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Researching Things",
    "text": "Researching Things\n\nMost cited paper: ‚ÄúMonopsony in Online Labor Markets‚Äù (Uses Double-Debiased ML for Causal Inference!)\nMost recent paper: ‚ÄúOperationalizing Freedom as Non-Domination in the Labor Market‚Äù (Cambridge U Press)\nRarely cited paper but often-thought-about obsession: ‚ÄúHow To Do Things With Translations‚Äù\nRelated thing you can buy in a bookstore: [Editorial board for new translation of] Capital, Vol. 1 by Karl Marx (Princeton U Press)"
  },
  {
    "objectID": "w01/slides.html#coarse-graining-units-of-observation",
    "href": "w01/slides.html#coarse-graining-units-of-observation",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Coarse-Graining Units of Observation",
    "text": "Coarse-Graining Units of Observation\n\n\n\nField\nExample Unit of Observation\n\n\n\n\nPhysics\nParticle\n[Particle = Fine-Graining of Molecules]\n\n\nChemistry\nMolecule = \\(\\cup\\)(Particles)\n[Molecule = Coarse-Graining of Particles]\n\n\nBiology\nCell = \\(\\cup\\)(Molecules)\n\n\nNeuro/Cognitive Science\nBrain = \\(\\cup\\)(Cells)\n\n\nHuman Physiology\nBody = Brain \\(\\cup\\) Other Organs\n\n\nüßê something happens here‚Ä¶ ü§î\n\n\nAnthropology\nHuman-Relational System (e.g., Kinship) = \\(\\cup\\)(Brains) \\(\\times\\) Natural Environment\n\n\nEconomics\nEconomy = Specific relational system of exchange w.r.t. scarce resources\n\n\nPolitical Economy\nEconomy-Context = Economic Exchange \\(\\cap\\) Relational Power\n\n\nSociology\nSociety = \\(\\cup\\)(Relational Systems: Kinship, Friendship, Authority, Power, Violence)\n\n\nHistory\nLongue-Dur√©e = Evolution of Societies over Time and Space"
  },
  {
    "objectID": "w01/slides.html#particularly-fun-non-standard-examples",
    "href": "w01/slides.html#particularly-fun-non-standard-examples",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Particularly Fun Non-‚ÄúStandard‚Äù Examples",
    "text": "Particularly Fun Non-‚ÄúStandard‚Äù Examples\n\nDeDeo, French Revolution\nGrimmer, Mirrors for Sultans and Princes"
  },
  {
    "objectID": "w01/slides.html#data-generating-processes-dgps",
    "href": "w01/slides.html#data-generating-processes-dgps",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Data-Generating Processes (DGPs)",
    "text": "Data-Generating Processes (DGPs)\nThe fundamental building block for the course is the idea of a Data-Generating Process (DGP). You may have encountered this concept in passing during other DSAN courses (for example, in DSAN 5100, a phrase like ‚ÄúAssume \\(X\\) is drawn i.i.d. from a Normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\)‚Äù is a statement characterizing the DGP of a Random Variable \\(X\\)), but in this course we will ‚Äúzoom in‚Äù on this concept rather than treating it like a black box or a footnote to e.g.¬†a theorem like the Law of Large Numbers.\nThis deep dive into DGPs is necessary for us here, since our goal in the course is to move from associational statements like ‚Äúan increase of \\(X\\) by one unit is associated with an increase of \\(Y\\) by \\(\\beta\\) units‚Äù to causal statements like ‚Äúincreasing \\(X\\) by one unit causes \\(Y\\) to increase by \\(\\beta\\) units‚Äù. As you‚Äôll see in Week 1, the tools from probability theory and statistics that you learned in DSAN 5100‚ÄîRandom Variables, Cumulative Distribution Functions, Conditional Probability, and so on‚Äîare necessary but not sufficient to analyze data from a causal perspective.\nFor example, if we use our tools from DSAN 5000 and DSAN 5100 on some dataset to discover that:\n\nThe probability that some event \\(E_1\\) occurs is \\(\\Pr(E_1) = 0.5\\), and\nThe probability that \\(E_1\\) occurs conditional on another event \\(E_0\\) occurring is \\(\\Pr(E_1 \\mid E_0) = 0.75\\),\n\nwe unfortunately cannot infer from these two pieces of information that the occurrence of \\(E_0\\) causes an increase in the likelihood of \\(E_1\\) occurring.\nThis issue (that conditional probabilities could not be interpreted causally) at first represented a kind of dead end for scientists interested in employing probability theory to study causal relationships‚Ä¶ In recent decades, however, researchers have built up what amounts to an additional ‚Äúlayer‚Äù of modeling tools which augment the existing machinery of probability theory to address causality head-on!1\nFor instance, a modeling approach called ‚Äú\\(\\textsf{do}\\)-Calculus‚Äù, that we will learn in this class, extends the core operations and definitions of probability theory to allow such an move to deriving causality! It does this by introducing a \\(\\textsf{do}(\\cdot)\\) operator that can be applied to Random Variables like \\(X\\), with e.g.¬†\\(\\textsf{do}(X = 5)\\) representing the event wherein someone has intervened in a Data-Generating Process to force the value of \\(X\\) to be 5.\nWith this operator in hand (that is, used alongside an explicit model of a DGP satisfying a set of underlying axioms which are slightly more strict than the axioms of probability theory), it turns out that we can make causal inferences using a very similar pair of facts! If we know that:\n\nThe probability that some event \\(E_1\\) occurs is \\(\\Pr(E_1) = 0.5\\), and\nThe probability that \\(E_1\\) occurs conditional on the event \\(\\textsf{do}(E_0)\\) occurring is \\(\\Pr(E_1 \\mid \\textsf{do}(E_0)) = 0.75\\),\n\nnow we can actually draw the inference that the occurrence of \\(E_0\\) caused an increase in the likelihood of \\(E_1\\) occurring!\nThis stylized comparison (between what‚Äôs possible using ‚Äúcore‚Äù probability theory and what‚Äôs possible when we augment it with additional causal modeling tools) serves as our basic motivation for the course, so that from Week 2 onwards we build upon this foundation to reach the three learning goals described in the next section!\nPearl (2000) represents a key work in this field of research, as it essentially brought together different pieces of causal models into one unified, rigorous framework."
  },
  {
    "objectID": "w01/slides.html#meta-logistics-spaced-repetition",
    "href": "w01/slides.html#meta-logistics-spaced-repetition",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Meta-Logistics: Spaced Repetition",
    "text": "Meta-Logistics: Spaced Repetition"
  },
  {
    "objectID": "w01/slides.html#meta-logistics-maria-montessori-and-your-final-projects",
    "href": "w01/slides.html#meta-logistics-maria-montessori-and-your-final-projects",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Meta-Logistics: Maria Montessori and Your Final Projects",
    "text": "Meta-Logistics: Maria Montessori and Your Final Projects"
  },
  {
    "objectID": "w01/slides.html#your-final-projects",
    "href": "w01/slides.html#your-final-projects",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Your Final Projects",
    "text": "Your Final Projects"
  },
  {
    "objectID": "w01/slides.html#jupyterhub",
    "href": "w01/slides.html#jupyterhub",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "JupyterHub",
    "text": "JupyterHub\nhttps://guhub.io"
  },
  {
    "objectID": "w01/slides.html#assignments-midterm",
    "href": "w01/slides.html#assignments-midterm",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "Assignments / Midterm",
    "text": "Assignments / Midterm"
  },
  {
    "objectID": "w01/slides.html#references",
    "href": "w01/slides.html#references",
    "title": "Week 1: From a Science of Particles to a Science of People",
    "section": "References",
    "text": "References\n\n\nPearl, Judea. 2000. Causality: Models, Reasoning, and Inference. Cambridge University Press."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Welcome to DSAN 5650: Causal Inference for Computational Social Science at Georgetown University!\nThe course meets on Wednesdays from 6:30-9pm online via Zoom",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-staff",
    "href": "syllabus.html#course-staff",
    "title": "Syllabus",
    "section": "Course Staff",
    "text": "Course Staff\n\nProf.¬†Jeff Jacobs, jj1088@georgetown.edu\n\nOffice hours (Click to schedule): Tuesdays, 3:30-6pm\n\nTA Courtney Green, crg123@georgetown.edu\n\nOffice hours by appointment\n\nTA Wendy Hu, lh1078@georgetown.edu\n\nOffice hours by appointment",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis course provides students with the opportunity to take the analytical skills, machine learning algorithms, and statistical methods learned throughout their first year in the program and explore how they can be employed to carry out rigorous, original research in the behavioral and social sciences. With a particular emphasis on tackling the additional challenges which arise when moving from associational to causal inference, particularly when only observational (as opposed to experimental) data is available, students will become proficient in cutting-edge causal Machine Learning techniques such as propensity score matching, synthetic controls, causal program evaluation, inverse social welfare function estimation from panel data, and Double-Debiased Machine Learning.\nIn-class examples will cover continuous, discrete-choice, and textual data from a wide swath of social and behavioral sciences: economics, political science, sociology, anthropology, quantitative history, and digital humanities. After gaining experience through in-class labs and homework assignments focused on reproducing key findings from recent journal articles in each of these disciplines, students will spend the final weeks of the course on a final project demonstrating their ability to develop, evaluate, and test the robustness of a causal hypothesis.\nPrerequisites: DSAN 5000, DSAN 5100 (DSAN 5300 recommended but not required)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-overview",
    "href": "syllabus.html#course-overview",
    "title": "Syllabus",
    "section": "Course Overview",
    "text": "Course Overview\nThe fundamental building block for the course is the idea of a Data-Generating Process (DGP). You may have encountered this concept in passing during other DSAN courses (for example, in DSAN 5100, a phrase like ‚ÄúAssume \\(X\\) is drawn i.i.d. from a Normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\)‚Äù is a statement characterizing the DGP of a Random Variable \\(X\\)), but in this course we will ‚Äúzoom in‚Äù on this concept rather than treating it like a black box or a footnote to e.g.¬†a theorem like the Law of Large Numbers.\nThis deep dive into DGPs is necessary for us here, since our goal in the course is to move from associational statements like ‚Äúan increase of \\(X\\) by one unit is associated with an increase of \\(Y\\) by \\(\\beta\\) units‚Äù to causal statements like ‚Äúincreasing \\(X\\) by one unit causes \\(Y\\) to increase by \\(\\beta\\) units‚Äù. As you‚Äôll see in Week 1, the tools from probability theory and statistics that you learned in DSAN 5100‚ÄîRandom Variables, Cumulative Distribution Functions, Conditional Probability, and so on‚Äîare necessary but not sufficient to analyze data from a causal perspective.\nFor example, if we use our tools from DSAN 5000 and DSAN 5100 on some dataset to discover that:\n\nThe probability that some event \\(E_1\\) occurs is \\(\\Pr(E_1) = 0.5\\), and\nThe probability that \\(E_1\\) occurs conditional on another event \\(E_0\\) occurring is \\(\\Pr(E_1 \\mid E_0) = 0.75\\),\n\nwe unfortunately cannot infer from these two pieces of information that the occurrence of \\(E_0\\) causes an increase in the likelihood of \\(E_1\\) occurring.\nThis issue (that conditional probabilities could not be interpreted causally) at first represented a kind of dead end for scientists interested in employing probability theory to study causal relationships‚Ä¶ In recent decades, however, researchers have built up what amounts to an additional ‚Äúlayer‚Äù of modeling tools which augment the existing machinery of probability theory to address causality head-on!1\nFor instance, a modeling approach called ‚Äú\\(\\textsf{do}\\)-Calculus‚Äù, that we will learn in this class, extends the core operations and definitions of probability theory to allow such an move to deriving causality! It does this by introducing a \\(\\textsf{do}(\\cdot)\\) operator that can be applied to Random Variables like \\(X\\), with e.g.¬†\\(\\textsf{do}(X = 5)\\) representing the event wherein someone has intervened in a Data-Generating Process to force the value of \\(X\\) to be 5.\nWith this operator in hand (that is, used alongside an explicit model of a DGP satisfying a set of underlying axioms which are slightly more strict than the axioms of probability theory), it turns out that we can make causal inferences using a very similar pair of facts! If we know that:\n\nThe probability that some event \\(E_1\\) occurs is \\(\\Pr(E_1) = 0.5\\), and\nThe probability that \\(E_1\\) occurs conditional on the event \\(\\textsf{do}(E_0)\\) occurring is \\(\\Pr(E_1 \\mid \\textsf{do}(E_0)) = 0.75\\),\n\nnow we can actually draw the inference that the occurrence of \\(E_0\\) caused an increase in the likelihood of \\(E_1\\) occurring!\nThis stylized comparison (between what‚Äôs possible using ‚Äúcore‚Äù probability theory and what‚Äôs possible when we augment it with additional causal modeling tools) serves as our basic motivation for the course, so that from Week 2 onwards we build upon this foundation to reach the three learning goals described in the next section!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#main-textbooks-resources",
    "href": "syllabus.html#main-textbooks-resources",
    "title": "Syllabus",
    "section": "Main Textbooks / Resources",
    "text": "Main Textbooks / Resources\nUnlike the case for topics like calculus or statistical learning, this field is too new (and exciting! with new methods being developed month-to-month) to have a single set of ‚Äúestablished‚Äù textbooks. Thus, the main collection of resources (books, papers, and explanatory videos) we‚Äôll draw on for this class are available on the resources page. However, there are three ‚Äúcore‚Äù textbooks you can draw on which best align with the topics in this course:\n\nMorgan and Winship, Counterfactuals and Causal Inference: Methods and Principles for Social Research (Morgan and Winship 2015) [PDF]\n\nThe book which comes closest to being an all-encompassing, single textbook for the class. It brings together different ‚Äústrands‚Äù of causal modeling research (since each field‚Äîeconomics, bioinformatics, sociology, etc.‚Äîtends to use its own notation and vocabulary), unifying them into a single approach. The only reason we can‚Äôt use it as the main textbook is because it hasn‚Äôt been updated since 2015, and most of the assignments in this class use computational tools from 2018 onwards!\n\nAngrist and Pischke, Mastering ‚ÄôMetrics: The Path from Cause to Effect (Angrist and Pischke 2014) [PDF]\n\nThis book is included as the second of the three ‚Äúcore‚Äù texts mainly because, it uses the language of causality specific to Econometrics, the language that is most familiar to me from my PhD training in Political Economy. However, if you tend to learn better by example, it also does a good job of foregrounding specific examples (like evaluating charter schools and community policing policies), so that the methods emerging naturally from attempts to solve these puzzles when association methods like linear regression fail to capture their causal linkages.\n\nPearl and Mackenzie, The Book of Why: The New Science of Cause and Effect (Pearl and Mackenzie 2018) [EPUB]\n\nThis book contrasts with the Angrist and Pischke book in using the language of causality formed within Computer Science rather than Economics. It can be a good starting point especially if you‚Äôre unfamiliar with the heavy use of diagrams for scientific modeling‚Äîbasically, whereas Angrist and Pischke‚Äôs first instinct is to use (sometimes informal) equations like \\(y = mx + b\\) to explain steps in the procedures, Pearl and Mackenzie‚Äôs instinct would be to instead use something like \\(\\require{enclose}\\enclose{circle}{\\kern .01em ~x~\\kern .01em} \\overset{\\small m, b}{\\longrightarrow} \\enclose{circle}{\\kern.01em y~\\kern .01em}\\) to represent the same concept (in this case, a line with slope \\(m\\) and intercept \\(b\\)!).",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "Syllabus",
    "section": "Schedule",
    "text": "Schedule\nThe following is a rough map of what we will work through together throughout the semester; given that everyone learns at a different pace, my aim is to leave us with a good amount of flexibility in terms of how much time we spend on each topic: if I find that it takes me longer than a week to convey a certain topic in sufficient depth, for example, then I view it as a strength rather than a weakness of the course that we can then rearrange the calendar below by adding an extra week on that particular topic! Similarly, if it seems like I am spending too much time on a topic, to the point that students seem bored or impatient to move onto the next topic, we can move a topic intended for the next week to the current week!\n\n\n\nUnit\nWeek\nDate\nTopic\n\n\n\n\nUnit 1: The Language of Causal Modeling\n1\nMay 21\nFrom a Science of Particles to a Science of People\n\n\n\n2\nMay 28\nProbabilistic Graphical Models (PGMs) as Data-Generating Processes (DGPs)\n\n\n\n\nMay 30 (Friday), 5:59pm EST\n[Deliverable] HW1: Causal Modeling with DAGs and PGMs: Direct and Indirect Effects\n\n\nUnit 2: Doin Thangs\n3\nJun 4\nPGMs as Causal Graphs via do-Calculus: Chains, Forks, and Colliders\n\n\n\n4\nJun 11\nSome Humility via Theory: Have We Closed All Backdoor Paths?\n\n\nUnit 3: Matching Apples to Apples\n5\nJun 18\nStatistical Matching (A Cautious First Dip into Computational Methods)\n\n\n\n6\nJun 25\nMidterm Review (feat. Example Problems)\n\n\nMidterm\n7\nJul 2\nIn-Class Midterm: Causal Models and Statistical Matching\n\n\nUnit 4: Machine Learning for Causal Inference\n8\nJul 9\nPropensity Score Matching\n\n\n\n9\nJul 16\nDouble-Debiased Machine Learning\n\n\n\n10\nJul 23\nCausal Forests for Heterogeneous Treatment Effects\n\n\n\n11\nJul 30\nFancier Causal Inference at the Fancy Computational Methods Frontier\n\n\nFinal Project Zone\n12\nAug 6\nFinal Project Huddle\n\n\n\n13\nAug 13\nFinal Project Presentations\n\n\n\n\nAug 15 (Friday), 5:59pm EDT\n[Deliverable] Final Project",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assignments-and-grading",
    "href": "syllabus.html#assignments-and-grading",
    "title": "Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThe main assignment in the course will be your final project, submitted at the end of the semester. However, there will also be a (virtual) in-class midterm exam and a series of assignments which exist to let you explore each of the modules of the course, in turn.\n\n\n\n\n\n\n\n\nAssignment\nDue Date\n% of Grade\n\n\n\n\nHW1: Causal Modeling with DAGs and PGMs: Direct and Indirect Effects\nFriday, May 30\n9%\n\n\nHW2: Traversing the Sea of Causality with the do-Harpoon in Hand: Chains, Forks, and Colliders\nFriday, February 21\n9%\n\n\nHW3: Statistical Matching: Apples to Apples and Oranges to Oranges\nFriday, June 27\n9%\n\n\nIn-Class Midterm\nWednesday, July 2\n25%\n\n\nHW4: Basic Computational Causal Methods\nFriday, July 11\n9%\n\n\nHW5: Fancy Computational Causal Methods\nFriday, July 25\n9%\n\n\nFinal Project\nFriday, August 15\n30%\n\n\n\n\nHomework Lateness Policy\nAfter the due date, for each assignment besides the midterm, you will have a grace period of 24 hours to submit the assignment without a lateness penalty. After this 24-hour grace period, late penalties will be applied based on the following scale (unless you obtain an excused lateness from one of the instructional staff!):\n\n0 to 24 hours late: no penalty\n24 to 30 hours late: 2.5% penalty\n30 to 42 hours late: 5% penalty\n42 to 54 hours late: 10% penalty\n54 to 66 hours late: 20% penalty\nMore than 66 hours late: Assignment submissions no longer accepted (without instructor approval)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPearl (2000) represents a key work in this field of research, as it essentially brought together different pieces of causal models into one unified, rigorous framework.‚Ü©Ô∏é",
    "crumbs": [
      "Syllabus"
    ]
  }
]